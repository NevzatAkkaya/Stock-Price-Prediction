{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":89393,"databundleVersionId":10297209,"sourceType":"competition"}],"dockerImageVersionId":30822,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-01-08T19:05:47.454338Z","iopub.execute_input":"2025-01-08T19:05:47.454828Z","iopub.status.idle":"2025-01-08T19:05:47.787135Z","shell.execute_reply.started":"2025-01-08T19:05:47.454788Z","shell.execute_reply":"2025-01-08T19:05:47.786224Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/math482-2024-2025-1-hw-03/sample_submission.csv\n/kaggle/input/math482-2024-2025-1-hw-03/train.csv\n/kaggle/input/math482-2024-2025-1-hw-03/test.csv\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"from sklearn import preprocessing\nimport matplotlib.pyplot as plt\ntraindf=pd.read_csv(\"/kaggle/input/math482-2024-2025-1-hw-03/train.csv\")\ntestdf=pd.read_csv(\"/kaggle/input/math482-2024-2025-1-hw-03/test.csv\")\ntraindf.isnull().sum() \ntrainY=traindf[\"target\"]\ntraindf.drop([\"id\"], axis=1, inplace=True)\ntestdf.drop([\"id\"], axis=1, inplace=True) #drop ids and extract labels","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-08T19:05:47.788236Z","iopub.execute_input":"2025-01-08T19:05:47.788642Z","iopub.status.idle":"2025-01-08T19:05:48.418097Z","shell.execute_reply.started":"2025-01-08T19:05:47.788617Z","shell.execute_reply":"2025-01-08T19:05:48.417166Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"copy=traindf.copy()\ncopy2=traindf.copy()\ncopy.drop([\"target\"],axis=1, inplace=True)\ncategorical_columns = traindf.select_dtypes(include=['object']).columns #select numerical and categorical columns for specific exploratorty data analysis\nnumeric_columns = copy.select_dtypes(include=['number']).columns\ntraindf[categorical_columns]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-08T19:05:48.419821Z","iopub.execute_input":"2025-01-08T19:05:48.420124Z","iopub.status.idle":"2025-01-08T19:05:48.457378Z","shell.execute_reply.started":"2025-01-08T19:05:48.420102Z","shell.execute_reply":"2025-01-08T19:05:48.456407Z"}},"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"      feature_03 feature_07 feature_11 feature_14 feature_16 feature_18  \\\n0              u         B1         xy         ij         C3         A2   \n1            NaN         B3        NaN         ij         C1         A4   \n2              u         B3         xy         ii         C2         A5   \n3              q         B6         yy         ji         C1         A8   \n4              t         B5         yy         jj        NaN         A7   \n...          ...        ...        ...        ...        ...        ...   \n29995          s         B2        NaN         ji         C3         A2   \n29996          q         B5         xx         ij         C3         A7   \n29997          s         B6         yx         ij         C5         A5   \n29998          r         B6        NaN         ji         C4         A7   \n29999          u         B1         xy         ji         C3         A3   \n\n      feature_19 feature_20  \n0             ab         D4  \n1             ac         D1  \n2             ab         D1  \n3             ad         D1  \n4            NaN        NaN  \n...          ...        ...  \n29995         ac         D1  \n29996         ab         D4  \n29997         aa         D1  \n29998         ae         D4  \n29999        NaN         D1  \n\n[30000 rows x 8 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>feature_03</th>\n      <th>feature_07</th>\n      <th>feature_11</th>\n      <th>feature_14</th>\n      <th>feature_16</th>\n      <th>feature_18</th>\n      <th>feature_19</th>\n      <th>feature_20</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>u</td>\n      <td>B1</td>\n      <td>xy</td>\n      <td>ij</td>\n      <td>C3</td>\n      <td>A2</td>\n      <td>ab</td>\n      <td>D4</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>NaN</td>\n      <td>B3</td>\n      <td>NaN</td>\n      <td>ij</td>\n      <td>C1</td>\n      <td>A4</td>\n      <td>ac</td>\n      <td>D1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>u</td>\n      <td>B3</td>\n      <td>xy</td>\n      <td>ii</td>\n      <td>C2</td>\n      <td>A5</td>\n      <td>ab</td>\n      <td>D1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>q</td>\n      <td>B6</td>\n      <td>yy</td>\n      <td>ji</td>\n      <td>C1</td>\n      <td>A8</td>\n      <td>ad</td>\n      <td>D1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>t</td>\n      <td>B5</td>\n      <td>yy</td>\n      <td>jj</td>\n      <td>NaN</td>\n      <td>A7</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>29995</th>\n      <td>s</td>\n      <td>B2</td>\n      <td>NaN</td>\n      <td>ji</td>\n      <td>C3</td>\n      <td>A2</td>\n      <td>ac</td>\n      <td>D1</td>\n    </tr>\n    <tr>\n      <th>29996</th>\n      <td>q</td>\n      <td>B5</td>\n      <td>xx</td>\n      <td>ij</td>\n      <td>C3</td>\n      <td>A7</td>\n      <td>ab</td>\n      <td>D4</td>\n    </tr>\n    <tr>\n      <th>29997</th>\n      <td>s</td>\n      <td>B6</td>\n      <td>yx</td>\n      <td>ij</td>\n      <td>C5</td>\n      <td>A5</td>\n      <td>aa</td>\n      <td>D1</td>\n    </tr>\n    <tr>\n      <th>29998</th>\n      <td>r</td>\n      <td>B6</td>\n      <td>NaN</td>\n      <td>ji</td>\n      <td>C4</td>\n      <td>A7</td>\n      <td>ae</td>\n      <td>D4</td>\n    </tr>\n    <tr>\n      <th>29999</th>\n      <td>u</td>\n      <td>B1</td>\n      <td>xy</td>\n      <td>ji</td>\n      <td>C3</td>\n      <td>A3</td>\n      <td>NaN</td>\n      <td>D1</td>\n    </tr>\n  </tbody>\n</table>\n<p>30000 rows Ã— 8 columns</p>\n</div>"},"metadata":{}}],"execution_count":3},{"cell_type":"code","source":"for  col in categorical_columns:\n    category_means = traindf.groupby(col)['target'].mean() #check the distribution of categorical columns to find out if there is an ordinary relation or not\n    print(category_means.sort_values())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-08T19:05:48.458734Z","iopub.execute_input":"2025-01-08T19:05:48.459009Z","iopub.status.idle":"2025-01-08T19:05:48.497447Z","shell.execute_reply.started":"2025-01-08T19:05:48.458988Z","shell.execute_reply":"2025-01-08T19:05:48.496472Z"}},"outputs":[{"name":"stdout","text":"feature_03\nu    1101.283430\ns    1123.285007\nq    1124.416177\np    1127.059847\nt    1150.239394\nr    1150.537786\nName: target, dtype: float64\nfeature_07\nB1    1116.604299\nB4    1121.923353\nB2    1130.381694\nB3    1131.159459\nB6    1132.794767\nB5    1142.128984\nName: target, dtype: float64\nfeature_11\nxy    1116.367454\nyx    1117.089159\nyy    1140.632663\nxx    1146.399702\nName: target, dtype: float64\nfeature_14\nij    1124.898162\nji    1128.959035\njj    1129.830736\nii    1134.050130\nName: target, dtype: float64\nfeature_16\nC4    1121.232557\nC3    1122.523295\nC2    1123.243565\nC1    1127.254313\nC5    1146.093980\nName: target, dtype: float64\nfeature_18\nA6    1116.867573\nA1    1119.003539\nA5    1124.504194\nA8    1125.952556\nA4    1130.137108\nA7    1133.020358\nA2    1133.408482\nA3    1139.020063\nName: target, dtype: float64\nfeature_19\nae    1113.891509\nab    1117.949863\nac    1125.416430\nad    1137.492436\naa    1148.784135\nName: target, dtype: float64\nfeature_20\nD6    1117.642400\nD2    1120.389419\nD3    1125.142079\nD4    1128.074422\nD1    1131.076651\nD5    1138.986324\nName: target, dtype: float64\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"traindf[\"feature_01\"].describe()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-08T19:05:48.498370Z","iopub.execute_input":"2025-01-08T19:05:48.498727Z","iopub.status.idle":"2025-01-08T19:05:48.512637Z","shell.execute_reply.started":"2025-01-08T19:05:48.498695Z","shell.execute_reply":"2025-01-08T19:05:48.511682Z"}},"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"count    27152.000000\nmean       394.091653\nstd       1164.757698\nmin         10.000000\n25%         35.010000\n50%         59.430000\n75%         84.380000\nmax       6428.390000\nName: feature_01, dtype: float64"},"metadata":{}}],"execution_count":5},{"cell_type":"code","source":"traindf[\"feature_17\"].dropna().plot(kind='hist', bins=10, color='skyblue', edgecolor='black')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-08T19:05:48.513700Z","iopub.execute_input":"2025-01-08T19:05:48.514140Z","iopub.status.idle":"2025-01-08T19:05:48.876910Z","shell.execute_reply.started":"2025-01-08T19:05:48.514106Z","shell.execute_reply":"2025-01-08T19:05:48.875725Z"}},"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"<Axes: ylabel='Frequency'>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<Figure size 640x480 with 1 Axes>","image/png":"iVBORw0KGgoAAAANSUhEUgAAAk0AAAGdCAYAAAAPLEfqAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAvK0lEQVR4nO3df1RU9b7/8Rc/HH6oQIqAHFEpLTVIExMp6+SRKxp1Mj1980dFHsqrBzoqZWp1zJt1KL2alia3W0mtq2neW1ZqGGFqJv5C0TQlTRNNQM1gBBUQ9vePLvs6abbF0Rno+VhrL539ebPnveezlNfas+czHoZhGAIAAMBFebq6AQAAgIaA0AQAAGABoQkAAMACQhMAAIAFhCYAAAALCE0AAAAWEJoAAAAsIDQBAABY4O3qBhqL2tpaHTlyRM2bN5eHh4er2wEAABYYhqGTJ08qPDxcnp4Xv5ZEaHKSI0eOKCIiwtVtAACAejh06JDatGlz0RpCk5M0b95c0s8vekBAgIu7AQAAVtjtdkVERJi/xy+G0OQkdW/JBQQEEJoAAGhgrNxaw43gAAAAFhCaAAAALCA0AQAAWEBoAgAAsIDQBAAAYAGhCQAAwAKXhqb09HTdcsstat68uUJCQjRw4EAVFBQ41Nx5553y8PBw2EaNGuVQU1hYqMTERPn7+yskJETjx4/X2bNnHWpWr16t7t27y8fHRx06dFBmZuZ5/cydO1ft27eXr6+vYmNjtWnTJqefMwAAaJhcGprWrFmjlJQUbdiwQdnZ2aqurla/fv1UUVHhUPfYY4+pqKjI3KZNm2aO1dTUKDExUVVVVVq/fr3eeecdZWZmavLkyWbNgQMHlJiYqD59+ig/P19jx47Vo48+qpUrV5o1ixcvVlpamp577jlt3bpVXbt2VUJCgo4ePXrlXwgAAOD2PAzDMFzdRJ1jx44pJCREa9as0R133CHp5ytN3bp106xZsy74M59++qnuvvtuHTlyRKGhoZKkjIwMTZgwQceOHZPNZtOECRO0fPly7dy50/y5IUOGqLS0VFlZWZKk2NhY3XLLLZozZ46kn79LLiIiQo8//rgmTpz4m73b7XYFBgaqrKyMxS0BAGggLuX3t1vd01RWViZJatGihcP+BQsWKDg4WFFRUZo0aZJOnTpljuXm5io6OtoMTJKUkJAgu92uXbt2mTXx8fEOx0xISFBubq4kqaqqSnl5eQ41np6eio+PN2t+qbKyUna73WEDAACNl9t8jUptba3Gjh2r2267TVFRUeb+YcOGqV27dgoPD9eOHTs0YcIEFRQU6IMPPpAkFRcXOwQmSebj4uLii9bY7XadPn1aP/30k2pqai5Ys2fPngv2m56ern/7t3+7vJMGAAANhtuEppSUFO3cuVPr1q1z2D9y5Ejz79HR0WrdurX69u2r7777Ttddd93VbtM0adIkpaWlmY/rvvAPAAA0Tm4RmlJTU7Vs2TKtXbtWbdq0uWhtbGysJGnfvn267rrrFBYWdt6n3EpKSiRJYWFh5p91+86tCQgIkJ+fn7y8vOTl5XXBmrpj/JKPj498fHysnyQAAGjQXBqaDMPQ448/rg8//FCrV69WZGTkb/5Mfn6+JKl169aSpLi4OL344os6evSoQkJCJEnZ2dkKCAhQly5dzJoVK1Y4HCc7O1txcXGSJJvNppiYGOXk5GjgwIGSfn67MCcnR6mpqc441ctWWFio48ePu7qNSxIcHKy2bdu6ug0AAJzDcKHRo0cbgYGBxurVq42ioiJzO3XqlGEYhrFv3z7j+eefN7Zs2WIcOHDA+Oijj4xrr73WuOOOO8xjnD171oiKijL69etn5OfnG1lZWUarVq2MSZMmmTX79+83/P39jfHjxxu7d+825s6da3h5eRlZWVlmzaJFiwwfHx8jMzPT+Oabb4yRI0caQUFBRnFxsaVzKSsrMyQZZWVlTnp1/s/BgwcNP39/Q1KD2vz8/Y2DBw86/fUAAMBZLuX3t0uvNM2bN0/Sz8sKnGv+/Pl65JFHZLPZ9Pnnn2vWrFmqqKhQRESEBg8erGeffdas9fLy0rJlyzR69GjFxcWpadOmSkpK0vPPP2/WREZGavny5Ro3bpxmz56tNm3a6M0331RCQoJZ88ADD+jYsWOaPHmyiouL1a1bN2VlZZ13c7grHD9+XKdPndL/e2GeQiI7urodS44e2Kv3nx2t48ePc7UJANAouNU6TQ3ZlVynaevWrYqJiVHqgs/1h85dnXrsK+WH3ds1Z3i88vLy1L17d1e3AwDABTXYdZoAAADcFaEJAADAAkITAACABYQmAAAACwhNAAAAFhCaAAAALCA0AQAAWEBoAgAAsIDQBAAAYAGhCQAAwAJCEwAAgAWEJgAAAAsITQAAABYQmgAAACwgNAEAAFhAaAIAALCA0AQAAGABoQkAAMACQhMAAIAFhCYAAAALCE0AAAAWEJoAAAAsIDQBAABYQGgCAACwgNAEAABgAaEJAADAAkITAACABYQmAAAACwhNAAAAFhCaAAAALCA0AQAAWEBoAgAAsIDQBAAAYAGhCQAAwAJCEwAAgAWEJgAAAAsITQAAABYQmgAAACwgNAEAAFhAaAIAALCA0AQAAGABoQkAAMACQhMAAIAFhCYAAAALCE0AAAAWEJoAAAAsIDQBAABYQGgCAACwgNAEAABgAaEJAADAAkITAACABYQmAAAACwhNAAAAFhCaAAAALCA0AQAAWEBoAgAAsIDQBAAAYAGhCQAAwAJCEwAAgAWEJgAAAAtcGprS09N1yy23qHnz5goJCdHAgQNVUFDgUHPmzBmlpKSoZcuWatasmQYPHqySkhKHmsLCQiUmJsrf318hISEaP368zp4961CzevVqde/eXT4+PurQoYMyMzPP62fu3Llq3769fH19FRsbq02bNjn9nAEAQMPk0tC0Zs0apaSkaMOGDcrOzlZ1dbX69euniooKs2bcuHH65JNPtGTJEq1Zs0ZHjhzRoEGDzPGamholJiaqqqpK69ev1zvvvKPMzExNnjzZrDlw4IASExPVp08f5efna+zYsXr00Ue1cuVKs2bx4sVKS0vTc889p61bt6pr165KSEjQ0aNHr86LAQAA3JqHYRiGq5uoc+zYMYWEhGjNmjW64447VFZWplatWmnhwoX6y1/+Iknas2ePOnfurNzcXPXq1Uuffvqp7r77bh05ckShoaGSpIyMDE2YMEHHjh2TzWbThAkTtHz5cu3cudN8riFDhqi0tFRZWVmSpNjYWN1yyy2aM2eOJKm2tlYRERF6/PHHNXHixN/s3W63KzAwUGVlZQoICHDq67J161bFxMQodcHn+kPnrk499pXyw+7tmjM8Xnl5eerevbur2wEA4IIu5fe3W93TVFZWJklq0aKFJCkvL0/V1dWKj483azp16qS2bdsqNzdXkpSbm6vo6GgzMElSQkKC7Ha7du3aZdace4y6mrpjVFVVKS8vz6HG09NT8fHxZs0vVVZWym63O2wAAKDxcpvQVFtbq7Fjx+q2225TVFSUJKm4uFg2m01BQUEOtaGhoSouLjZrzg1MdeN1YxersdvtOn36tI4fP66ampoL1tQd45fS09MVGBhobhEREfU7cQAA0CC4TWhKSUnRzp07tWjRIle3YsmkSZNUVlZmbocOHXJ1SwAA4ArydnUDkpSamqply5Zp7dq1atOmjbk/LCxMVVVVKi0tdbjaVFJSorCwMLPml59yq/t03bk1v/zEXUlJiQICAuTn5ycvLy95eXldsKbuGL/k4+MjHx+f+p0wAABocFx6pckwDKWmpurDDz/UqlWrFBkZ6TAeExOjJk2aKCcnx9xXUFCgwsJCxcXFSZLi4uL09ddfO3zKLTs7WwEBAerSpYtZc+4x6mrqjmGz2RQTE+NQU1tbq5ycHLMGAAD8vrn0SlNKSooWLlyojz76SM2bNzfvHwoMDJSfn58CAwOVnJystLQ0tWjRQgEBAXr88ccVFxenXr16SZL69eunLl266KGHHtK0adNUXFysZ599VikpKeaVoFGjRmnOnDl66qmn9Ne//lWrVq3S+++/r+XLl5u9pKWlKSkpST169FDPnj01a9YsVVRUaMSIEVf/hQEAAG7HpaFp3rx5kqQ777zTYf/8+fP1yCOPSJJeeeUVeXp6avDgwaqsrFRCQoJef/11s9bLy0vLli3T6NGjFRcXp6ZNmyopKUnPP/+8WRMZGanly5dr3Lhxmj17ttq0aaM333xTCQkJZs0DDzygY8eOafLkySouLla3bt2UlZV13s3hAADg98mt1mlqyFinyRHrNAEAGoIGu04TAACAuyI0AQAAWEBoAgAAsIDQBAAAYAGhCQAAwAJCEwAAgAWEJgAAAAsITQAAABYQmgAAACwgNAEAAFhAaAIAALCA0AQAAGABoQkAAMACQhMAAIAFhCYAAAALCE0AAAAWEJoAAAAsIDQBAABYQGgCAACwgNAEAABgAaEJAADAAkITAACABYQmAAAACwhNAAAAFhCaAAAALCA0AQAAWEBoAgAAsIDQBAAAYAGhCQAAwAJCEwAAgAWEJgAAAAsITQAAABYQmgAAACwgNAEAAFhAaAIAALCA0AQAAGABoQkAAMACQhMAAIAFhCYAAAALCE0AAAAWEJoAAAAsIDQBAABYQGgCAACwgNAEAABgAaEJAADAAkITAACABYQmAAAACwhNAAAAFhCaAAAALCA0AQAAWEBoAgAAsIDQBAAAYAGhCQAAwAJCEwAAgAWEJgAAAAsITQAAABYQmgAAACwgNAEAAFhAaAIAALCA0AQAAGCBS0PT2rVrdc899yg8PFweHh5aunSpw/gjjzwiDw8Ph61///4ONSdOnNDw4cMVEBCgoKAgJScnq7y83KFmx44duv322+Xr66uIiAhNmzbtvF6WLFmiTp06ydfXV9HR0VqxYoXTzxcAADRc9QpN+/fvd8qTV1RUqGvXrpo7d+6v1vTv319FRUXm9t577zmMDx8+XLt27VJ2draWLVumtWvXauTIkea43W5Xv3791K5dO+Xl5Wn69OmaMmWK3njjDbNm/fr1Gjp0qJKTk7Vt2zYNHDhQAwcO1M6dO51yngAAoOHzrs8PdejQQX/84x+VnJysv/zlL/L19a3Xkw8YMEADBgy4aI2Pj4/CwsIuOLZ7925lZWVp8+bN6tGjhyTptdde01133aV///d/V3h4uBYsWKCqqiq9/fbbstlsuvHGG5Wfn6+ZM2ea4Wr27Nnq37+/xo8fL0maOnWqsrOzNWfOHGVkZNTr3AAAQONSrytNW7du1U033aS0tDSFhYXpX//1X7Vp0yZn9yZJWr16tUJCQnTDDTdo9OjR+vHHH82x3NxcBQUFmYFJkuLj4+Xp6amNGzeaNXfccYdsNptZk5CQoIKCAv30009mTXx8vMPzJiQkKDc391f7qqyslN1ud9gAAEDjVa/Q1K1bN82ePVtHjhzR22+/raKiIvXu3VtRUVGaOXOmjh075pTm+vfvr3fffVc5OTl6+eWXtWbNGg0YMEA1NTWSpOLiYoWEhDj8jLe3t1q0aKHi4mKzJjQ01KGm7vFv1dSNX0h6eroCAwPNLSIi4vJOFgAAuLXLuhHc29tbgwYN0pIlS/Tyyy9r3759evLJJxUREaGHH35YRUVFl9XckCFD9Oc//1nR0dEaOHCgli1bps2bN2v16tWXdVxnmDRpksrKyszt0KFDrm4JAABcQZcVmrZs2aK//e1vat26tWbOnKknn3xS3333nbKzs3XkyBHde++9zupTknTttdcqODhY+/btkySFhYXp6NGjDjVnz57ViRMnzPugwsLCVFJS4lBT9/i3an7tXirp53utAgICHDYAANB41Ss0zZw5U9HR0br11lt15MgRvfvuuzp48KBeeOEFRUZG6vbbb1dmZqa2bt3q1GYPHz6sH3/8Ua1bt5YkxcXFqbS0VHl5eWbNqlWrVFtbq9jYWLNm7dq1qq6uNmuys7N1ww036JprrjFrcnJyHJ4rOztbcXFxTu0fAAA0XPUKTfPmzdOwYcN08OBBLV26VHfffbc8PR0PFRISorfeeuuixykvL1d+fr7y8/MlSQcOHFB+fr4KCwtVXl6u8ePHa8OGDfr++++Vk5Oje++9Vx06dFBCQoIkqXPnzurfv78ee+wxbdq0SV999ZVSU1M1ZMgQhYeHS5KGDRsmm82m5ORk7dq1S4sXL9bs2bOVlpZm9jFmzBhlZWVpxowZ2rNnj6ZMmaItW7YoNTW1Pi8PAABohOq15MDevXt/s8ZmsykpKemiNVu2bFGfPn3Mx3VBJikpSfPmzdOOHTv0zjvvqLS0VOHh4erXr5+mTp0qHx8f82cWLFig1NRU9e3bV56enho8eLBeffVVczwwMFCfffaZUlJSFBMTo+DgYE2ePNlhLadbb71VCxcu1LPPPqunn35aHTt21NKlSxUVFWX5NQEAAI1bvULT/Pnz1axZM91///0O+5csWaJTp079Zliqc+edd8owjF8dX7ly5W8eo0WLFlq4cOFFa2666SZ9+eWXF625//77zzsfAACAOvV6ey49PV3BwcHn7Q8JCdE///nPy24KAADA3dQrNBUWFioyMvK8/e3atVNhYeFlNwUAAOBu6hWaQkJCtGPHjvP2b9++XS1btrzspgAAANxNvULT0KFD9fe//11ffPGFampqVFNTo1WrVmnMmDEaMmSIs3sEAABwuXrdCD516lR9//336tu3r7y9fz5EbW2tHn74Ye5pAgAAjVK9QpPNZtPixYs1depUbd++XX5+foqOjla7du2c3R8AAIBbqFdoqnP99dfr+uuvd1YvAAAAbqteoammpkaZmZnKycnR0aNHVVtb6zC+atUqpzQHAADgLuoVmsaMGaPMzEwlJiYqKipKHh4ezu4LAADArdQrNC1atEjvv/++7rrrLmf3AwAA4JbqteSAzWZThw4dnN0LAACA26pXaHriiSc0e/bsi35vHAAAQGNSr7fn1q1bpy+++EKffvqpbrzxRjVp0sRh/IMPPnBKcwAAAO6iXqEpKChI9913n7N7AQAAcFv1Ck3z5893dh8AAABurV73NEnS2bNn9fnnn+s//uM/dPLkSUnSkSNHVF5e7rTmAAAA3EW9rjQdPHhQ/fv3V2FhoSorK/Uv//Ivat68uV5++WVVVlYqIyPD2X0CAAC4VL2uNI0ZM0Y9evTQTz/9JD8/P3P/fffdp5ycHKc1BwAA4C7qdaXpyy+/1Pr162Wz2Rz2t2/fXj/88INTGgMAAHAn9brSVFtbq5qamvP2Hz58WM2bN7/spgAAANxNvUJTv379NGvWLPOxh4eHysvL9dxzz/HVKgAAoFGq19tzM2bMUEJCgrp06aIzZ85o2LBh2rt3r4KDg/Xee+85u0cAAACXq1doatOmjbZv365FixZpx44dKi8vV3JysoYPH+5wYzgAAEBjUa/QJEne3t568MEHndkLAACA26pXaHr33XcvOv7www/XqxkAAAB3Va/QNGbMGIfH1dXVOnXqlGw2m/z9/QlNAACg0anXp+d++uknh628vFwFBQXq3bs3N4IDAIBGqd7fPfdLHTt21EsvvXTeVSgAAIDGwGmhSfr55vAjR44485AAAABuoV73NH388ccOjw3DUFFRkebMmaPbbrvNKY0BAAC4k3qFpoEDBzo89vDwUKtWrfSnP/1JM2bMcEZfAAAAbqVeoam2ttbZfQAAALg1p97TBAAA0FjV60pTWlqa5dqZM2fW5ykAAADcSr1C07Zt27Rt2zZVV1frhhtukCR9++238vLyUvfu3c06Dw8P53QJAADgYvUKTffcc4+aN2+ud955R9dcc42knxe8HDFihG6//XY98cQTTm0SAADA1ep1T9OMGTOUnp5uBiZJuuaaa/TCCy/w6TkAANAo1Ss02e12HTt27Lz9x44d08mTJy+7KQAAAHdTr9B03333acSIEfrggw90+PBhHT58WP/zP/+j5ORkDRo0yNk9AgAAuFy97mnKyMjQk08+qWHDhqm6uvrnA3l7Kzk5WdOnT3dqgwAAAO6gXqHJ399fr7/+uqZPn67vvvtOknTdddepadOmTm0OAADAXVzW4pZFRUUqKipSx44d1bRpUxmG4ay+AAAA3Eq9QtOPP/6ovn376vrrr9ddd92loqIiSVJycjLLDQAAgEapXqFp3LhxatKkiQoLC+Xv72/uf+CBB5SVleW05gAAANxFve5p+uyzz7Ry5Uq1adPGYX/Hjh118OBBpzQGAADgTup1pamiosLhClOdEydOyMfH57KbAgAAcDf1Ck2333673n33XfOxh4eHamtrNW3aNPXp08dpzQEAALiLer09N23aNPXt21dbtmxRVVWVnnrqKe3atUsnTpzQV1995eweAQAAXK5eV5qioqL07bffqnfv3rr33ntVUVGhQYMGadu2bbruuuuc3SMAAIDLXfKVpurqavXv318ZGRl65plnrkRPAAAAbueSrzQ1adJEO3bsuBK9AAAAuK16vT334IMP6q233nJ2LwAAAG6rXjeCnz17Vm+//bY+//xzxcTEnPedczNnznRKcwAAAO7ikkLT/v371b59e+3cuVPdu3eXJH377bcONR4eHs7rDgAAwE1cUmjq2LGjioqK9MUXX0j6+WtTXn31VYWGhl6R5gAAANzFJd3TZBiGw+NPP/1UFRUVTm0IAADAHdXrRvA6vwxRAAAAjdUlhSYPD4/z7lniHiYAAPB7cEn3NBmGoUceecT8Ut4zZ85o1KhR53167oMPPnBehwAAAG7gkkJTUlKSw+MHH3zQqc0AAAC4q0sKTfPnz79SfQAAALi1y7oR/HKtXbtW99xzj8LDw+Xh4aGlS5c6jBuGocmTJ6t169by8/NTfHy89u7d61Bz4sQJDR8+XAEBAQoKClJycrLKy8sdanbs2KHbb79dvr6+ioiI0LRp087rZcmSJerUqZN8fX0VHR2tFStWOP18AQBAw+XS0FRRUaGuXbtq7ty5FxyfNm2aXn31VWVkZGjjxo1q2rSpEhISdObMGbNm+PDh2rVrl7Kzs7Vs2TKtXbtWI0eONMftdrv69eundu3aKS8vT9OnT9eUKVP0xhtvmDXr16/X0KFDlZycrG3btmngwIEaOHCgdu7ceeVOHgAANCgehpusG+Dh4aEPP/xQAwcOlPTzVabw8HA98cQTevLJJyVJZWVlCg0NVWZmpoYMGaLdu3erS5cu2rx5s3r06CFJysrK0l133aXDhw8rPDxc8+bN0zPPPKPi4mLZbDZJ0sSJE7V06VLt2bNH0s+LdFZUVGjZsmVmP7169VK3bt2UkZFhqX+73a7AwECVlZUpICDAWS+LJGnr1q2KiYlR6oLP9YfOXZ167Cvlh93bNWd4vPLy8szV4wEAcDeX8vvbpVeaLubAgQMqLi5WfHy8uS8wMFCxsbHKzc2VJOXm5iooKMgMTJIUHx8vT09Pbdy40ay54447zMAkSQkJCSooKNBPP/1k1pz7PHU1dc9zIZWVlbLb7Q4bAABovNw2NBUXF0vSeV/REhoaao4VFxcrJCTEYdzb21stWrRwqLnQMc59jl+rqRu/kPT0dAUGBppbRETEpZ4iAABoQNw2NLm7SZMmqayszNwOHTrk6pYAAMAV5LahKSwsTJJUUlLisL+kpMQcCwsL09GjRx3Gz549qxMnTjjUXOgY5z7Hr9XUjV+Ij4+PAgICHDYAANB4uW1oioyMVFhYmHJycsx9drtdGzduVFxcnCQpLi5OpaWlysvLM2tWrVql2tpaxcbGmjVr165VdXW1WZOdna0bbrhB11xzjVlz7vPU1dQ9DwAAgEtDU3l5ufLz85Wfny/p55u/8/PzVVhYKA8PD40dO1YvvPCCPv74Y3399dd6+OGHFR4ebn7CrnPnzurfv78ee+wxbdq0SV999ZVSU1M1ZMgQhYeHS5KGDRsmm82m5ORk7dq1S4sXL9bs2bOVlpZm9jFmzBhlZWVpxowZ2rNnj6ZMmaItW7YoNTX1ar8kAADATV3SiuDOtmXLFvXp08d8XBdkkpKSlJmZqaeeekoVFRUaOXKkSktL1bt3b2VlZcnX19f8mQULFig1NVV9+/aVp6enBg8erFdffdUcDwwM1GeffaaUlBTFxMQoODhYkydPdljL6dZbb9XChQv17LPP6umnn1bHjh21dOlSRUVFXYVXAQAANARus05TQ8c6TY5YpwkA0BA0inWaAAAA3AmhCQAAwAJCEwAAgAWEJgAAAAsITQAAABYQmgAAACwgNAEAAFhAaAIAALCA0AQAAGABoQkAAMACQhMAAIAFhCYAAAALCE0AAAAWEJoAAAAsIDQBAABYQGgCAACwgNAEAABgAaEJAADAAkITAACABYQmAAAACwhNAAAAFhCaAAAALCA0AQAAWEBoAgAAsIDQBAAAYAGhCQAAwAJCEwAAgAWEJgAAAAsITQAAABYQmgAAACwgNAEAAFhAaAIAALCA0AQAAGABoQkAAMACQhMAAIAFhCYAAAALCE0AAAAWEJoAAAAsIDQBAABYQGgCAACwgNAEAABgAaEJAADAAkITAACABYQmAAAACwhNAAAAFhCaAAAALCA0AQAAWEBoAgAAsIDQBAAAYAGhCQAAwAJCEwAAgAWEJgAAAAsITQAAABYQmgAAACwgNAEAAFhAaAIAALCA0AQAAGABoQkAAMACQhMAAIAFhCYAAAAL3Do0TZkyRR4eHg5bp06dzPEzZ84oJSVFLVu2VLNmzTR48GCVlJQ4HKOwsFCJiYny9/dXSEiIxo8fr7NnzzrUrF69Wt27d5ePj486dOigzMzMq3F6AACgAXHr0CRJN954o4qKisxt3bp15ti4ceP0ySefaMmSJVqzZo2OHDmiQYMGmeM1NTVKTExUVVWV1q9fr3feeUeZmZmaPHmyWXPgwAElJiaqT58+ys/P19ixY/Xoo49q5cqVV/U8AQCAe/N2dQO/xdvbW2FhYeftLysr01tvvaWFCxfqT3/6kyRp/vz56ty5szZs2KBevXrps88+0zfffKPPP/9coaGh6tatm6ZOnaoJEyZoypQpstlsysjIUGRkpGbMmCFJ6ty5s9atW6dXXnlFCQkJV/VcAQCA+3L7K0179+5VeHi4rr32Wg0fPlyFhYWSpLy8PFVXVys+Pt6s7dSpk9q2bavc3FxJUm5urqKjoxUaGmrWJCQkyG63a9euXWbNuceoq6k7xq+prKyU3W532AAAQOPl1qEpNjZWmZmZysrK0rx583TgwAHdfvvtOnnypIqLi2Wz2RQUFOTwM6GhoSouLpYkFRcXOwSmuvG6sYvV2O12nT59+ld7S09PV2BgoLlFRERc7ukCAAA35tZvzw0YMMD8+0033aTY2Fi1a9dO77//vvz8/FzYmTRp0iSlpaWZj+12O8EJAIBGzK2vNP1SUFCQrr/+eu3bt09hYWGqqqpSaWmpQ01JSYl5D1RYWNh5n6are/xbNQEBARcNZj4+PgoICHDYAABA49WgQlN5ebm+++47tW7dWjExMWrSpIlycnLM8YKCAhUWFiouLk6SFBcXp6+//lpHjx41a7KzsxUQEKAuXbqYNeceo66m7hgAAACSm4emJ598UmvWrNH333+v9evX67777pOXl5eGDh2qwMBAJScnKy0tTV988YXy8vI0YsQIxcXFqVevXpKkfv36qUuXLnrooYe0fft2rVy5Us8++6xSUlLk4+MjSRo1apT279+vp556Snv27NHrr7+u999/X+PGjXPlqQMAADfj1vc0HT58WEOHDtWPP/6oVq1aqXfv3tqwYYNatWolSXrllVfk6empwYMHq7KyUgkJCXr99dfNn/fy8tKyZcs0evRoxcXFqWnTpkpKStLzzz9v1kRGRmr58uUaN26cZs+erTZt2ujNN99kuQEAAODArUPTokWLLjru6+uruXPnau7cub9a065dO61YseKix7nzzju1bdu2evUIAAB+H9z67TkAAAB3QWgCAACwgNAEAABgAaEJAADAAkITAACABYQmAAAACwhNAAAAFhCaAAAALCA0AQAAWEBoAgAAsIDQBAAAYAGhCQAAwAJCEwAAgAWEJgAAAAsITQAAABYQmgAAACwgNAEAAFhAaAIAALCA0AQAAGABoQkAAMACQhMAAIAFhCYAAAALCE0AAAAWEJoAAAAsIDQBAABYQGgCAACwgNAEAABgAaEJAADAAkITAACABYQmAAAACwhNAAAAFhCaAAAALCA0AQAAWEBoAgAAsIDQBAAAYAGhCQAAwAJCEwAAgAWEJgAAAAsITQAAABYQmgAAACwgNAEAAFhAaAIAALCA0AQAAGABoQkAAMACQhMAAIAFhCYAAAALCE0AAAAWEJoAAAAsIDQBAABYQGgCAACwwNvVDQC4PIWFhTp+/Lir27gkwcHBatu2ravbAIBLQmgCGrDCwkJ16txZp0+dcnUrl8TP3197du8mOAFoUAhNQAN2/PhxnT51Sv/vhXkKiezo6nYsOXpgr95/drSOHz9OaALQoBCagEYgJLKj/tC5q6vbAIBGjRvBAQAALCA0AQAAWEBoAgAAsIDQBAAAYAE3ggPnaGhrHu3evdvVLdRbQ+udtaUAEJqA/9VQ1zxqaE4eL5GHp6cefPBBV7dySXx8ffU///3fat26tatbsYygBzgXoekX5s6dq+nTp6u4uFhdu3bVa6+9pp49e7q6rQarIV1N2L17d4Nb86jgqxxlv57u6jYuyemTdhm1tQ3qdT6wbaNWzPyH7r77ble3ckkIeoBzEZrOsXjxYqWlpSkjI0OxsbGaNWuWEhISVFBQoJCQEFe316A01KsJUsNa8+jogb2ubqHeGtrrTNC7OlgtHu6M0HSOmTNn6rHHHtOIESMkSRkZGVq+fLnefvttTZw40cXdNSwN8WpCQ7xqg6uLoHdlsVo83B2h6X9VVVUpLy9PkyZNMvd5enoqPj5eubm559VXVlaqsrLSfFxWViZJstvtTu+tvLxckvTD7h2qOlXh9ONfCce+//kKSPWZ0w2m57NVP89nQ3yd6fnKasg9N6R/g9VnTkuS8vLyzP/3GgJPT0/V1ta6uo1L1hD7DgsLU1hYmFOPWfd72zCM3y42YBiGYfzwww+GJGP9+vUO+8ePH2/07NnzvPrnnnvOkMTGxsbGxsbWCLZDhw79ZlbgSlM9TZo0SWlpaebj2tpanThxQi1btpSHh4dTn8tutysiIkKHDh1SQECAU48Na5gD12MO3APz4HrMgXMZhqGTJ08qPDz8N2sJTf8rODhYXl5eKikpcdhfUlJywUuBPj4+8vHxcdgXFBR0JVtUQEAA/0BcjDlwPebAPTAPrsccOE9gYKClOlYE/182m00xMTHKyckx99XW1ionJ0dxcXEu7AwAALgDrjSdIy0tTUlJSerRo4d69uypWbNmqaKiwvw0HQAA+P0iNJ3jgQce0LFjxzR58mQVFxerW7duysrKUmhoqEv78vHx0XPPPXfe24G4epgD12MO3APz4HrMget4GIaVz9gBAAD8vnFPEwAAgAWEJgAAAAsITQAAABYQmgAAACwgNLm5uXPnqn379vL19VVsbKw2bdrk6pYajfT0dN1yyy1q3ry5QkJCNHDgQBUUFDjUnDlzRikpKWrZsqWaNWumwYMHn7cAamFhoRITE+Xv76+QkBCNHz9eZ8+evZqn0mi89NJL8vDw0NixY819zMGV98MPP+jBBx9Uy5Yt5efnp+joaG3ZssUcNwxDkydPVuvWreXn56f4+Hjt3bvX4RgnTpzQ8OHDFRAQoKCgICUnJzeo749ztZqaGv3jH/9QZGSk/Pz8dN1112nq1KkO34fGPLgBJ3xtG66QRYsWGTabzXj77beNXbt2GY899pgRFBRklJSUuLq1RiEhIcGYP3++sXPnTiM/P9+46667jLZt2xrl5eVmzahRo4yIiAgjJyfH2LJli9GrVy/j1ltvNcfPnj1rREVFGfHx8ca2bduMFStWGMHBwcakSZNccUoN2qZNm4z27dsbN910kzFmzBhzP3NwZZ04ccJo166d8cgjjxgbN2409u/fb6xcudLYt2+fWfPSSy8ZgYGBxtKlS43t27cbf/7zn43IyEjj9OnTZk3//v2Nrl27Ghs2bDC+/PJLo0OHDsbQoUNdcUoN0osvvmi0bNnSWLZsmXHgwAFjyZIlRrNmzYzZs2ebNcyD6xGa3FjPnj2NlJQU83FNTY0RHh5upKenu7Crxuvo0aOGJGPNmjWGYRhGaWmp0aRJE2PJkiVmze7duw1JRm5urmEYhrFixQrD09PTKC4uNmvmzZtnBAQEGJWVlVf3BBqwkydPGh07djSys7ONP/7xj2ZoYg6uvAkTJhi9e/f+1fHa2lojLCzMmD59urmvtLTU8PHxMd577z3DMAzjm2++MSQZmzdvNms+/fRTw8PDw/jhhx+uXPONSGJiovHXv/7VYd+gQYOM4cOHG4bBPLgL3p5zU1VVVcrLy1N8fLy5z9PTU/Hx8crNzXVhZ41XWVmZJKlFixaSpLy8PFVXVzvMQadOndS2bVtzDnJzcxUdHe2wAGpCQoLsdrt27dp1Fbtv2FJSUpSYmOjwWkvMwdXw8ccfq0ePHrr//vsVEhKim2++Wf/5n/9pjh84cEDFxcUOcxAYGKjY2FiHOQgKClKPHj3Mmvj4eHl6emrjxo1X72QasFtvvVU5OTn69ttvJUnbt2/XunXrNGDAAEnMg7tgRXA3dfz4cdXU1Jy3GnloaKj27Nnjoq4ar9raWo0dO1a33XaboqKiJEnFxcWy2WznfRFzaGioiouLzZoLzVHdGH7bokWLtHXrVm3evPm8Mebgytu/f7/mzZuntLQ0Pf3009q8ebP+/ve/y2azKSkpyXwNL/QanzsHISEhDuPe3t5q0aIFc2DRxIkTZbfb1alTJ3l5eammpkYvvviihg8fLknMg5sgNAH6+UrHzp07tW7dOle38rty6NAhjRkzRtnZ2fL19XV1O79LtbW16tGjh/75z39Kkm6++Wbt3LlTGRkZSkpKcnF3vx/vv/++FixYoIULF+rGG29Ufn6+xo4dq/DwcObBjfD2nJsKDg6Wl5fXeZ8SKikpUVhYmIu6apxSU1O1bNkyffHFF2rTpo25PywsTFVVVSotLXWoP3cOwsLCLjhHdWO4uLy8PB09elTdu3eXt7e3vL29tWbNGr366qvy9vZWaGgoc3CFtW7dWl26dHHY17lzZxUWFkr6v9fwYv8XhYWF6ejRow7jZ8+e1YkTJ5gDi8aPH6+JEydqyJAhio6O1kMPPaRx48YpPT1dEvPgLghNbspmsykmJkY5OTnmvtraWuXk5CguLs6FnTUehmEoNTVVH374oVatWqXIyEiH8ZiYGDVp0sRhDgoKClRYWGjOQVxcnL7++muH/6iys7MVEBBw3i8inK9v3776+uuvlZ+fb249evTQ8OHDzb8zB1fWbbfddt5SG99++63atWsnSYqMjFRYWJjDHNjtdm3cuNFhDkpLS5WXl2fWrFq1SrW1tYqNjb0KZ9HwnTp1Sp6ejr+Svby8VFtbK4l5cBuuvhMdv27RokWGj4+PkZmZaXzzzTfGyJEjjaCgIIdPCaH+Ro8ebQQGBhqrV682ioqKzO3UqVNmzahRo4y2bdsaq1atMrZs2WLExcUZcXFx5njdx9379etn5OfnG1lZWUarVq34uPtlOPfTc4bBHFxpmzZtMry9vY0XX3zR2Lt3r7FgwQLD39/f+K//+i+z5qWXXjKCgoKMjz76yNixY4dx7733XvCj7jfffLOxceNGY926dUbHjh35qPslSEpKMv7whz+YSw588MEHRnBwsPHUU0+ZNcyD6xGa3Nxrr71mtG3b1rDZbEbPnj2NDRs2uLqlRkPSBbf58+ebNadPnzb+9re/Gddcc43h7+9v3HfffUZRUZHDcb7//ntjwIABhp+fnxEcHGw88cQTRnV19VU+m8bjl6GJObjyPvnkEyMqKsrw8fExOnXqZLzxxhsO47W1tcY//vEPIzQ01PDx8TH69u1rFBQUONT8+OOPxtChQ41mzZoZAQEBxogRI4yTJ09ezdNo0Ox2uzFmzBijbdu2hq+vr3HttdcazzzzjMOyGcyD63kYxjnLjQIAAOCCuKcJAADAAkITAACABYQmAAAACwhNAAAAFhCaAAAALCA0AQAAWEBoAgAAsIDQBAAAYAGhCQAAwAJCEwAAgAWEJgAAAAsITQAAABb8f3YKO82phcLkAAAAAElFTkSuQmCC\n"},"metadata":{}}],"execution_count":6},{"cell_type":"code","source":"traindf.drop(\"target\", axis=1, inplace=True)\nfor col in traindf.select_dtypes(include=['number']).columns: #handle NaN values by replacing them with median\n    traindf[col] = traindf[col].fillna(traindf[col].median())\n\nfor col in traindf.select_dtypes(include='object').columns:\n    most_frequent = traindf[col].mode()[0]                 #handle NaN values by replacingthem with most frequent values\n    traindf[col] = traindf[col].fillna(most_frequent)    ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-08T19:05:48.877943Z","iopub.execute_input":"2025-01-08T19:05:48.878271Z","iopub.status.idle":"2025-01-08T19:05:48.938509Z","shell.execute_reply.started":"2025-01-08T19:05:48.878240Z","shell.execute_reply":"2025-01-08T19:05:48.937502Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"for col in testdf.select_dtypes(include=['number']).columns:\n    testdf[col] = testdf[col].fillna(testdf[col].median())\n\nfor col in testdf.select_dtypes(include='object').columns:\n    most_frequent = testdf[col].mode()[0]\n    testdf[col] = testdf[col].fillna(most_frequent)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-08T19:05:48.940560Z","iopub.execute_input":"2025-01-08T19:05:48.940794Z","iopub.status.idle":"2025-01-08T19:05:48.969117Z","shell.execute_reply.started":"2025-01-08T19:05:48.940774Z","shell.execute_reply":"2025-01-08T19:05:48.968187Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"def detect_outliers_iqr(df, column):\n    Q1 = df[column].quantile(0.25)  # First quartile (25th percentile)\n    Q3 = df[column].quantile(0.75)  # Third quartile (75th percentile)\n    IQR = Q3 - Q1                   # Interquartile range\n    lower_bound = Q1 - 1.5 * IQR    # Lower bound for outliers\n    upper_bound = Q3 + 1.5 * IQR    # Upper bound for outliers\n    \n    outliers = df[(df[column] < lower_bound) | (df[column] > upper_bound)]\n    return outliers","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-08T19:05:48.970632Z","iopub.execute_input":"2025-01-08T19:05:48.970876Z","iopub.status.idle":"2025-01-08T19:05:48.975544Z","shell.execute_reply.started":"2025-01-08T19:05:48.970857Z","shell.execute_reply":"2025-01-08T19:05:48.974536Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"outlier_summary = {}\nfor col in numeric_columns:\n    if col != 'target':\n        outliers = detect_outliers_iqr(traindf, col)\n        outlier_summary[col] = len(outliers)\n\noutlier_summary_df = pd.DataFrame.from_dict(outlier_summary, orient='index', columns=['Outlier_Count'])\noutlier_summary_df['Outlier_Proportion'] = outlier_summary_df['Outlier_Count'] / len(traindf)\noutlier_summary_df.sort_values(by='Outlier_Proportion', ascending=False).head(10)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-08T19:05:48.976241Z","iopub.execute_input":"2025-01-08T19:05:48.976576Z","iopub.status.idle":"2025-01-08T19:05:49.042665Z","shell.execute_reply.started":"2025-01-08T19:05:48.976553Z","shell.execute_reply":"2025-01-08T19:05:49.041663Z"}},"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"            Outlier_Count  Outlier_Proportion\nfeature_13           3944            0.131467\nfeature_09           3254            0.108467\nfeature_05           3251            0.108367\nfeature_12           3217            0.107233\nfeature_21           3059            0.101967\nfeature_08           2773            0.092433\nfeature_02           2719            0.090633\nfeature_04           2679            0.089300\nfeature_17           2677            0.089233\nfeature_06           2671            0.089033","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Outlier_Count</th>\n      <th>Outlier_Proportion</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>feature_13</th>\n      <td>3944</td>\n      <td>0.131467</td>\n    </tr>\n    <tr>\n      <th>feature_09</th>\n      <td>3254</td>\n      <td>0.108467</td>\n    </tr>\n    <tr>\n      <th>feature_05</th>\n      <td>3251</td>\n      <td>0.108367</td>\n    </tr>\n    <tr>\n      <th>feature_12</th>\n      <td>3217</td>\n      <td>0.107233</td>\n    </tr>\n    <tr>\n      <th>feature_21</th>\n      <td>3059</td>\n      <td>0.101967</td>\n    </tr>\n    <tr>\n      <th>feature_08</th>\n      <td>2773</td>\n      <td>0.092433</td>\n    </tr>\n    <tr>\n      <th>feature_02</th>\n      <td>2719</td>\n      <td>0.090633</td>\n    </tr>\n    <tr>\n      <th>feature_04</th>\n      <td>2679</td>\n      <td>0.089300</td>\n    </tr>\n    <tr>\n      <th>feature_17</th>\n      <td>2677</td>\n      <td>0.089233</td>\n    </tr>\n    <tr>\n      <th>feature_06</th>\n      <td>2671</td>\n      <td>0.089033</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":10},{"cell_type":"code","source":"for col in ['feature_13', 'feature_09', 'feature_21', 'feature_05', 'feature_09']:\n    lower_cap = traindf[col].quantile(0.05)\n    upper_cap = traindf[col].quantile(0.95)\n    traindf[col] = traindf[col].clip(lower=lower_cap, upper=upper_cap)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-08T19:05:49.043613Z","iopub.execute_input":"2025-01-08T19:05:49.043936Z","iopub.status.idle":"2025-01-08T19:05:49.066479Z","shell.execute_reply.started":"2025-01-08T19:05:49.043903Z","shell.execute_reply":"2025-01-08T19:05:49.065495Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"traindf.isna().sum()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-08T19:05:49.067552Z","iopub.execute_input":"2025-01-08T19:05:49.067874Z","iopub.status.idle":"2025-01-08T19:05:49.087441Z","shell.execute_reply.started":"2025-01-08T19:05:49.067828Z","shell.execute_reply":"2025-01-08T19:05:49.086386Z"}},"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"feature_01    0\nfeature_02    0\nfeature_03    0\nfeature_04    0\nfeature_05    0\nfeature_06    0\nfeature_07    0\nfeature_08    0\nfeature_09    0\nfeature_10    0\nfeature_11    0\nfeature_12    0\nfeature_13    0\nfeature_14    0\nfeature_15    0\nfeature_16    0\nfeature_17    0\nfeature_18    0\nfeature_19    0\nfeature_20    0\nfeature_21    0\ndtype: int64"},"metadata":{}}],"execution_count":12},{"cell_type":"code","source":"numeric_columns = traindf.select_dtypes(include=['number']).columns\nfrom sklearn import preprocessing \nmin_max_scaler = preprocessing.MinMaxScaler()\ntrainvardf=min_max_scaler.fit_transform(traindf[numeric_columns])\n#Scaling data to check and compare variances of features","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-08T19:05:49.088364Z","iopub.execute_input":"2025-01-08T19:05:49.088678Z","iopub.status.idle":"2025-01-08T19:05:49.108882Z","shell.execute_reply.started":"2025-01-08T19:05:49.088650Z","shell.execute_reply":"2025-01-08T19:05:49.107787Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"df=pd.DataFrame(trainvardf,columns=numeric_columns) #Checking for monotonic relations between features and target\ndf[\"target\"]=trainY\ndf.corr(method='spearman')[\"target\"]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-08T19:05:49.109828Z","iopub.execute_input":"2025-01-08T19:05:49.110144Z","iopub.status.idle":"2025-01-08T19:05:49.180746Z","shell.execute_reply.started":"2025-01-08T19:05:49.110110Z","shell.execute_reply":"2025-01-08T19:05:49.179884Z"}},"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"feature_01   -0.006534\nfeature_02   -0.000268\nfeature_04    0.336026\nfeature_05   -0.003597\nfeature_06   -0.000944\nfeature_08    0.460693\nfeature_09    0.000872\nfeature_10   -0.001485\nfeature_12   -0.003343\nfeature_13   -0.008672\nfeature_15    0.558059\nfeature_17    0.005597\nfeature_21   -0.006219\ntarget        1.000000\nName: target, dtype: float64"},"metadata":{}}],"execution_count":14},{"cell_type":"code","source":"#Searching for features that have low variance which could be redundant\npd.DataFrame(trainvardf, columns=numeric_columns).var()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-08T19:05:49.181543Z","iopub.execute_input":"2025-01-08T19:05:49.181849Z","iopub.status.idle":"2025-01-08T19:05:49.200088Z","shell.execute_reply.started":"2025-01-08T19:05:49.181825Z","shell.execute_reply":"2025-01-08T19:05:49.199318Z"}},"outputs":[{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"feature_01    0.030039\nfeature_02    0.001277\nfeature_04    0.001955\nfeature_05    0.054341\nfeature_06    0.011801\nfeature_08    0.023644\nfeature_09    0.053731\nfeature_10    0.028935\nfeature_12    0.002554\nfeature_13    0.056149\nfeature_15    0.006937\nfeature_17    0.013943\nfeature_21    0.057301\ndtype: float64"},"metadata":{}}],"execution_count":15},{"cell_type":"code","source":"import seaborn as sns\ncorr=traindf[numeric_columns].corr() #checking for correlation between features (high correlation between 2 variables indicates one of them could be dropped)\nsns.heatmap(corr)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-08T19:05:49.201301Z","iopub.execute_input":"2025-01-08T19:05:49.201668Z","iopub.status.idle":"2025-01-08T19:05:50.087593Z","shell.execute_reply.started":"2025-01-08T19:05:49.201625Z","shell.execute_reply":"2025-01-08T19:05:50.086311Z"}},"outputs":[{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"<Axes: >"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<Figure size 640x480 with 2 Axes>","image/png":"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\n"},"metadata":{}}],"execution_count":16},{"cell_type":"code","source":"corr=traindf[numeric_columns].corr(method='spearman') \nsns.heatmap(corr)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-08T19:05:50.088532Z","iopub.execute_input":"2025-01-08T19:05:50.089000Z","iopub.status.idle":"2025-01-08T19:05:50.524167Z","shell.execute_reply.started":"2025-01-08T19:05:50.088971Z","shell.execute_reply":"2025-01-08T19:05:50.523300Z"}},"outputs":[{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"<Axes: >"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<Figure size 640x480 with 2 Axes>","image/png":"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\n"},"metadata":{}}],"execution_count":17},{"cell_type":"code","source":"columns=traindf.columns\nfrom sklearn.preprocessing import StandardScaler\nscaler=StandardScaler()\nscaled=scaler.fit_transform(traindf[numeric_columns])\nscaled=pd.DataFrame(scaled,columns=numeric_columns)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-08T19:05:50.525143Z","iopub.execute_input":"2025-01-08T19:05:50.525518Z","iopub.status.idle":"2025-01-08T19:05:50.549814Z","shell.execute_reply.started":"2025-01-08T19:05:50.525482Z","shell.execute_reply":"2025-01-08T19:05:50.549181Z"}},"outputs":[],"execution_count":18},{"cell_type":"code","source":"traindf.drop([\"feature_02\",\"feature_09\",\"feature_10\"], axis=1,inplace=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-08T19:05:50.550516Z","iopub.execute_input":"2025-01-08T19:05:50.550791Z","iopub.status.idle":"2025-01-08T19:05:50.558351Z","shell.execute_reply.started":"2025-01-08T19:05:50.550764Z","shell.execute_reply":"2025-01-08T19:05:50.557532Z"}},"outputs":[],"execution_count":19},{"cell_type":"code","source":"testdf.drop([\"feature_02\",\"feature_09\",\"feature_10\"], axis=1,inplace=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-08T19:05:50.559046Z","iopub.execute_input":"2025-01-08T19:05:50.559258Z","iopub.status.idle":"2025-01-08T19:05:50.572899Z","shell.execute_reply.started":"2025-01-08T19:05:50.559233Z","shell.execute_reply":"2025-01-08T19:05:50.572035Z"}},"outputs":[],"execution_count":20},{"cell_type":"code","source":"from sklearn.feature_selection import mutual_info_regression\nnumeric_columns=traindf.select_dtypes(include=[\"number\"]).columns\nmi_scores = mutual_info_regression(scaled, trainY)\nmi_results = pd.DataFrame({'Feature': scaled.columns, 'MI Score': mi_scores})\nprint(mi_results)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-08T19:05:50.573750Z","iopub.execute_input":"2025-01-08T19:05:50.574063Z","iopub.status.idle":"2025-01-08T19:05:53.360491Z","shell.execute_reply.started":"2025-01-08T19:05:50.574043Z","shell.execute_reply":"2025-01-08T19:05:53.359506Z"}},"outputs":[{"name":"stdout","text":"       Feature  MI Score\n0   feature_01  0.000000\n1   feature_02  0.003649\n2   feature_04  0.081218\n3   feature_05  0.000000\n4   feature_06  0.000000\n5   feature_08  0.214434\n6   feature_09  0.000000\n7   feature_10  0.001962\n8   feature_12  0.000000\n9   feature_13  0.000000\n10  feature_15  0.306039\n11  feature_17  0.000000\n12  feature_21  0.000000\n","output_type":"stream"}],"execution_count":21},{"cell_type":"code","source":"traindf.drop([\"feature_01\",\"feature_05\",\"feature_06\",\"feature_12\",\"feature_13\",\"feature_17\",\"feature_21\"], axis=1, inplace=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-08T19:05:53.361466Z","iopub.execute_input":"2025-01-08T19:05:53.361809Z","iopub.status.idle":"2025-01-08T19:05:53.373781Z","shell.execute_reply.started":"2025-01-08T19:05:53.361776Z","shell.execute_reply":"2025-01-08T19:05:53.372834Z"}},"outputs":[],"execution_count":22},{"cell_type":"code","source":"testdf.drop([\"feature_01\",\"feature_05\",\"feature_06\",\"feature_12\",\"feature_13\",\"feature_17\",\"feature_21\"], axis=1, inplace=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-08T19:05:53.380851Z","iopub.execute_input":"2025-01-08T19:05:53.381145Z","iopub.status.idle":"2025-01-08T19:05:53.391003Z","shell.execute_reply.started":"2025-01-08T19:05:53.381114Z","shell.execute_reply":"2025-01-08T19:05:53.389922Z"}},"outputs":[],"execution_count":23},{"cell_type":"code","source":"traindf[categorical_columns].nunique()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-08T19:05:53.393105Z","iopub.execute_input":"2025-01-08T19:05:53.393479Z","iopub.status.idle":"2025-01-08T19:05:53.421957Z","shell.execute_reply.started":"2025-01-08T19:05:53.393422Z","shell.execute_reply":"2025-01-08T19:05:53.421333Z"}},"outputs":[{"execution_count":24,"output_type":"execute_result","data":{"text/plain":"feature_03    6\nfeature_07    6\nfeature_11    4\nfeature_14    4\nfeature_16    5\nfeature_18    8\nfeature_19    5\nfeature_20    6\ndtype: int64"},"metadata":{}}],"execution_count":24},{"cell_type":"code","source":"traindf[\"feature_18\"].unique()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-08T19:05:53.422846Z","iopub.execute_input":"2025-01-08T19:05:53.423146Z","iopub.status.idle":"2025-01-08T19:05:53.429184Z","shell.execute_reply.started":"2025-01-08T19:05:53.423117Z","shell.execute_reply":"2025-01-08T19:05:53.428256Z"}},"outputs":[{"execution_count":25,"output_type":"execute_result","data":{"text/plain":"array(['A2', 'A4', 'A5', 'A8', 'A7', 'A1', 'A3', 'A6'], dtype=object)"},"metadata":{}}],"execution_count":25},{"cell_type":"code","source":"order_dict={\n    \"feature_20\":[\"D1\",\"D2\",\"D3\",\"D4\",\"D5\",\"D6\"],\n    \"feature_07\":[\"B1\",\"B2\",\"B3\",\"B4\",\"B5\",\"B6\"], #ordering features for encoding\n    \"feature_16\":[\"C1\",\"C2\",\"C3\",\"C4\",\"C5\"],\n    \"feature_18\":[\"A1\",\"A2\",\"A3\",\"A4\",\"A5\",\"A6\",\"A7\",\"A8\"]\n}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-08T19:05:53.430507Z","iopub.execute_input":"2025-01-08T19:05:53.430851Z","iopub.status.idle":"2025-01-08T19:05:53.440279Z","shell.execute_reply.started":"2025-01-08T19:05:53.430823Z","shell.execute_reply":"2025-01-08T19:05:53.439422Z"}},"outputs":[],"execution_count":26},{"cell_type":"code","source":"for col, order in order_dict.items():\n    traindf[col] = pd.Categorical(traindf[col], categories=order, ordered=True) \n    traindf[f\"{col}_encoded\"] = traindf[col].cat.codes","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-08T19:05:53.441096Z","iopub.execute_input":"2025-01-08T19:05:53.441372Z","iopub.status.idle":"2025-01-08T19:05:53.481478Z","shell.execute_reply.started":"2025-01-08T19:05:53.441345Z","shell.execute_reply":"2025-01-08T19:05:53.480516Z"}},"outputs":[],"execution_count":27},{"cell_type":"code","source":"for col, order in order_dict.items():\n    testdf[col] = pd.Categorical(testdf[col], categories=order, ordered=True)\n    testdf[f\"{col}_encoded\"] = testdf[col].cat.codes","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-08T19:05:53.482497Z","iopub.execute_input":"2025-01-08T19:05:53.482809Z","iopub.status.idle":"2025-01-08T19:05:53.506275Z","shell.execute_reply.started":"2025-01-08T19:05:53.482781Z","shell.execute_reply":"2025-01-08T19:05:53.505030Z"}},"outputs":[],"execution_count":28},{"cell_type":"code","source":"traindf.drop([\"feature_20\",\"feature_07\",\"feature_16\",\"feature_18\"], axis=1, inplace=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-08T19:05:53.507598Z","iopub.execute_input":"2025-01-08T19:05:53.507887Z","iopub.status.idle":"2025-01-08T19:05:53.523375Z","shell.execute_reply.started":"2025-01-08T19:05:53.507867Z","shell.execute_reply":"2025-01-08T19:05:53.522479Z"}},"outputs":[],"execution_count":29},{"cell_type":"code","source":"testdf.drop([\"feature_20\",\"feature_07\",\"feature_16\",\"feature_18\"], axis=1, inplace=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-08T19:05:53.524314Z","iopub.execute_input":"2025-01-08T19:05:53.524634Z","iopub.status.idle":"2025-01-08T19:05:53.539322Z","shell.execute_reply.started":"2025-01-08T19:05:53.524605Z","shell.execute_reply":"2025-01-08T19:05:53.538319Z"}},"outputs":[],"execution_count":30},{"cell_type":"code","source":"#one-hot encoding remaining categorical feautes","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-08T19:05:53.540151Z","iopub.execute_input":"2025-01-08T19:05:53.540362Z","iopub.status.idle":"2025-01-08T19:05:53.555556Z","shell.execute_reply.started":"2025-01-08T19:05:53.540344Z","shell.execute_reply":"2025-01-08T19:05:53.554705Z"}},"outputs":[],"execution_count":31},{"cell_type":"code","source":"traindf=pd.get_dummies(traindf, columns=['feature_03', 'feature_11',\"feature_14\",\"feature_19\"], drop_first=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-08T19:05:53.556414Z","iopub.execute_input":"2025-01-08T19:05:53.556807Z","iopub.status.idle":"2025-01-08T19:05:53.583853Z","shell.execute_reply.started":"2025-01-08T19:05:53.556774Z","shell.execute_reply":"2025-01-08T19:05:53.583138Z"}},"outputs":[],"execution_count":32},{"cell_type":"code","source":"testdf=pd.get_dummies(testdf, columns=['feature_03', 'feature_11',\"feature_14\",\"feature_19\"], drop_first=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-08T19:05:53.584629Z","iopub.execute_input":"2025-01-08T19:05:53.584833Z","iopub.status.idle":"2025-01-08T19:05:53.596258Z","shell.execute_reply.started":"2025-01-08T19:05:53.584816Z","shell.execute_reply":"2025-01-08T19:05:53.595500Z"}},"outputs":[],"execution_count":33},{"cell_type":"code","source":"for col in traindf.columns:\n    if(any([x in col for x in ['feature_03', 'feature_11',\"feature_14\",\"feature_19\"]])):\n        traindf[col]=traindf[col].map({True:1, False:0})\ntraindf #changing boolean values with integers for model compatibility","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-08T19:05:53.597311Z","iopub.execute_input":"2025-01-08T19:05:53.597616Z","iopub.status.idle":"2025-01-08T19:05:53.648344Z","shell.execute_reply.started":"2025-01-08T19:05:53.597593Z","shell.execute_reply":"2025-01-08T19:05:53.647535Z"}},"outputs":[{"execution_count":34,"output_type":"execute_result","data":{"text/plain":"       feature_04  feature_08  feature_15  feature_20_encoded  \\\n0          -28.35      102.89        5.29                   3   \n1          -14.07      106.68      -12.72                   0   \n2           -8.50       70.79       -3.47                   0   \n3            0.32       90.18       31.65                   0   \n4          -32.25      119.19      -12.25                   0   \n...           ...         ...         ...                 ...   \n29995     7822.04      110.81      -20.34                   0   \n29996       32.65      102.89       -0.16                   3   \n29997        0.32       67.71      411.17                   0   \n29998      -36.70       60.69       13.01                   3   \n29999      -24.78      109.61      -22.83                   0   \n\n       feature_07_encoded  feature_16_encoded  feature_18_encoded  \\\n0                       0                   2                   1   \n1                       2                   0                   3   \n2                       2                   1                   4   \n3                       5                   0                   7   \n4                       4                   0                   6   \n...                   ...                 ...                 ...   \n29995                   1                   2                   1   \n29996                   4                   2                   6   \n29997                   5                   4                   4   \n29998                   5                   3                   6   \n29999                   0                   2                   2   \n\n       feature_03_q  feature_03_r  feature_03_s  ...  feature_11_xy  \\\n0                 0             0             0  ...              1   \n1                 0             0             0  ...              0   \n2                 0             0             0  ...              1   \n3                 1             0             0  ...              0   \n4                 0             0             0  ...              0   \n...             ...           ...           ...  ...            ...   \n29995             0             0             1  ...              0   \n29996             1             0             0  ...              0   \n29997             0             0             1  ...              0   \n29998             0             1             0  ...              0   \n29999             0             0             0  ...              1   \n\n       feature_11_yx  feature_11_yy  feature_14_ij  feature_14_ji  \\\n0                  0              0              1              0   \n1                  0              0              1              0   \n2                  0              0              0              0   \n3                  0              1              0              1   \n4                  0              1              0              0   \n...              ...            ...            ...            ...   \n29995              0              0              0              1   \n29996              0              0              1              0   \n29997              1              0              1              0   \n29998              0              0              0              1   \n29999              0              0              0              1   \n\n       feature_14_jj  feature_19_ab  feature_19_ac  feature_19_ad  \\\n0                  0              1              0              0   \n1                  0              0              1              0   \n2                  0              1              0              0   \n3                  0              0              0              1   \n4                  1              0              0              0   \n...              ...            ...            ...            ...   \n29995              0              0              1              0   \n29996              0              1              0              0   \n29997              0              0              0              0   \n29998              0              0              0              0   \n29999              0              0              0              0   \n\n       feature_19_ae  \n0                  0  \n1                  0  \n2                  0  \n3                  0  \n4                  1  \n...              ...  \n29995              0  \n29996              0  \n29997              0  \n29998              1  \n29999              1  \n\n[30000 rows x 22 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>feature_04</th>\n      <th>feature_08</th>\n      <th>feature_15</th>\n      <th>feature_20_encoded</th>\n      <th>feature_07_encoded</th>\n      <th>feature_16_encoded</th>\n      <th>feature_18_encoded</th>\n      <th>feature_03_q</th>\n      <th>feature_03_r</th>\n      <th>feature_03_s</th>\n      <th>...</th>\n      <th>feature_11_xy</th>\n      <th>feature_11_yx</th>\n      <th>feature_11_yy</th>\n      <th>feature_14_ij</th>\n      <th>feature_14_ji</th>\n      <th>feature_14_jj</th>\n      <th>feature_19_ab</th>\n      <th>feature_19_ac</th>\n      <th>feature_19_ad</th>\n      <th>feature_19_ae</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>-28.35</td>\n      <td>102.89</td>\n      <td>5.29</td>\n      <td>3</td>\n      <td>0</td>\n      <td>2</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>-14.07</td>\n      <td>106.68</td>\n      <td>-12.72</td>\n      <td>0</td>\n      <td>2</td>\n      <td>0</td>\n      <td>3</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>-8.50</td>\n      <td>70.79</td>\n      <td>-3.47</td>\n      <td>0</td>\n      <td>2</td>\n      <td>1</td>\n      <td>4</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.32</td>\n      <td>90.18</td>\n      <td>31.65</td>\n      <td>0</td>\n      <td>5</td>\n      <td>0</td>\n      <td>7</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>-32.25</td>\n      <td>119.19</td>\n      <td>-12.25</td>\n      <td>0</td>\n      <td>4</td>\n      <td>0</td>\n      <td>6</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>29995</th>\n      <td>7822.04</td>\n      <td>110.81</td>\n      <td>-20.34</td>\n      <td>0</td>\n      <td>1</td>\n      <td>2</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>29996</th>\n      <td>32.65</td>\n      <td>102.89</td>\n      <td>-0.16</td>\n      <td>3</td>\n      <td>4</td>\n      <td>2</td>\n      <td>6</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>29997</th>\n      <td>0.32</td>\n      <td>67.71</td>\n      <td>411.17</td>\n      <td>0</td>\n      <td>5</td>\n      <td>4</td>\n      <td>4</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>...</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>29998</th>\n      <td>-36.70</td>\n      <td>60.69</td>\n      <td>13.01</td>\n      <td>3</td>\n      <td>5</td>\n      <td>3</td>\n      <td>6</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>29999</th>\n      <td>-24.78</td>\n      <td>109.61</td>\n      <td>-22.83</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>30000 rows Ã— 22 columns</p>\n</div>"},"metadata":{}}],"execution_count":34},{"cell_type":"code","source":"for col in testdf.columns:\n    if(any([x in col for x in ['feature_03', 'feature_11',\"feature_14\",\"feature_19\"]])):\n        testdf[col]=testdf[col].map({True:1, False:0})\ntraindf","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-08T19:05:53.649237Z","iopub.execute_input":"2025-01-08T19:05:53.649604Z","iopub.status.idle":"2025-01-08T19:05:53.696265Z","shell.execute_reply.started":"2025-01-08T19:05:53.649571Z","shell.execute_reply":"2025-01-08T19:05:53.695380Z"}},"outputs":[{"execution_count":35,"output_type":"execute_result","data":{"text/plain":"       feature_04  feature_08  feature_15  feature_20_encoded  \\\n0          -28.35      102.89        5.29                   3   \n1          -14.07      106.68      -12.72                   0   \n2           -8.50       70.79       -3.47                   0   \n3            0.32       90.18       31.65                   0   \n4          -32.25      119.19      -12.25                   0   \n...           ...         ...         ...                 ...   \n29995     7822.04      110.81      -20.34                   0   \n29996       32.65      102.89       -0.16                   3   \n29997        0.32       67.71      411.17                   0   \n29998      -36.70       60.69       13.01                   3   \n29999      -24.78      109.61      -22.83                   0   \n\n       feature_07_encoded  feature_16_encoded  feature_18_encoded  \\\n0                       0                   2                   1   \n1                       2                   0                   3   \n2                       2                   1                   4   \n3                       5                   0                   7   \n4                       4                   0                   6   \n...                   ...                 ...                 ...   \n29995                   1                   2                   1   \n29996                   4                   2                   6   \n29997                   5                   4                   4   \n29998                   5                   3                   6   \n29999                   0                   2                   2   \n\n       feature_03_q  feature_03_r  feature_03_s  ...  feature_11_xy  \\\n0                 0             0             0  ...              1   \n1                 0             0             0  ...              0   \n2                 0             0             0  ...              1   \n3                 1             0             0  ...              0   \n4                 0             0             0  ...              0   \n...             ...           ...           ...  ...            ...   \n29995             0             0             1  ...              0   \n29996             1             0             0  ...              0   \n29997             0             0             1  ...              0   \n29998             0             1             0  ...              0   \n29999             0             0             0  ...              1   \n\n       feature_11_yx  feature_11_yy  feature_14_ij  feature_14_ji  \\\n0                  0              0              1              0   \n1                  0              0              1              0   \n2                  0              0              0              0   \n3                  0              1              0              1   \n4                  0              1              0              0   \n...              ...            ...            ...            ...   \n29995              0              0              0              1   \n29996              0              0              1              0   \n29997              1              0              1              0   \n29998              0              0              0              1   \n29999              0              0              0              1   \n\n       feature_14_jj  feature_19_ab  feature_19_ac  feature_19_ad  \\\n0                  0              1              0              0   \n1                  0              0              1              0   \n2                  0              1              0              0   \n3                  0              0              0              1   \n4                  1              0              0              0   \n...              ...            ...            ...            ...   \n29995              0              0              1              0   \n29996              0              1              0              0   \n29997              0              0              0              0   \n29998              0              0              0              0   \n29999              0              0              0              0   \n\n       feature_19_ae  \n0                  0  \n1                  0  \n2                  0  \n3                  0  \n4                  1  \n...              ...  \n29995              0  \n29996              0  \n29997              0  \n29998              1  \n29999              1  \n\n[30000 rows x 22 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>feature_04</th>\n      <th>feature_08</th>\n      <th>feature_15</th>\n      <th>feature_20_encoded</th>\n      <th>feature_07_encoded</th>\n      <th>feature_16_encoded</th>\n      <th>feature_18_encoded</th>\n      <th>feature_03_q</th>\n      <th>feature_03_r</th>\n      <th>feature_03_s</th>\n      <th>...</th>\n      <th>feature_11_xy</th>\n      <th>feature_11_yx</th>\n      <th>feature_11_yy</th>\n      <th>feature_14_ij</th>\n      <th>feature_14_ji</th>\n      <th>feature_14_jj</th>\n      <th>feature_19_ab</th>\n      <th>feature_19_ac</th>\n      <th>feature_19_ad</th>\n      <th>feature_19_ae</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>-28.35</td>\n      <td>102.89</td>\n      <td>5.29</td>\n      <td>3</td>\n      <td>0</td>\n      <td>2</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>-14.07</td>\n      <td>106.68</td>\n      <td>-12.72</td>\n      <td>0</td>\n      <td>2</td>\n      <td>0</td>\n      <td>3</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>-8.50</td>\n      <td>70.79</td>\n      <td>-3.47</td>\n      <td>0</td>\n      <td>2</td>\n      <td>1</td>\n      <td>4</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.32</td>\n      <td>90.18</td>\n      <td>31.65</td>\n      <td>0</td>\n      <td>5</td>\n      <td>0</td>\n      <td>7</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>-32.25</td>\n      <td>119.19</td>\n      <td>-12.25</td>\n      <td>0</td>\n      <td>4</td>\n      <td>0</td>\n      <td>6</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>29995</th>\n      <td>7822.04</td>\n      <td>110.81</td>\n      <td>-20.34</td>\n      <td>0</td>\n      <td>1</td>\n      <td>2</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>29996</th>\n      <td>32.65</td>\n      <td>102.89</td>\n      <td>-0.16</td>\n      <td>3</td>\n      <td>4</td>\n      <td>2</td>\n      <td>6</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>29997</th>\n      <td>0.32</td>\n      <td>67.71</td>\n      <td>411.17</td>\n      <td>0</td>\n      <td>5</td>\n      <td>4</td>\n      <td>4</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>...</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>29998</th>\n      <td>-36.70</td>\n      <td>60.69</td>\n      <td>13.01</td>\n      <td>3</td>\n      <td>5</td>\n      <td>3</td>\n      <td>6</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>29999</th>\n      <td>-24.78</td>\n      <td>109.61</td>\n      <td>-22.83</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>30000 rows Ã— 22 columns</p>\n</div>"},"metadata":{}}],"execution_count":35},{"cell_type":"code","source":"mi_scores = mutual_info_regression(traindf, trainY)\nmi_results = pd.DataFrame({'Feature': traindf.columns, 'MI Score': mi_scores})\nprint(mi_results) #checking mutual info to see which features are more effective","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-08T19:05:53.697150Z","iopub.execute_input":"2025-01-08T19:05:53.697514Z","iopub.status.idle":"2025-01-08T19:05:58.385672Z","shell.execute_reply.started":"2025-01-08T19:05:53.697488Z","shell.execute_reply":"2025-01-08T19:05:58.384895Z"}},"outputs":[{"name":"stdout","text":"               Feature  MI Score\n0           feature_04  0.081195\n1           feature_08  0.214562\n2           feature_15  0.306185\n3   feature_20_encoded  0.002987\n4   feature_07_encoded  0.001570\n5   feature_16_encoded  0.004454\n6   feature_18_encoded  0.001381\n7         feature_03_q  0.000766\n8         feature_03_r  0.000000\n9         feature_03_s  0.000201\n10        feature_03_t  0.000000\n11        feature_03_u  0.001871\n12       feature_11_xy  0.000000\n13       feature_11_yx  0.000000\n14       feature_11_yy  0.000742\n15       feature_14_ij  0.002189\n16       feature_14_ji  0.000000\n17       feature_14_jj  0.001492\n18       feature_19_ab  0.000585\n19       feature_19_ac  0.000000\n20       feature_19_ad  0.000000\n21       feature_19_ae  0.000000\n","output_type":"stream"}],"execution_count":36},{"cell_type":"code","source":"traindf.drop([\"feature_19_ae\",\"feature_19_ad\",\"feature_19_ac\",\"feature_11_yx\",\"feature_11_xy\",\"feature_03_t\",\"feature_03_s\",\"feature_03_r\"], axis=1, inplace=True)\ntraindf","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-08T19:05:58.386516Z","iopub.execute_input":"2025-01-08T19:05:58.386781Z","iopub.status.idle":"2025-01-08T19:05:58.405663Z","shell.execute_reply.started":"2025-01-08T19:05:58.386749Z","shell.execute_reply":"2025-01-08T19:05:58.404553Z"}},"outputs":[{"execution_count":37,"output_type":"execute_result","data":{"text/plain":"       feature_04  feature_08  feature_15  feature_20_encoded  \\\n0          -28.35      102.89        5.29                   3   \n1          -14.07      106.68      -12.72                   0   \n2           -8.50       70.79       -3.47                   0   \n3            0.32       90.18       31.65                   0   \n4          -32.25      119.19      -12.25                   0   \n...           ...         ...         ...                 ...   \n29995     7822.04      110.81      -20.34                   0   \n29996       32.65      102.89       -0.16                   3   \n29997        0.32       67.71      411.17                   0   \n29998      -36.70       60.69       13.01                   3   \n29999      -24.78      109.61      -22.83                   0   \n\n       feature_07_encoded  feature_16_encoded  feature_18_encoded  \\\n0                       0                   2                   1   \n1                       2                   0                   3   \n2                       2                   1                   4   \n3                       5                   0                   7   \n4                       4                   0                   6   \n...                   ...                 ...                 ...   \n29995                   1                   2                   1   \n29996                   4                   2                   6   \n29997                   5                   4                   4   \n29998                   5                   3                   6   \n29999                   0                   2                   2   \n\n       feature_03_q  feature_03_u  feature_11_yy  feature_14_ij  \\\n0                 0             1              0              1   \n1                 0             1              0              1   \n2                 0             1              0              0   \n3                 1             0              1              0   \n4                 0             0              1              0   \n...             ...           ...            ...            ...   \n29995             0             0              0              0   \n29996             1             0              0              1   \n29997             0             0              0              1   \n29998             0             0              0              0   \n29999             0             1              0              0   \n\n       feature_14_ji  feature_14_jj  feature_19_ab  \n0                  0              0              1  \n1                  0              0              0  \n2                  0              0              1  \n3                  1              0              0  \n4                  0              1              0  \n...              ...            ...            ...  \n29995              1              0              0  \n29996              0              0              1  \n29997              0              0              0  \n29998              1              0              0  \n29999              1              0              0  \n\n[30000 rows x 14 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>feature_04</th>\n      <th>feature_08</th>\n      <th>feature_15</th>\n      <th>feature_20_encoded</th>\n      <th>feature_07_encoded</th>\n      <th>feature_16_encoded</th>\n      <th>feature_18_encoded</th>\n      <th>feature_03_q</th>\n      <th>feature_03_u</th>\n      <th>feature_11_yy</th>\n      <th>feature_14_ij</th>\n      <th>feature_14_ji</th>\n      <th>feature_14_jj</th>\n      <th>feature_19_ab</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>-28.35</td>\n      <td>102.89</td>\n      <td>5.29</td>\n      <td>3</td>\n      <td>0</td>\n      <td>2</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>-14.07</td>\n      <td>106.68</td>\n      <td>-12.72</td>\n      <td>0</td>\n      <td>2</td>\n      <td>0</td>\n      <td>3</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>-8.50</td>\n      <td>70.79</td>\n      <td>-3.47</td>\n      <td>0</td>\n      <td>2</td>\n      <td>1</td>\n      <td>4</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.32</td>\n      <td>90.18</td>\n      <td>31.65</td>\n      <td>0</td>\n      <td>5</td>\n      <td>0</td>\n      <td>7</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>-32.25</td>\n      <td>119.19</td>\n      <td>-12.25</td>\n      <td>0</td>\n      <td>4</td>\n      <td>0</td>\n      <td>6</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>29995</th>\n      <td>7822.04</td>\n      <td>110.81</td>\n      <td>-20.34</td>\n      <td>0</td>\n      <td>1</td>\n      <td>2</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>29996</th>\n      <td>32.65</td>\n      <td>102.89</td>\n      <td>-0.16</td>\n      <td>3</td>\n      <td>4</td>\n      <td>2</td>\n      <td>6</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>29997</th>\n      <td>0.32</td>\n      <td>67.71</td>\n      <td>411.17</td>\n      <td>0</td>\n      <td>5</td>\n      <td>4</td>\n      <td>4</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>29998</th>\n      <td>-36.70</td>\n      <td>60.69</td>\n      <td>13.01</td>\n      <td>3</td>\n      <td>5</td>\n      <td>3</td>\n      <td>6</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>29999</th>\n      <td>-24.78</td>\n      <td>109.61</td>\n      <td>-22.83</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2</td>\n      <td>2</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>30000 rows Ã— 14 columns</p>\n</div>"},"metadata":{}}],"execution_count":37},{"cell_type":"code","source":"testdf.drop([\"feature_19_ae\",\"feature_19_ad\",\"feature_19_ac\",\"feature_11_yx\",\"feature_11_xy\",\"feature_03_t\",\"feature_03_s\",\"feature_03_r\"], axis=1, inplace=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-08T19:05:58.406773Z","iopub.execute_input":"2025-01-08T19:05:58.407091Z","iopub.status.idle":"2025-01-08T19:05:58.412673Z","shell.execute_reply.started":"2025-01-08T19:05:58.407063Z","shell.execute_reply":"2025-01-08T19:05:58.411758Z"}},"outputs":[],"execution_count":38},{"cell_type":"code","source":"scaler = StandardScaler()\ntraindf = scaler.fit_transform(traindf)  \ntestdf = scaler.transform(testdf)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-08T19:05:58.413890Z","iopub.execute_input":"2025-01-08T19:05:58.414235Z","iopub.status.idle":"2025-01-08T19:05:58.441373Z","shell.execute_reply.started":"2025-01-08T19:05:58.414211Z","shell.execute_reply":"2025-01-08T19:05:58.440503Z"}},"outputs":[],"execution_count":39},{"cell_type":"code","source":"from sklearn.svm import SVR\nfrom sklearn.preprocessing import PolynomialFeatures\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_squared_error\n\nX_train, X_test, y_train, y_test = train_test_split(traindf, trainY, test_size=0.2, random_state=42)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-08T19:05:58.442240Z","iopub.execute_input":"2025-01-08T19:05:58.442499Z","iopub.status.idle":"2025-01-08T19:05:58.453170Z","shell.execute_reply.started":"2025-01-08T19:05:58.442474Z","shell.execute_reply":"2025-01-08T19:05:58.452404Z"}},"outputs":[],"execution_count":40},{"cell_type":"code","source":"traindf","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-08T19:05:58.453969Z","iopub.execute_input":"2025-01-08T19:05:58.454236Z","iopub.status.idle":"2025-01-08T19:05:58.465322Z","shell.execute_reply.started":"2025-01-08T19:05:58.454201Z","shell.execute_reply":"2025-01-08T19:05:58.464531Z"}},"outputs":[{"execution_count":41,"output_type":"execute_result","data":{"text/plain":"array([[-0.02832855, -0.29816053,  0.01266248, ..., -0.65262798,\n        -0.5008332 ,  2.1317274 ],\n       [-0.0154243 , -0.29659351, -0.01776942, ..., -0.65262798,\n        -0.5008332 , -0.46910313],\n       [-0.01039092, -0.31143261, -0.00213949, ..., -0.65262798,\n        -0.5008332 ,  2.1317274 ],\n       ...,\n       [-0.00242065, -0.31270607,  0.69848698, ..., -0.65262798,\n        -0.5008332 , -0.46910313],\n       [-0.03587411, -0.31560856,  0.02570714, ...,  1.53226651,\n        -0.5008332 , -0.46910313],\n       [-0.02510249, -0.29538207, -0.03485251, ...,  1.53226651,\n        -0.5008332 , -0.46910313]])"},"metadata":{}}],"execution_count":41},{"cell_type":"code","source":"from sklearn.pipeline import Pipeline\npipeline = Pipeline([\n    ('scaler', StandardScaler()),\n    ('svr', SVR(kernel='rbf', C=10, epsilon=0.1))\n])\n\npipeline.fit(X_train, y_train)\ny_pred_pipeline = pipeline.predict(X_test)\nmse_pipeline = mean_squared_error(y_test, y_pred_pipeline)\nprint(f\"Pipeline SVR Mean Squared Error: {mse_pipeline}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-07T20:25:16.222095Z","iopub.status.idle":"2025-01-07T20:25:16.222371Z","shell.execute_reply":"2025-01-07T20:25:16.222255Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.model_selection import GridSearchCV\n\nparam_grid = {\n    'C': [0.1, 1, 10, 15, 20],\n    'epsilon': [0.01,0.1, 0.2, 0.5,1],\n    'kernel': ['rbf', 'poly']\n}\n\ngrid_search = GridSearchCV(SVR(), param_grid, cv=5, scoring='neg_mean_squared_error')\ngrid_search.fit(X_train, y_train)\n\nprint(\"Best parameters:\", grid_search.best_params_)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-07T20:25:16.222948Z","iopub.status.idle":"2025-01-07T20:25:16.223314Z","shell.execute_reply":"2025-01-07T20:25:16.223130Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"best_svr_model = grid_search.best_estimator_\ny_pred = best_svr_model.predict(X_test)\nmse = mean_squared_error(y_test, y_pred)\nprint(f\"Mean Squared Error: {mse}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-07T20:25:16.224741Z","iopub.status.idle":"2025-01-07T20:25:16.225101Z","shell.execute_reply":"2025-01-07T20:25:16.224974Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"poly = PolynomialFeatures(degree=2)\nX_train_poly = poly.fit_transform(X_train)\nX_test_poly = poly.transform(X_test)\n\npoly_model = LinearRegression()\npoly_model.fit(X_train_poly, y_train)\n\ny_pred = poly_model.predict(X_test_poly)\n\nmse = mean_squared_error(y_test, y_pred)\nprint(f\"Mean Squared Error: {mse}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-07T20:25:16.225881Z","iopub.status.idle":"2025-01-07T20:25:16.226240Z","shell.execute_reply":"2025-01-07T20:25:16.226086Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"linear_model = LinearRegression()\nlinear_model.fit(X_train, y_train)\n\ny_pred = linear_model.predict(X_test)\n\nmse = mean_squared_error(y_test, y_pred)\nprint(f\"Mean Squared Error: {mse}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-07T20:25:16.227201Z","iopub.status.idle":"2025-01-07T20:25:16.227669Z","shell.execute_reply":"2025-01-07T20:25:16.227471Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras.callbacks import ModelCheckpoint\nfrom tensorflow.keras import layers, regularizers, optimizers, callbacks\n\ncheckpoint = ModelCheckpoint(\n    filepath=\"/kaggle/working/weights.keras\",\n    monitor=\"val_loss\",        \n    save_best_only=True,\n    mode=\"min\",                \n    verbose=1                  \n)\n\nmodel = tf.keras.Sequential([\n    layers.InputLayer(shape=(14,)),  \n    layers.Dense(units=140, activation=\"relu\", kernel_regularizer=regularizers.l2(0.01)),#kernel regularizer for preventing overfitting\n    layers.BatchNormalization(), #for more stable activation\n    layers.Dropout(0.3), #dropout for preventing overfitting\n    layers.Dense(units=90, activation=\"relu\", kernel_regularizer=regularizers.l2(0.01)),\n    layers.BatchNormalization(), \n    layers.Dropout(0.3), \n    layers.Dense(units=16, activation=\"relu\", kernel_regularizer=regularizers.l2(0.01)),\n    layers.Dense(units=1)  \n])\n\nmodel.compile(\n    optimizer=optimizers.RMSprop(learning_rate=0.0001, momentum=0.15),\n    loss=\"mse\",\n    metrics=[\"mse\"])  \n\n\nhistory = model.fit(X_train, y_train, validation_data=(X_test, y_test),\n                    batch_size=80, epochs=1200, callbacks=[checkpoint])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-08T21:32:14.398224Z","iopub.execute_input":"2025-01-08T21:32:14.398677Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/1200\n\u001b[1m294/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1718200.6250 - mse: 1718199.1250\nEpoch 1: val_loss improved from inf to 1739760.50000, saving model to /kaggle/working/weights.keras\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 1718119.6250 - mse: 1718118.0000 - val_loss: 1739760.5000 - val_mse: 1739758.7500\nEpoch 2/1200\n\u001b[1m294/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1697202.0000 - mse: 1697200.5000\nEpoch 2: val_loss improved from 1739760.50000 to 1726954.87500, saving model to /kaggle/working/weights.keras\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1697418.6250 - mse: 1697417.1250 - val_loss: 1726954.8750 - val_mse: 1726953.5000\nEpoch 3/1200\n\u001b[1m291/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1699011.3750 - mse: 1699009.7500\nEpoch 3: val_loss improved from 1726954.87500 to 1713616.50000, saving model to /kaggle/working/weights.keras\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1698932.5000 - mse: 1698930.7500 - val_loss: 1713616.5000 - val_mse: 1713614.6250\nEpoch 4/1200\n\u001b[1m291/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1684434.2500 - mse: 1684432.2500\nEpoch 4: val_loss improved from 1713616.50000 to 1696582.50000, saving model to /kaggle/working/weights.keras\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1684263.3750 - mse: 1684261.5000 - val_loss: 1696582.5000 - val_mse: 1696581.0000\nEpoch 5/1200\n\u001b[1m293/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1662655.1250 - mse: 1662653.3750\nEpoch 5: val_loss improved from 1696582.50000 to 1674982.37500, saving model to /kaggle/working/weights.keras\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1662584.8750 - mse: 1662583.1250 - val_loss: 1674982.3750 - val_mse: 1674980.5000\nEpoch 6/1200\n\u001b[1m291/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1642036.1250 - mse: 1642033.8750\nEpoch 6: val_loss improved from 1674982.37500 to 1649690.62500, saving model to /kaggle/working/weights.keras\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1641951.5000 - mse: 1641949.2500 - val_loss: 1649690.6250 - val_mse: 1649688.8750\nEpoch 7/1200\n\u001b[1m293/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1623200.6250 - mse: 1623198.7500\nEpoch 7: val_loss improved from 1649690.62500 to 1618001.37500, saving model to /kaggle/working/weights.keras\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1622869.6250 - mse: 1622867.8750 - val_loss: 1618001.3750 - val_mse: 1617999.3750\nEpoch 8/1200\n\u001b[1m291/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1591356.2500 - mse: 1591353.6250\nEpoch 8: val_loss improved from 1618001.37500 to 1579526.00000, saving model to /kaggle/working/weights.keras\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1590885.5000 - mse: 1590882.7500 - val_loss: 1579526.0000 - val_mse: 1579523.1250\nEpoch 9/1200\n\u001b[1m289/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1565331.6250 - mse: 1565329.3750\nEpoch 9: val_loss improved from 1579526.00000 to 1537610.75000, saving model to /kaggle/working/weights.keras\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1564293.7500 - mse: 1564291.3750 - val_loss: 1537610.7500 - val_mse: 1537607.8750\nEpoch 10/1200\n\u001b[1m288/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1523944.3750 - mse: 1523942.1250\nEpoch 10: val_loss improved from 1537610.75000 to 1487250.62500, saving model to /kaggle/working/weights.keras\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1522606.7500 - mse: 1522604.6250 - val_loss: 1487250.6250 - val_mse: 1487247.8750\nEpoch 11/1200\n\u001b[1m291/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1453909.0000 - mse: 1453906.1250\nEpoch 11: val_loss improved from 1487250.62500 to 1432152.87500, saving model to /kaggle/working/weights.keras\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1453519.7500 - mse: 1453516.8750 - val_loss: 1432152.8750 - val_mse: 1432150.0000\nEpoch 12/1200\n\u001b[1m297/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1398063.1250 - mse: 1398060.5000\nEpoch 12: val_loss improved from 1432152.87500 to 1371227.50000, saving model to /kaggle/working/weights.keras\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1397882.6250 - mse: 1397880.1250 - val_loss: 1371227.5000 - val_mse: 1371224.6250\nEpoch 13/1200\n\u001b[1m294/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1327946.5000 - mse: 1327943.0000\nEpoch 13: val_loss improved from 1371227.50000 to 1300121.37500, saving model to /kaggle/working/weights.keras\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1327807.5000 - mse: 1327804.0000 - val_loss: 1300121.3750 - val_mse: 1300118.1250\nEpoch 14/1200\n\u001b[1m285/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1265256.5000 - mse: 1265253.0000\nEpoch 14: val_loss improved from 1300121.37500 to 1229594.87500, saving model to /kaggle/working/weights.keras\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1264778.3750 - mse: 1264774.7500 - val_loss: 1229594.8750 - val_mse: 1229591.7500\nEpoch 15/1200\n\u001b[1m292/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1202223.2500 - mse: 1202219.0000\nEpoch 15: val_loss improved from 1229594.87500 to 1155584.37500, saving model to /kaggle/working/weights.keras\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1201604.6250 - mse: 1201600.5000 - val_loss: 1155584.3750 - val_mse: 1155580.2500\nEpoch 16/1200\n\u001b[1m297/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1135637.8750 - mse: 1135633.6250\nEpoch 16: val_loss improved from 1155584.37500 to 1081729.50000, saving model to /kaggle/working/weights.keras\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1135304.2500 - mse: 1135300.0000 - val_loss: 1081729.5000 - val_mse: 1081725.1250\nEpoch 17/1200\n\u001b[1m281/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1057175.7500 - mse: 1057171.0000\nEpoch 17: val_loss improved from 1081729.50000 to 1002691.68750, saving model to /kaggle/working/weights.keras\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1055976.5000 - mse: 1055971.7500 - val_loss: 1002691.6875 - val_mse: 1002687.0000\nEpoch 18/1200\n\u001b[1m276/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 990471.1250 - mse: 990466.0625\nEpoch 18: val_loss improved from 1002691.68750 to 925385.12500, saving model to /kaggle/working/weights.keras\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 988307.8750 - mse: 988302.7500 - val_loss: 925385.1250 - val_mse: 925379.9375\nEpoch 19/1200\n\u001b[1m277/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 915728.0625 - mse: 915722.7500\nEpoch 19: val_loss improved from 925385.12500 to 844139.87500, saving model to /kaggle/working/weights.keras\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 913531.5625 - mse: 913526.1875 - val_loss: 844139.8750 - val_mse: 844134.3750\nEpoch 20/1200\n\u001b[1m291/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 831417.3750 - mse: 831411.6875\nEpoch 20: val_loss improved from 844139.87500 to 761511.50000, saving model to /kaggle/working/weights.keras\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 830682.3750 - mse: 830676.6875 - val_loss: 761511.5000 - val_mse: 761505.3750\nEpoch 21/1200\n\u001b[1m291/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 753634.1250 - mse: 753627.9375\nEpoch 21: val_loss improved from 761511.50000 to 687893.87500, saving model to /kaggle/working/weights.keras\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 752830.1875 - mse: 752824.0000 - val_loss: 687893.8750 - val_mse: 687887.3125\nEpoch 22/1200\n\u001b[1m292/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 678103.5000 - mse: 678096.8750\nEpoch 22: val_loss improved from 687893.87500 to 628000.00000, saving model to /kaggle/working/weights.keras\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 677717.1250 - mse: 677710.5625 - val_loss: 628000.0000 - val_mse: 627992.9375\nEpoch 23/1200\n\u001b[1m290/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 624970.6250 - mse: 624963.3125\nEpoch 23: val_loss improved from 628000.00000 to 581504.12500, saving model to /kaggle/working/weights.keras\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 624459.0000 - mse: 624451.6875 - val_loss: 581504.1250 - val_mse: 581496.5625\nEpoch 24/1200\n\u001b[1m289/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 576831.5625 - mse: 576824.0625\nEpoch 24: val_loss improved from 581504.12500 to 547044.68750, saving model to /kaggle/working/weights.keras\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 576567.7500 - mse: 576560.3125 - val_loss: 547044.6875 - val_mse: 547036.6875\nEpoch 25/1200\n\u001b[1m295/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 540895.7500 - mse: 540887.6250\nEpoch 25: val_loss improved from 547044.68750 to 519538.59375, saving model to /kaggle/working/weights.keras\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 540917.6250 - mse: 540909.5625 - val_loss: 519538.5938 - val_mse: 519530.2500\nEpoch 26/1200\n\u001b[1m285/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 523001.4688 - mse: 522993.2188\nEpoch 26: val_loss improved from 519538.59375 to 499350.28125, saving model to /kaggle/working/weights.keras\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 522722.7188 - mse: 522714.4375 - val_loss: 499350.2812 - val_mse: 499341.7812\nEpoch 27/1200\n\u001b[1m283/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 508108.9688 - mse: 508100.3125\nEpoch 27: val_loss improved from 499350.28125 to 483107.12500, saving model to /kaggle/working/weights.keras\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 507670.9375 - mse: 507662.2812 - val_loss: 483107.1250 - val_mse: 483098.1875\nEpoch 28/1200\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 495431.6562 - mse: 495422.7500\nEpoch 28: val_loss improved from 483107.12500 to 469974.21875, saving model to /kaggle/working/weights.keras\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 495396.4375 - mse: 495387.5625 - val_loss: 469974.2188 - val_mse: 469965.2812\nEpoch 29/1200\n\u001b[1m289/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 478250.1875 - mse: 478241.1562\nEpoch 29: val_loss improved from 469974.21875 to 458327.12500, saving model to /kaggle/working/weights.keras\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 477996.4375 - mse: 477987.3750 - val_loss: 458327.1250 - val_mse: 458317.8125\nEpoch 30/1200\n\u001b[1m288/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 463354.8438 - mse: 463345.7188\nEpoch 30: val_loss improved from 458327.12500 to 449135.03125, saving model to /kaggle/working/weights.keras\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 463340.6875 - mse: 463331.5938 - val_loss: 449135.0312 - val_mse: 449125.6875\nEpoch 31/1200\n\u001b[1m284/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 450572.5938 - mse: 450563.1875\nEpoch 31: val_loss improved from 449135.03125 to 442721.53125, saving model to /kaggle/working/weights.keras\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 450827.8750 - mse: 450818.4375 - val_loss: 442721.5312 - val_mse: 442712.0938\nEpoch 32/1200\n\u001b[1m287/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 449549.9062 - mse: 449540.2812\nEpoch 32: val_loss improved from 442721.53125 to 438002.46875, saving model to /kaggle/working/weights.keras\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 449609.0938 - mse: 449599.4688 - val_loss: 438002.4688 - val_mse: 437992.9062\nEpoch 33/1200\n\u001b[1m291/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 441082.3750 - mse: 441072.8438\nEpoch 33: val_loss improved from 438002.46875 to 434230.53125, saving model to /kaggle/working/weights.keras\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 441243.5312 - mse: 441234.0312 - val_loss: 434230.5312 - val_mse: 434220.8750\nEpoch 34/1200\n\u001b[1m285/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 445291.3125 - mse: 445281.5312\nEpoch 34: val_loss improved from 434230.53125 to 431680.90625, saving model to /kaggle/working/weights.keras\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 445299.6875 - mse: 445289.9375 - val_loss: 431680.9062 - val_mse: 431671.2500\nEpoch 35/1200\n\u001b[1m286/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 433492.1250 - mse: 433482.5312\nEpoch 35: val_loss improved from 431680.90625 to 430019.59375, saving model to /kaggle/working/weights.keras\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 433924.9688 - mse: 433915.3750 - val_loss: 430019.5938 - val_mse: 430009.9375\nEpoch 36/1200\n\u001b[1m289/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 440788.3125 - mse: 440778.5312\nEpoch 36: val_loss improved from 430019.59375 to 428174.71875, saving model to /kaggle/working/weights.keras\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 440808.0938 - mse: 440798.3125 - val_loss: 428174.7188 - val_mse: 428164.9062\nEpoch 37/1200\n\u001b[1m295/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 433811.5625 - mse: 433801.7812\nEpoch 37: val_loss improved from 428174.71875 to 426977.15625, saving model to /kaggle/working/weights.keras\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 433906.6250 - mse: 433896.8438 - val_loss: 426977.1562 - val_mse: 426967.2188\nEpoch 38/1200\n\u001b[1m288/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 429609.2188 - mse: 429599.4062\nEpoch 38: val_loss improved from 426977.15625 to 425858.93750, saving model to /kaggle/working/weights.keras\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 429908.0938 - mse: 429898.3125 - val_loss: 425858.9375 - val_mse: 425849.1875\nEpoch 39/1200\n\u001b[1m288/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 436765.5625 - mse: 436755.7188\nEpoch 39: val_loss improved from 425858.93750 to 424226.18750, saving model to /kaggle/working/weights.keras\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 436855.5000 - mse: 436845.6562 - val_loss: 424226.1875 - val_mse: 424216.3750\nEpoch 40/1200\n\u001b[1m290/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 437083.4688 - mse: 437073.5938\nEpoch 40: val_loss improved from 424226.18750 to 423276.93750, saving model to /kaggle/working/weights.keras\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 437049.0625 - mse: 437039.1875 - val_loss: 423276.9375 - val_mse: 423267.0000\nEpoch 41/1200\n\u001b[1m286/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 429325.6250 - mse: 429315.8125\nEpoch 41: val_loss improved from 423276.93750 to 422041.09375, saving model to /kaggle/working/weights.keras\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 429537.4375 - mse: 429527.6250 - val_loss: 422041.0938 - val_mse: 422031.2188\nEpoch 42/1200\n\u001b[1m294/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 434774.8438 - mse: 434765.0938\nEpoch 42: val_loss improved from 422041.09375 to 420880.37500, saving model to /kaggle/working/weights.keras\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 434758.6875 - mse: 434748.9062 - val_loss: 420880.3750 - val_mse: 420870.5312\nEpoch 43/1200\n\u001b[1m295/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 426225.4688 - mse: 426215.5938\nEpoch 43: val_loss improved from 420880.37500 to 420153.81250, saving model to /kaggle/working/weights.keras\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 426378.8125 - mse: 426368.9375 - val_loss: 420153.8125 - val_mse: 420143.9062\nEpoch 44/1200\n\u001b[1m288/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 427742.7188 - mse: 427732.7812\nEpoch 44: val_loss improved from 420153.81250 to 418787.62500, saving model to /kaggle/working/weights.keras\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 427837.9688 - mse: 427828.0312 - val_loss: 418787.6250 - val_mse: 418777.6875\nEpoch 45/1200\n\u001b[1m289/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 433690.9062 - mse: 433680.8750\nEpoch 45: val_loss improved from 418787.62500 to 417779.37500, saving model to /kaggle/working/weights.keras\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 433593.9375 - mse: 433583.9062 - val_loss: 417779.3750 - val_mse: 417769.3750\nEpoch 46/1200\n\u001b[1m296/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 441193.8125 - mse: 441183.9062\nEpoch 46: val_loss improved from 417779.37500 to 416516.43750, saving model to /kaggle/working/weights.keras\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 441010.1562 - mse: 441000.2500 - val_loss: 416516.4375 - val_mse: 416506.4688\nEpoch 47/1200\n\u001b[1m283/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 428696.2188 - mse: 428686.2500\nEpoch 47: val_loss improved from 416516.43750 to 414856.37500, saving model to /kaggle/working/weights.keras\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 428645.4375 - mse: 428635.4688 - val_loss: 414856.3750 - val_mse: 414846.3438\nEpoch 48/1200\n\u001b[1m295/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 427055.3125 - mse: 427045.4688\nEpoch 48: val_loss improved from 414856.37500 to 413740.96875, saving model to /kaggle/working/weights.keras\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 427067.5625 - mse: 427057.7188 - val_loss: 413740.9688 - val_mse: 413731.1250\nEpoch 49/1200\n\u001b[1m289/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 422073.4688 - mse: 422063.4688\nEpoch 49: val_loss improved from 413740.96875 to 412946.43750, saving model to /kaggle/working/weights.keras\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 422219.4688 - mse: 422209.4688 - val_loss: 412946.4375 - val_mse: 412936.5000\nEpoch 50/1200\n\u001b[1m286/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 417439.1250 - mse: 417429.1562\nEpoch 50: val_loss improved from 412946.43750 to 411207.28125, saving model to /kaggle/working/weights.keras\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 417744.7812 - mse: 417734.8125 - val_loss: 411207.2812 - val_mse: 411197.3125\nEpoch 51/1200\n\u001b[1m283/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 425085.0938 - mse: 425074.9688\nEpoch 51: val_loss improved from 411207.28125 to 409505.09375, saving model to /kaggle/working/weights.keras\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 425059.9375 - mse: 425049.8125 - val_loss: 409505.0938 - val_mse: 409495.0000\nEpoch 52/1200\n\u001b[1m291/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 422804.6250 - mse: 422794.5625\nEpoch 52: val_loss improved from 409505.09375 to 407664.21875, saving model to /kaggle/working/weights.keras\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 422754.5000 - mse: 422744.4375 - val_loss: 407664.2188 - val_mse: 407654.1875\nEpoch 53/1200\n\u001b[1m284/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 416782.4688 - mse: 416772.4062\nEpoch 53: val_loss improved from 407664.21875 to 405426.21875, saving model to /kaggle/working/weights.keras\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 417066.1250 - mse: 417056.0625 - val_loss: 405426.2188 - val_mse: 405416.1562\nEpoch 54/1200\n\u001b[1m288/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 417838.8125 - mse: 417828.6875\nEpoch 54: val_loss improved from 405426.21875 to 402992.62500, saving model to /kaggle/working/weights.keras\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 417873.4375 - mse: 417863.2812 - val_loss: 402992.6250 - val_mse: 402982.5000\nEpoch 55/1200\n\u001b[1m281/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 414484.5312 - mse: 414474.4062\nEpoch 55: val_loss improved from 402992.62500 to 400855.56250, saving model to /kaggle/working/weights.keras\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 414502.0938 - mse: 414491.9688 - val_loss: 400855.5625 - val_mse: 400845.2812\nEpoch 56/1200\n\u001b[1m292/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 413091.7500 - mse: 413081.5625\nEpoch 56: val_loss improved from 400855.56250 to 398077.40625, saving model to /kaggle/working/weights.keras\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 413116.2812 - mse: 413106.0625 - val_loss: 398077.4062 - val_mse: 398067.1562\nEpoch 57/1200\n\u001b[1m284/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 415507.5000 - mse: 415497.2500\nEpoch 57: val_loss improved from 398077.40625 to 396124.59375, saving model to /kaggle/working/weights.keras\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 415306.0312 - mse: 415295.7500 - val_loss: 396124.5938 - val_mse: 396114.3438\nEpoch 58/1200\n\u001b[1m290/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 409948.0312 - mse: 409937.7812\nEpoch 58: val_loss improved from 396124.59375 to 393678.40625, saving model to /kaggle/working/weights.keras\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 410077.3750 - mse: 410067.1250 - val_loss: 393678.4062 - val_mse: 393668.2812\nEpoch 59/1200\n\u001b[1m289/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 407285.9688 - mse: 407275.6562\nEpoch 59: val_loss improved from 393678.40625 to 389840.21875, saving model to /kaggle/working/weights.keras\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 407311.5000 - mse: 407301.1562 - val_loss: 389840.2188 - val_mse: 389829.7500\nEpoch 60/1200\n\u001b[1m285/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 407252.7500 - mse: 407242.4062\nEpoch 60: val_loss improved from 389840.21875 to 387334.03125, saving model to /kaggle/working/weights.keras\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 407223.3125 - mse: 407212.9688 - val_loss: 387334.0312 - val_mse: 387323.4688\nEpoch 61/1200\n\u001b[1m278/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 399681.7812 - mse: 399671.5312\nEpoch 61: val_loss improved from 387334.03125 to 384587.06250, saving model to /kaggle/working/weights.keras\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 399979.0312 - mse: 399968.7812 - val_loss: 384587.0625 - val_mse: 384576.6875\nEpoch 62/1200\n\u001b[1m291/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 401395.7812 - mse: 401385.4375\nEpoch 62: val_loss improved from 384587.06250 to 381701.62500, saving model to /kaggle/working/weights.keras\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 401330.6562 - mse: 401320.3125 - val_loss: 381701.6250 - val_mse: 381691.2188\nEpoch 63/1200\n\u001b[1m277/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 403280.9062 - mse: 403270.5312\nEpoch 63: val_loss improved from 381701.62500 to 377744.09375, saving model to /kaggle/working/weights.keras\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 402836.0312 - mse: 402825.6562 - val_loss: 377744.0938 - val_mse: 377733.5938\nEpoch 64/1200\n\u001b[1m275/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 388068.9375 - mse: 388058.5000\nEpoch 64: val_loss improved from 377744.09375 to 374853.68750, saving model to /kaggle/working/weights.keras\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 388398.5312 - mse: 388388.1250 - val_loss: 374853.6875 - val_mse: 374843.2500\nEpoch 65/1200\n\u001b[1m290/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 394155.8438 - mse: 394145.3750\nEpoch 65: val_loss improved from 374853.68750 to 371326.12500, saving model to /kaggle/working/weights.keras\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 394105.5312 - mse: 394095.0625 - val_loss: 371326.1250 - val_mse: 371315.5938\nEpoch 66/1200\n\u001b[1m279/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 389803.1250 - mse: 389792.8438\nEpoch 66: val_loss improved from 371326.12500 to 364751.50000, saving model to /kaggle/working/weights.keras\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 389562.2188 - mse: 389551.9375 - val_loss: 364751.5000 - val_mse: 364741.0000\nEpoch 67/1200\n\u001b[1m284/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 380094.8438 - mse: 380084.3438\nEpoch 67: val_loss improved from 364751.50000 to 362397.21875, saving model to /kaggle/working/weights.keras\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 380411.5938 - mse: 380401.0938 - val_loss: 362397.2188 - val_mse: 362386.7188\nEpoch 68/1200\n\u001b[1m283/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 389021.8438 - mse: 389011.2812\nEpoch 68: val_loss improved from 362397.21875 to 355782.31250, saving model to /kaggle/working/weights.keras\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 388748.1875 - mse: 388737.6562 - val_loss: 355782.3125 - val_mse: 355771.7188\nEpoch 69/1200\n\u001b[1m283/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 380156.6562 - mse: 380146.0625\nEpoch 69: val_loss improved from 355782.31250 to 350723.06250, saving model to /kaggle/working/weights.keras\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 379982.2500 - mse: 379971.6562 - val_loss: 350723.0625 - val_mse: 350712.5312\nEpoch 70/1200\n\u001b[1m289/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 375662.7500 - mse: 375652.1250\nEpoch 70: val_loss improved from 350723.06250 to 348704.75000, saving model to /kaggle/working/weights.keras\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 375639.5625 - mse: 375628.9062 - val_loss: 348704.7500 - val_mse: 348694.1250\nEpoch 71/1200\n\u001b[1m294/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 375220.2812 - mse: 375209.5625\nEpoch 71: val_loss improved from 348704.75000 to 342892.25000, saving model to /kaggle/working/weights.keras\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 375137.2812 - mse: 375126.5625 - val_loss: 342892.2500 - val_mse: 342881.5938\nEpoch 72/1200\n\u001b[1m292/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 362403.4375 - mse: 362392.6250\nEpoch 72: val_loss improved from 342892.25000 to 337241.09375, saving model to /kaggle/working/weights.keras\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 362517.3750 - mse: 362506.5625 - val_loss: 337241.0938 - val_mse: 337230.3438\nEpoch 73/1200\n\u001b[1m292/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 362895.9062 - mse: 362885.1875\nEpoch 73: val_loss improved from 337241.09375 to 336540.28125, saving model to /kaggle/working/weights.keras\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 362873.2188 - mse: 362862.5312 - val_loss: 336540.2812 - val_mse: 336529.4062\nEpoch 74/1200\n\u001b[1m292/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 351802.7188 - mse: 351791.9375\nEpoch 74: val_loss improved from 336540.28125 to 329203.50000, saving model to /kaggle/working/weights.keras\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 351988.8125 - mse: 351978.0625 - val_loss: 329203.5000 - val_mse: 329192.6250\nEpoch 75/1200\n\u001b[1m287/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 354022.8438 - mse: 354012.0938\nEpoch 75: val_loss improved from 329203.50000 to 322509.40625, saving model to /kaggle/working/weights.keras\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 353969.3438 - mse: 353958.5938 - val_loss: 322509.4062 - val_mse: 322498.5938\nEpoch 76/1200\n\u001b[1m286/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 352424.0000 - mse: 352413.1875\nEpoch 76: val_loss improved from 322509.40625 to 320296.62500, saving model to /kaggle/working/weights.keras\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 352405.0938 - mse: 352394.2812 - val_loss: 320296.6250 - val_mse: 320285.9375\nEpoch 77/1200\n\u001b[1m299/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 347042.5938 - mse: 347031.7500\nEpoch 77: val_loss improved from 320296.62500 to 318116.28125, saving model to /kaggle/working/weights.keras\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 347062.2812 - mse: 347051.4375 - val_loss: 318116.2812 - val_mse: 318105.4688\nEpoch 78/1200\n\u001b[1m286/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 345082.8125 - mse: 345071.9062\nEpoch 78: val_loss improved from 318116.28125 to 314699.96875, saving model to /kaggle/working/weights.keras\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 345046.6562 - mse: 345035.7500 - val_loss: 314699.9688 - val_mse: 314689.0000\nEpoch 79/1200\n\u001b[1m290/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 341596.1562 - mse: 341585.2500\nEpoch 79: val_loss improved from 314699.96875 to 310303.90625, saving model to /kaggle/working/weights.keras\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 341573.9062 - mse: 341562.9688 - val_loss: 310303.9062 - val_mse: 310293.0625\nEpoch 80/1200\n\u001b[1m298/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 338034.2188 - mse: 338023.2500\nEpoch 80: val_loss improved from 310303.90625 to 306299.81250, saving model to /kaggle/working/weights.keras\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 338043.7812 - mse: 338032.8125 - val_loss: 306299.8125 - val_mse: 306288.8750\nEpoch 81/1200\n\u001b[1m282/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 340847.7500 - mse: 340836.8750\nEpoch 81: val_loss improved from 306299.81250 to 303213.28125, saving model to /kaggle/working/weights.keras\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 340533.7188 - mse: 340522.8438 - val_loss: 303213.2812 - val_mse: 303202.3125\nEpoch 82/1200\n\u001b[1m293/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 337836.2500 - mse: 337825.2812\nEpoch 82: val_loss improved from 303213.28125 to 301912.31250, saving model to /kaggle/working/weights.keras\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 337774.2812 - mse: 337763.2812 - val_loss: 301912.3125 - val_mse: 301901.3125\nEpoch 83/1200\n\u001b[1m293/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 331290.4375 - mse: 331279.4375\nEpoch 83: val_loss improved from 301912.31250 to 299061.65625, saving model to /kaggle/working/weights.keras\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 331292.4375 - mse: 331281.4062 - val_loss: 299061.6562 - val_mse: 299050.5938\nEpoch 84/1200\n\u001b[1m287/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 327006.5938 - mse: 326995.5938\nEpoch 84: val_loss improved from 299061.65625 to 292991.09375, saving model to /kaggle/working/weights.keras\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 327019.9062 - mse: 327008.9062 - val_loss: 292991.0938 - val_mse: 292980.0312\nEpoch 85/1200\n\u001b[1m287/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 328473.6562 - mse: 328462.5938\nEpoch 85: val_loss improved from 292991.09375 to 291093.15625, saving model to /kaggle/working/weights.keras\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 328449.1875 - mse: 328438.1250 - val_loss: 291093.1562 - val_mse: 291082.1250\nEpoch 86/1200\n\u001b[1m294/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 328174.1562 - mse: 328163.1250\nEpoch 86: val_loss improved from 291093.15625 to 289778.93750, saving model to /kaggle/working/weights.keras\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 328068.5000 - mse: 328057.4375 - val_loss: 289778.9375 - val_mse: 289767.8750\nEpoch 87/1200\n\u001b[1m289/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 324493.0938 - mse: 324481.9375\nEpoch 87: val_loss improved from 289778.93750 to 287144.25000, saving model to /kaggle/working/weights.keras\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 324385.5312 - mse: 324374.4062 - val_loss: 287144.2500 - val_mse: 287133.0625\nEpoch 88/1200\n\u001b[1m296/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 322025.0000 - mse: 322013.8125\nEpoch 88: val_loss did not improve from 287144.25000\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 322018.9062 - mse: 322007.7188 - val_loss: 287749.2500 - val_mse: 287738.0625\nEpoch 89/1200\n\u001b[1m296/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 318956.2812 - mse: 318945.0938\nEpoch 89: val_loss improved from 287144.25000 to 285300.53125, saving model to /kaggle/working/weights.keras\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 318928.4688 - mse: 318917.3125 - val_loss: 285300.5312 - val_mse: 285289.3750\nEpoch 90/1200\n\u001b[1m291/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 319687.3438 - mse: 319676.2500\nEpoch 90: val_loss improved from 285300.53125 to 281679.87500, saving model to /kaggle/working/weights.keras\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 319629.6875 - mse: 319618.5938 - val_loss: 281679.8750 - val_mse: 281668.6250\nEpoch 91/1200\n\u001b[1m277/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 315569.1250 - mse: 315557.9688\nEpoch 91: val_loss did not improve from 281679.87500\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 315618.5000 - mse: 315607.3438 - val_loss: 287609.9688 - val_mse: 287598.7500\nEpoch 92/1200\n\u001b[1m296/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 311692.7812 - mse: 311681.5625\nEpoch 92: val_loss did not improve from 281679.87500\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 311708.7812 - mse: 311697.5625 - val_loss: 281756.8750 - val_mse: 281745.5938\nEpoch 93/1200\n\u001b[1m299/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 314794.0312 - mse: 314782.8438\nEpoch 93: val_loss improved from 281679.87500 to 275534.40625, saving model to /kaggle/working/weights.keras\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 314802.0625 - mse: 314790.8750 - val_loss: 275534.4062 - val_mse: 275523.1250\nEpoch 94/1200\n\u001b[1m283/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 313289.7812 - mse: 313278.4688\nEpoch 94: val_loss did not improve from 275534.40625\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 313298.3750 - mse: 313287.0625 - val_loss: 280326.7188 - val_mse: 280315.4688\nEpoch 95/1200\n\u001b[1m285/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 305076.3125 - mse: 305065.0000\nEpoch 95: val_loss did not improve from 275534.40625\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 305356.3125 - mse: 305345.0000 - val_loss: 283228.1875 - val_mse: 283216.9062\nEpoch 96/1200\n\u001b[1m288/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 311092.9688 - mse: 311081.7500\nEpoch 96: val_loss improved from 275534.40625 to 275005.75000, saving model to /kaggle/working/weights.keras\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 311050.9062 - mse: 311039.6875 - val_loss: 275005.7500 - val_mse: 274994.4688\nEpoch 97/1200\n\u001b[1m290/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 303950.2812 - mse: 303938.9375\nEpoch 97: val_loss did not improve from 275005.75000\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 304007.6562 - mse: 303996.3438 - val_loss: 285733.7188 - val_mse: 285722.4375\nEpoch 98/1200\n\u001b[1m289/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 310651.2812 - mse: 310640.0625\nEpoch 98: val_loss improved from 275005.75000 to 274865.65625, saving model to /kaggle/working/weights.keras\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 310577.0938 - mse: 310565.8438 - val_loss: 274865.6562 - val_mse: 274854.3125\nEpoch 99/1200\n\u001b[1m290/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 316200.7188 - mse: 316189.4062\nEpoch 99: val_loss improved from 274865.65625 to 273378.84375, saving model to /kaggle/working/weights.keras\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 315888.6562 - mse: 315877.3750 - val_loss: 273378.8438 - val_mse: 273367.5000\nEpoch 100/1200\n\u001b[1m289/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 305714.2500 - mse: 305703.0938\nEpoch 100: val_loss improved from 273378.84375 to 272692.87500, saving model to /kaggle/working/weights.keras\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 305692.7500 - mse: 305681.5938 - val_loss: 272692.8750 - val_mse: 272681.5938\nEpoch 101/1200\n\u001b[1m286/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 301477.5000 - mse: 301466.2188\nEpoch 101: val_loss improved from 272692.87500 to 270350.53125, saving model to /kaggle/working/weights.keras\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 301450.2812 - mse: 301439.0000 - val_loss: 270350.5312 - val_mse: 270339.1875\nEpoch 102/1200\n\u001b[1m296/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 302119.9062 - mse: 302108.5625\nEpoch 102: val_loss did not improve from 270350.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 302160.5000 - mse: 302149.1562 - val_loss: 273597.3438 - val_mse: 273586.0625\nEpoch 103/1200\n\u001b[1m296/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 299203.7812 - mse: 299192.5000\nEpoch 103: val_loss did not improve from 270350.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 299247.0625 - mse: 299235.7812 - val_loss: 271024.3438 - val_mse: 271013.0312\nEpoch 104/1200\n\u001b[1m292/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 304131.1250 - mse: 304119.7812\nEpoch 104: val_loss improved from 270350.53125 to 265322.00000, saving model to /kaggle/working/weights.keras\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 304083.5938 - mse: 304072.2500 - val_loss: 265322.0000 - val_mse: 265310.6562\nEpoch 105/1200\n\u001b[1m287/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 306256.4688 - mse: 306245.1875\nEpoch 105: val_loss improved from 265322.00000 to 263519.40625, saving model to /kaggle/working/weights.keras\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 306110.0000 - mse: 306098.7188 - val_loss: 263519.4062 - val_mse: 263508.0625\nEpoch 106/1200\n\u001b[1m279/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 296521.6250 - mse: 296510.2188\nEpoch 106: val_loss did not improve from 263519.40625\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 296743.8438 - mse: 296732.4375 - val_loss: 266184.6250 - val_mse: 266173.3438\nEpoch 107/1200\n\u001b[1m289/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 300702.0000 - mse: 300690.7188\nEpoch 107: val_loss did not improve from 263519.40625\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 300611.6875 - mse: 300600.4062 - val_loss: 270636.8750 - val_mse: 270625.4375\nEpoch 108/1200\n\u001b[1m277/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 294588.7500 - mse: 294577.3125\nEpoch 108: val_loss improved from 263519.40625 to 262148.06250, saving model to /kaggle/working/weights.keras\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 294722.1875 - mse: 294710.7812 - val_loss: 262148.0625 - val_mse: 262136.7188\nEpoch 109/1200\n\u001b[1m293/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 298022.0312 - mse: 298010.5000\nEpoch 109: val_loss improved from 262148.06250 to 258614.42188, saving model to /kaggle/working/weights.keras\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 298071.3750 - mse: 298059.8438 - val_loss: 258614.4219 - val_mse: 258603.0469\nEpoch 110/1200\n\u001b[1m294/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 299291.3125 - mse: 299279.9375\nEpoch 110: val_loss improved from 258614.42188 to 257253.12500, saving model to /kaggle/working/weights.keras\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 299170.5625 - mse: 299159.1875 - val_loss: 257253.1250 - val_mse: 257241.7500\nEpoch 111/1200\n\u001b[1m298/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 295584.3750 - mse: 295572.9688\nEpoch 111: val_loss improved from 257253.12500 to 251213.78125, saving model to /kaggle/working/weights.keras\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 295550.0312 - mse: 295538.6250 - val_loss: 251213.7812 - val_mse: 251202.2188\nEpoch 112/1200\n\u001b[1m295/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 289063.5000 - mse: 289052.1250\nEpoch 112: val_loss did not improve from 251213.78125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 289063.6250 - mse: 289052.2500 - val_loss: 255056.8906 - val_mse: 255045.4375\nEpoch 113/1200\n\u001b[1m297/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 282741.2812 - mse: 282729.8750\nEpoch 113: val_loss improved from 251213.78125 to 244007.81250, saving model to /kaggle/working/weights.keras\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 282739.2500 - mse: 282727.8125 - val_loss: 244007.8125 - val_mse: 243996.3594\nEpoch 114/1200\n\u001b[1m289/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 280375.1562 - mse: 280363.7188\nEpoch 114: val_loss improved from 244007.81250 to 239596.73438, saving model to /kaggle/working/weights.keras\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 280280.8750 - mse: 280269.4375 - val_loss: 239596.7344 - val_mse: 239585.3594\nEpoch 115/1200\n\u001b[1m288/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 274595.6562 - mse: 274584.2188\nEpoch 115: val_loss improved from 239596.73438 to 231202.53125, saving model to /kaggle/working/weights.keras\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 274521.1875 - mse: 274509.7500 - val_loss: 231202.5312 - val_mse: 231191.0469\nEpoch 116/1200\n\u001b[1m292/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 270018.0000 - mse: 270006.4062\nEpoch 116: val_loss improved from 231202.53125 to 216421.71875, saving model to /kaggle/working/weights.keras\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 269991.3750 - mse: 269979.8125 - val_loss: 216421.7188 - val_mse: 216410.2344\nEpoch 117/1200\n\u001b[1m296/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 268253.3125 - mse: 268241.8438\nEpoch 117: val_loss did not improve from 216421.71875\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 268214.9375 - mse: 268203.4688 - val_loss: 217693.1562 - val_mse: 217681.6250\nEpoch 118/1200\n\u001b[1m286/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 253594.8125 - mse: 253583.3125\nEpoch 118: val_loss improved from 216421.71875 to 204892.79688, saving model to /kaggle/working/weights.keras\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 253882.6719 - mse: 253871.1875 - val_loss: 204892.7969 - val_mse: 204881.1875\nEpoch 119/1200\n\u001b[1m283/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 260138.1406 - mse: 260126.6250\nEpoch 119: val_loss did not improve from 204892.79688\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 260174.2500 - mse: 260162.7500 - val_loss: 208934.6562 - val_mse: 208923.1719\nEpoch 120/1200\n\u001b[1m288/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 261829.6562 - mse: 261818.0938\nEpoch 120: val_loss improved from 204892.79688 to 199122.84375, saving model to /kaggle/working/weights.keras\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 261638.6406 - mse: 261627.0781 - val_loss: 199122.8438 - val_mse: 199111.3125\nEpoch 121/1200\n\u001b[1m289/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 256335.6875 - mse: 256324.1094\nEpoch 121: val_loss improved from 199122.84375 to 193901.15625, saving model to /kaggle/working/weights.keras\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 256208.7656 - mse: 256197.1875 - val_loss: 193901.1562 - val_mse: 193889.6562\nEpoch 122/1200\n\u001b[1m274/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 258974.7656 - mse: 258963.1562\nEpoch 122: val_loss did not improve from 193901.15625\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 258308.6406 - mse: 258297.0469 - val_loss: 194268.7500 - val_mse: 194257.1562\nEpoch 123/1200\n\u001b[1m294/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 248410.3125 - mse: 248398.7344\nEpoch 123: val_loss improved from 193901.15625 to 191810.85938, saving model to /kaggle/working/weights.keras\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 248415.0469 - mse: 248403.4688 - val_loss: 191810.8594 - val_mse: 191799.2969\nEpoch 124/1200\n\u001b[1m292/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 239865.7344 - mse: 239854.1875\nEpoch 124: val_loss did not improve from 191810.85938\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 239943.7500 - mse: 239932.2188 - val_loss: 192939.8125 - val_mse: 192928.2500\nEpoch 125/1200\n\u001b[1m298/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 247381.7188 - mse: 247370.1875\nEpoch 125: val_loss did not improve from 191810.85938\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 247383.8906 - mse: 247372.3594 - val_loss: 192988.7344 - val_mse: 192977.1094\nEpoch 126/1200\n\u001b[1m294/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 240490.7500 - mse: 240479.1406\nEpoch 126: val_loss did not improve from 191810.85938\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 240575.8125 - mse: 240564.2031 - val_loss: 192664.7500 - val_mse: 192653.1406\nEpoch 127/1200\n\u001b[1m288/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 247169.9375 - mse: 247158.3438\nEpoch 127: val_loss improved from 191810.85938 to 184016.81250, saving model to /kaggle/working/weights.keras\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 247060.8594 - mse: 247049.2500 - val_loss: 184016.8125 - val_mse: 184005.2031\nEpoch 128/1200\n\u001b[1m296/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 247250.0938 - mse: 247238.5781\nEpoch 128: val_loss improved from 184016.81250 to 174826.96875, saving model to /kaggle/working/weights.keras\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 247134.2500 - mse: 247122.7188 - val_loss: 174826.9688 - val_mse: 174815.3438\nEpoch 129/1200\n\u001b[1m295/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 243188.4531 - mse: 243176.9062\nEpoch 129: val_loss did not improve from 174826.96875\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 243227.6094 - mse: 243216.0625 - val_loss: 178208.2031 - val_mse: 178196.5781\nEpoch 130/1200\n\u001b[1m298/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 232037.2031 - mse: 232025.5938\nEpoch 130: val_loss did not improve from 174826.96875\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 232100.6406 - mse: 232089.0156 - val_loss: 181246.9688 - val_mse: 181235.4062\nEpoch 131/1200\n\u001b[1m274/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 240137.5938 - mse: 240126.0156\nEpoch 131: val_loss did not improve from 174826.96875\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 239782.2031 - mse: 239770.6094 - val_loss: 189654.1719 - val_mse: 189642.5156\nEpoch 132/1200\n\u001b[1m299/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 238359.2031 - mse: 238347.5781\nEpoch 132: val_loss did not improve from 174826.96875\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 238353.5469 - mse: 238341.9062 - val_loss: 177485.5312 - val_mse: 177473.8906\nEpoch 133/1200\n\u001b[1m279/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 236803.2656 - mse: 236791.6406\nEpoch 133: val_loss did not improve from 174826.96875\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 236958.9375 - mse: 236947.3281 - val_loss: 177406.6875 - val_mse: 177395.0156\nEpoch 134/1200\n\u001b[1m295/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 236241.1250 - mse: 236229.4531\nEpoch 134: val_loss did not improve from 174826.96875\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 236262.6562 - mse: 236250.9688 - val_loss: 177033.2188 - val_mse: 177021.5312\nEpoch 135/1200\n\u001b[1m290/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 237058.4531 - mse: 237046.7500\nEpoch 135: val_loss improved from 174826.96875 to 174572.89062, saving model to /kaggle/working/weights.keras\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 237010.1875 - mse: 236998.4844 - val_loss: 174572.8906 - val_mse: 174561.2969\nEpoch 136/1200\n\u001b[1m297/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 231986.4688 - mse: 231974.8438\nEpoch 136: val_loss improved from 174572.89062 to 172043.90625, saving model to /kaggle/working/weights.keras\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 231986.7344 - mse: 231975.1094 - val_loss: 172043.9062 - val_mse: 172032.3125\nEpoch 137/1200\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 233702.9531 - mse: 233691.3125\nEpoch 137: val_loss improved from 172043.90625 to 166966.17188, saving model to /kaggle/working/weights.keras\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 233703.1719 - mse: 233691.5312 - val_loss: 166966.1719 - val_mse: 166954.5625\nEpoch 138/1200\n\u001b[1m279/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 230326.5000 - mse: 230314.9062\nEpoch 138: val_loss did not improve from 166966.17188\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 230283.7031 - mse: 230272.0938 - val_loss: 176591.2344 - val_mse: 176579.5625\nEpoch 139/1200\n\u001b[1m287/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 234453.0156 - mse: 234441.3281\nEpoch 139: val_loss did not improve from 166966.17188\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 234341.7969 - mse: 234330.1250 - val_loss: 172724.6406 - val_mse: 172712.9375\nEpoch 140/1200\n\u001b[1m286/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 225172.9531 - mse: 225161.2656\nEpoch 140: val_loss improved from 166966.17188 to 165879.78125, saving model to /kaggle/working/weights.keras\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 225315.2812 - mse: 225303.5938 - val_loss: 165879.7812 - val_mse: 165868.1406\nEpoch 141/1200\n\u001b[1m293/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 225524.8906 - mse: 225513.1875\nEpoch 141: val_loss did not improve from 165879.78125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 225603.9688 - mse: 225592.2656 - val_loss: 168810.5000 - val_mse: 168798.8281\nEpoch 142/1200\n\u001b[1m289/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 227057.5781 - mse: 227045.7656\nEpoch 142: val_loss did not improve from 165879.78125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 226963.5938 - mse: 226951.7812 - val_loss: 169065.0312 - val_mse: 169053.2656\nEpoch 143/1200\n\u001b[1m285/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 224032.9062 - mse: 224021.1562\nEpoch 143: val_loss improved from 165879.78125 to 163635.04688, saving model to /kaggle/working/weights.keras\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 224166.3281 - mse: 224154.5938 - val_loss: 163635.0469 - val_mse: 163623.3594\nEpoch 144/1200\n\u001b[1m290/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 220231.5312 - mse: 220219.7812\nEpoch 144: val_loss did not improve from 163635.04688\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 220380.1875 - mse: 220368.4375 - val_loss: 168225.6562 - val_mse: 168213.9375\nEpoch 145/1200\n\u001b[1m287/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 223045.2188 - mse: 223033.4688\nEpoch 145: val_loss improved from 163635.04688 to 161063.17188, saving model to /kaggle/working/weights.keras\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 223134.7188 - mse: 223122.9688 - val_loss: 161063.1719 - val_mse: 161051.4844\nEpoch 146/1200\n\u001b[1m294/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 227493.3906 - mse: 227481.6406\nEpoch 146: val_loss did not improve from 161063.17188\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 227386.5625 - mse: 227374.8125 - val_loss: 161301.0312 - val_mse: 161289.2969\nEpoch 147/1200\n\u001b[1m282/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 221200.4688 - mse: 221188.7188\nEpoch 147: val_loss did not improve from 161063.17188\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 221172.2969 - mse: 221160.5469 - val_loss: 164065.1250 - val_mse: 164053.3750\nEpoch 148/1200\n\u001b[1m293/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 219195.0312 - mse: 219183.2656\nEpoch 148: val_loss improved from 161063.17188 to 156717.81250, saving model to /kaggle/working/weights.keras\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 219241.0156 - mse: 219229.2500 - val_loss: 156717.8125 - val_mse: 156706.0312\nEpoch 149/1200\n\u001b[1m290/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 219112.2656 - mse: 219100.4531\nEpoch 149: val_loss did not improve from 156717.81250\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 219050.6406 - mse: 219038.8125 - val_loss: 159559.9844 - val_mse: 159548.2188\nEpoch 150/1200\n\u001b[1m288/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 219059.7656 - mse: 219048.0781\nEpoch 150: val_loss did not improve from 156717.81250\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 218978.9844 - mse: 218967.3125 - val_loss: 158688.8594 - val_mse: 158677.0938\nEpoch 151/1200\n\u001b[1m285/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 215291.7969 - mse: 215280.0000\nEpoch 151: val_loss improved from 156717.81250 to 154947.54688, saving model to /kaggle/working/weights.keras\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 215208.1406 - mse: 215196.3281 - val_loss: 154947.5469 - val_mse: 154935.8125\nEpoch 152/1200\n\u001b[1m293/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 211630.4688 - mse: 211618.7500\nEpoch 152: val_loss did not improve from 154947.54688\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 211560.7031 - mse: 211549.0000 - val_loss: 155437.3125 - val_mse: 155425.5625\nEpoch 153/1200\n\u001b[1m298/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 213652.5469 - mse: 213640.7344\nEpoch 153: val_loss did not improve from 154947.54688\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 213656.5312 - mse: 213644.7344 - val_loss: 158784.7656 - val_mse: 158772.9844\nEpoch 154/1200\n\u001b[1m299/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 209789.5312 - mse: 209777.6562\nEpoch 154: val_loss improved from 154947.54688 to 149797.17188, saving model to /kaggle/working/weights.keras\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 209770.2500 - mse: 209758.3750 - val_loss: 149797.1719 - val_mse: 149785.3906\nEpoch 155/1200\n\u001b[1m299/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 210738.9688 - mse: 210727.1094\nEpoch 155: val_loss did not improve from 149797.17188\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 210731.9688 - mse: 210720.1094 - val_loss: 163649.3125 - val_mse: 163637.5156\nEpoch 156/1200\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 209805.0938 - mse: 209793.2656\nEpoch 156: val_loss did not improve from 149797.17188\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 209800.4375 - mse: 209788.5938 - val_loss: 152772.6562 - val_mse: 152760.8594\nEpoch 157/1200\n\u001b[1m298/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 204992.4219 - mse: 204980.5625\nEpoch 157: val_loss did not improve from 149797.17188\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 205002.2969 - mse: 204990.4375 - val_loss: 152453.7344 - val_mse: 152441.9219\nEpoch 158/1200\n\u001b[1m294/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 202242.4844 - mse: 202230.6719\nEpoch 158: val_loss did not improve from 149797.17188\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 202321.7969 - mse: 202309.9844 - val_loss: 151834.1719 - val_mse: 151822.3438\nEpoch 159/1200\n\u001b[1m296/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 206906.6562 - mse: 206894.8750\nEpoch 159: val_loss did not improve from 149797.17188\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 206876.6875 - mse: 206864.9062 - val_loss: 152412.5469 - val_mse: 152400.7031\nEpoch 160/1200\n\u001b[1m294/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 198217.2500 - mse: 198205.5156\nEpoch 160: val_loss improved from 149797.17188 to 148080.59375, saving model to /kaggle/working/weights.keras\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 198330.9062 - mse: 198319.1562 - val_loss: 148080.5938 - val_mse: 148068.7500\nEpoch 161/1200\n\u001b[1m283/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 202750.7500 - mse: 202738.8906\nEpoch 161: val_loss did not improve from 148080.59375\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 202860.3594 - mse: 202848.4844 - val_loss: 150409.7500 - val_mse: 150397.8906\nEpoch 162/1200\n\u001b[1m296/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 201445.1250 - mse: 201433.1875\nEpoch 162: val_loss did not improve from 148080.59375\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 201430.0312 - mse: 201418.0781 - val_loss: 154174.0469 - val_mse: 154162.2344\nEpoch 163/1200\n\u001b[1m282/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 202852.4219 - mse: 202840.5938\nEpoch 163: val_loss did not improve from 148080.59375\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 202664.2812 - mse: 202652.4688 - val_loss: 150679.7969 - val_mse: 150667.9531\nEpoch 164/1200\n\u001b[1m292/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 195880.0156 - mse: 195868.1406\nEpoch 164: val_loss did not improve from 148080.59375\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 195998.2500 - mse: 195986.3750 - val_loss: 154912.8594 - val_mse: 154901.0312\nEpoch 165/1200\n\u001b[1m292/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 199795.4844 - mse: 199783.6250\nEpoch 165: val_loss improved from 148080.59375 to 146347.71875, saving model to /kaggle/working/weights.keras\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 199806.6406 - mse: 199794.7812 - val_loss: 146347.7188 - val_mse: 146335.8281\nEpoch 166/1200\n\u001b[1m295/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 202459.2188 - mse: 202447.2812\nEpoch 166: val_loss did not improve from 146347.71875\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 202427.3281 - mse: 202415.4062 - val_loss: 151974.4219 - val_mse: 151962.4844\nEpoch 167/1200\n\u001b[1m288/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 195190.7969 - mse: 195178.9375\nEpoch 167: val_loss did not improve from 146347.71875\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 195350.2969 - mse: 195338.4375 - val_loss: 150516.2031 - val_mse: 150504.2500\nEpoch 168/1200\n\u001b[1m293/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 195267.9844 - mse: 195256.0469\nEpoch 168: val_loss did not improve from 146347.71875\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 195356.8281 - mse: 195344.8906 - val_loss: 149902.5781 - val_mse: 149890.6562\nEpoch 169/1200\n\u001b[1m292/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 197481.8438 - mse: 197469.9219\nEpoch 169: val_loss did not improve from 146347.71875\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 197488.4688 - mse: 197476.5312 - val_loss: 149841.6875 - val_mse: 149829.7656\nEpoch 170/1200\n\u001b[1m294/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 199610.9531 - mse: 199599.0469\nEpoch 170: val_loss did not improve from 146347.71875\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 199599.2031 - mse: 199587.2969 - val_loss: 146447.9062 - val_mse: 146435.9688\nEpoch 171/1200\n\u001b[1m293/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 191958.8281 - mse: 191946.9844\nEpoch 171: val_loss did not improve from 146347.71875\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 191994.7344 - mse: 191982.8750 - val_loss: 150909.1250 - val_mse: 150897.2031\nEpoch 172/1200\n\u001b[1m292/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 195280.5000 - mse: 195268.5781\nEpoch 172: val_loss did not improve from 146347.71875\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 195226.2969 - mse: 195214.3750 - val_loss: 147592.0156 - val_mse: 147580.0469\nEpoch 173/1200\n\u001b[1m295/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 194020.9688 - mse: 194009.0469\nEpoch 173: val_loss did not improve from 146347.71875\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 194084.8438 - mse: 194072.9062 - val_loss: 148336.9844 - val_mse: 148325.0312\nEpoch 174/1200\n\u001b[1m291/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 196347.7031 - mse: 196335.7812\nEpoch 174: val_loss did not improve from 146347.71875\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 196305.2500 - mse: 196293.3281 - val_loss: 148049.5625 - val_mse: 148037.6094\nEpoch 175/1200\n\u001b[1m285/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 194549.4062 - mse: 194537.4375\nEpoch 175: val_loss did not improve from 146347.71875\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 194509.5156 - mse: 194497.5469 - val_loss: 149183.4531 - val_mse: 149171.4844\nEpoch 176/1200\n\u001b[1m276/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 201352.7031 - mse: 201340.7500\nEpoch 176: val_loss improved from 146347.71875 to 144450.50000, saving model to /kaggle/working/weights.keras\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 201006.8125 - mse: 200994.8438 - val_loss: 144450.5000 - val_mse: 144438.5625\nEpoch 177/1200\n\u001b[1m297/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 196634.1406 - mse: 196622.1875\nEpoch 177: val_loss did not improve from 144450.50000\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 196599.9375 - mse: 196587.9844 - val_loss: 149676.4219 - val_mse: 149664.4375\nEpoch 178/1200\n\u001b[1m298/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 195124.8594 - mse: 195112.8906\nEpoch 178: val_loss did not improve from 144450.50000\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 195115.0312 - mse: 195103.0625 - val_loss: 155009.7344 - val_mse: 154997.7344\nEpoch 179/1200\n\u001b[1m290/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 189162.5625 - mse: 189150.5781\nEpoch 179: val_loss did not improve from 144450.50000\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 189257.5625 - mse: 189245.5781 - val_loss: 151482.6094 - val_mse: 151470.6094\nEpoch 180/1200\n\u001b[1m289/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 189347.1562 - mse: 189335.1562\nEpoch 180: val_loss did not improve from 144450.50000\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 189385.8438 - mse: 189373.8438 - val_loss: 154685.2969 - val_mse: 154673.2969\nEpoch 181/1200\n\u001b[1m294/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 195669.1406 - mse: 195657.2031\nEpoch 181: val_loss did not improve from 144450.50000\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 195621.4375 - mse: 195609.5000 - val_loss: 152432.3125 - val_mse: 152420.3125\nEpoch 182/1200\n\u001b[1m289/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 187200.9062 - mse: 187188.8906\nEpoch 182: val_loss did not improve from 144450.50000\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 187333.6250 - mse: 187321.6250 - val_loss: 145546.5469 - val_mse: 145534.5000\nEpoch 183/1200\n\u001b[1m294/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 196234.1875 - mse: 196222.1719\nEpoch 183: val_loss did not improve from 144450.50000\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 196157.5938 - mse: 196145.5781 - val_loss: 145078.8125 - val_mse: 145066.7344\nEpoch 184/1200\n\u001b[1m293/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 188564.1406 - mse: 188552.1562\nEpoch 184: val_loss improved from 144450.50000 to 144144.60938, saving model to /kaggle/working/weights.keras\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 188574.3281 - mse: 188562.3594 - val_loss: 144144.6094 - val_mse: 144132.5938\nEpoch 185/1200\n\u001b[1m293/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 192510.8750 - mse: 192498.8438\nEpoch 185: val_loss did not improve from 144144.60938\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 192479.3438 - mse: 192467.3125 - val_loss: 149638.0625 - val_mse: 149626.0312\nEpoch 186/1200\n\u001b[1m293/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 194098.8594 - mse: 194086.8281\nEpoch 186: val_loss improved from 144144.60938 to 143170.48438, saving model to /kaggle/working/weights.keras\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 193974.2812 - mse: 193962.2656 - val_loss: 143170.4844 - val_mse: 143158.4375\nEpoch 187/1200\n\u001b[1m291/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 186999.5000 - mse: 186987.4062\nEpoch 187: val_loss did not improve from 143170.48438\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 187089.8594 - mse: 187077.7812 - val_loss: 147385.4688 - val_mse: 147373.4375\nEpoch 188/1200\n\u001b[1m289/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 188770.3438 - mse: 188758.2656\nEpoch 188: val_loss did not improve from 143170.48438\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 188715.8125 - mse: 188703.7344 - val_loss: 146248.1719 - val_mse: 146236.0938\nEpoch 189/1200\n\u001b[1m275/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 187742.7500 - mse: 187730.6406\nEpoch 189: val_loss did not improve from 143170.48438\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 187631.4844 - mse: 187619.3750 - val_loss: 146882.7969 - val_mse: 146870.7344\nEpoch 190/1200\n\u001b[1m287/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 186082.3438 - mse: 186070.2656\nEpoch 190: val_loss did not improve from 143170.48438\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 186189.0156 - mse: 186176.9531 - val_loss: 146878.9688 - val_mse: 146866.8906\nEpoch 191/1200\n\u001b[1m283/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 187427.3438 - mse: 187415.2188\nEpoch 191: val_loss did not improve from 143170.48438\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 187503.0625 - mse: 187490.9375 - val_loss: 145549.0312 - val_mse: 145536.9375\nEpoch 192/1200\n\u001b[1m283/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 187597.5156 - mse: 187585.4062\nEpoch 192: val_loss did not improve from 143170.48438\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 187479.1719 - mse: 187467.0625 - val_loss: 143869.4688 - val_mse: 143857.3906\nEpoch 193/1200\n\u001b[1m298/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 182332.1094 - mse: 182320.0312\nEpoch 193: val_loss did not improve from 143170.48438\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 182350.8750 - mse: 182338.7969 - val_loss: 147476.2812 - val_mse: 147464.1875\nEpoch 194/1200\n\u001b[1m299/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 187574.3125 - mse: 187562.2344\nEpoch 194: val_loss did not improve from 143170.48438\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 187565.0000 - mse: 187552.9062 - val_loss: 150411.2656 - val_mse: 150399.1094\nEpoch 195/1200\n\u001b[1m293/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 186822.6719 - mse: 186810.5781\nEpoch 195: val_loss did not improve from 143170.48438\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 186820.3125 - mse: 186808.2188 - val_loss: 155050.0938 - val_mse: 155038.0000\nEpoch 196/1200\n\u001b[1m299/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 184641.5312 - mse: 184629.3750\nEpoch 196: val_loss did not improve from 143170.48438\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 184652.5312 - mse: 184640.3906 - val_loss: 143711.9844 - val_mse: 143699.8594\nEpoch 197/1200\n\u001b[1m284/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 186463.9375 - mse: 186451.8125\nEpoch 197: val_loss did not improve from 143170.48438\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 186442.5781 - mse: 186430.4531 - val_loss: 145073.7656 - val_mse: 145061.6719\nEpoch 198/1200\n\u001b[1m298/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 184555.5781 - mse: 184543.4531\nEpoch 198: val_loss did not improve from 143170.48438\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 184546.1875 - mse: 184534.0625 - val_loss: 145356.8125 - val_mse: 145344.7031\nEpoch 199/1200\n\u001b[1m276/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 183828.9844 - mse: 183816.8750\nEpoch 199: val_loss did not improve from 143170.48438\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 183920.4062 - mse: 183908.2969 - val_loss: 147590.7344 - val_mse: 147578.6094\nEpoch 200/1200\n\u001b[1m285/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 180817.3750 - mse: 180805.1875\nEpoch 200: val_loss did not improve from 143170.48438\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 180881.7500 - mse: 180869.5625 - val_loss: 144990.0000 - val_mse: 144977.8438\nEpoch 201/1200\n\u001b[1m288/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 183131.9844 - mse: 183119.8438\nEpoch 201: val_loss did not improve from 143170.48438\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 183182.3438 - mse: 183170.2031 - val_loss: 148061.6406 - val_mse: 148049.5156\nEpoch 202/1200\n\u001b[1m297/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 181869.3906 - mse: 181857.2188\nEpoch 202: val_loss did not improve from 143170.48438\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 181853.5625 - mse: 181841.3906 - val_loss: 147780.8594 - val_mse: 147768.6875\nEpoch 203/1200\n\u001b[1m279/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 180335.5938 - mse: 180323.3906\nEpoch 203: val_loss did not improve from 143170.48438\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 180449.0469 - mse: 180436.8438 - val_loss: 157678.9375 - val_mse: 157666.7500\nEpoch 204/1200\n\u001b[1m289/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 175235.5938 - mse: 175223.3906\nEpoch 204: val_loss did not improve from 143170.48438\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 175540.4844 - mse: 175528.2969 - val_loss: 156098.2812 - val_mse: 156086.0938\nEpoch 205/1200\n\u001b[1m282/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 179763.2031 - mse: 179750.9531\nEpoch 205: val_loss did not improve from 143170.48438\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 179807.2969 - mse: 179795.0469 - val_loss: 145764.8281 - val_mse: 145752.6406\nEpoch 206/1200\n\u001b[1m291/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 182717.8125 - mse: 182705.6719\nEpoch 206: val_loss did not improve from 143170.48438\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 182670.3125 - mse: 182658.1562 - val_loss: 143280.1094 - val_mse: 143267.9062\nEpoch 207/1200\n\u001b[1m297/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 183685.3594 - mse: 183673.2344\nEpoch 207: val_loss did not improve from 143170.48438\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 183657.8594 - mse: 183645.7344 - val_loss: 146812.2188 - val_mse: 146800.0000\nEpoch 208/1200\n\u001b[1m286/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 178333.8750 - mse: 178321.7188\nEpoch 208: val_loss did not improve from 143170.48438\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 178382.0000 - mse: 178369.8594 - val_loss: 145955.7812 - val_mse: 145943.5781\nEpoch 209/1200\n\u001b[1m288/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 177819.4844 - mse: 177807.2344\nEpoch 209: val_loss did not improve from 143170.48438\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 177875.6250 - mse: 177863.3750 - val_loss: 144855.7188 - val_mse: 144843.5156\nEpoch 210/1200\n\u001b[1m292/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 176395.3125 - mse: 176383.1094\nEpoch 210: val_loss did not improve from 143170.48438\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 176442.8281 - mse: 176430.6406 - val_loss: 146142.0625 - val_mse: 146129.8281\nEpoch 211/1200\n\u001b[1m290/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 182675.4531 - mse: 182663.2500\nEpoch 211: val_loss did not improve from 143170.48438\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 182614.8438 - mse: 182602.6562 - val_loss: 145201.1250 - val_mse: 145188.9219\nEpoch 212/1200\n\u001b[1m293/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 181721.4844 - mse: 181709.2188\nEpoch 212: val_loss did not improve from 143170.48438\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 181674.2500 - mse: 181662.0000 - val_loss: 152497.1562 - val_mse: 152484.8906\nEpoch 213/1200\n\u001b[1m290/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 175858.2969 - mse: 175846.0625\nEpoch 213: val_loss did not improve from 143170.48438\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 175903.6562 - mse: 175891.4219 - val_loss: 143697.7031 - val_mse: 143685.4375\nEpoch 214/1200\n\u001b[1m294/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 178040.0312 - mse: 178027.7500\nEpoch 214: val_loss improved from 143170.48438 to 142006.81250, saving model to /kaggle/working/weights.keras\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 178102.0000 - mse: 178089.7188 - val_loss: 142006.8125 - val_mse: 141994.6094\nEpoch 215/1200\n\u001b[1m282/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 177727.4062 - mse: 177715.2188\nEpoch 215: val_loss did not improve from 142006.81250\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 177707.7500 - mse: 177695.5625 - val_loss: 144094.1094 - val_mse: 144081.8438\nEpoch 216/1200\n\u001b[1m293/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 175068.8125 - mse: 175056.5156\nEpoch 216: val_loss did not improve from 142006.81250\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 175075.8906 - mse: 175063.5938 - val_loss: 148231.7188 - val_mse: 148219.4688\nEpoch 217/1200\n\u001b[1m281/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 176877.4844 - mse: 176865.2188\nEpoch 217: val_loss did not improve from 142006.81250\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 176883.0156 - mse: 176870.7344 - val_loss: 146164.7969 - val_mse: 146152.5156\nEpoch 218/1200\n\u001b[1m294/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 178596.1406 - mse: 178583.9219\nEpoch 218: val_loss did not improve from 142006.81250\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 178552.4375 - mse: 178540.2188 - val_loss: 143461.1250 - val_mse: 143448.8125\nEpoch 219/1200\n\u001b[1m274/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 175603.0938 - mse: 175590.7812\nEpoch 219: val_loss did not improve from 142006.81250\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 175521.1250 - mse: 175508.8125 - val_loss: 149249.9688 - val_mse: 149237.6719\nEpoch 220/1200\n\u001b[1m274/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 177640.7500 - mse: 177628.5156\nEpoch 220: val_loss did not improve from 142006.81250\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 177559.8750 - mse: 177547.6406 - val_loss: 144204.5469 - val_mse: 144192.2812\nEpoch 221/1200\n\u001b[1m293/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 177493.0156 - mse: 177480.7031\nEpoch 221: val_loss improved from 142006.81250 to 140824.31250, saving model to /kaggle/working/weights.keras\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 177468.7812 - mse: 177456.4531 - val_loss: 140824.3125 - val_mse: 140811.9688\nEpoch 222/1200\n\u001b[1m289/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 172453.4688 - mse: 172441.1719\nEpoch 222: val_loss did not improve from 140824.31250\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 172469.8750 - mse: 172457.5781 - val_loss: 147465.1875 - val_mse: 147452.8906\nEpoch 223/1200\n\u001b[1m295/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 176645.6094 - mse: 176633.2500\nEpoch 223: val_loss did not improve from 140824.31250\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 176624.0469 - mse: 176611.7031 - val_loss: 147095.6719 - val_mse: 147083.3750\nEpoch 224/1200\n\u001b[1m295/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 175795.2656 - mse: 175782.9531\nEpoch 224: val_loss did not improve from 140824.31250\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 175774.3750 - mse: 175762.0625 - val_loss: 149680.5938 - val_mse: 149668.2500\nEpoch 225/1200\n\u001b[1m292/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 171495.1719 - mse: 171482.8906\nEpoch 225: val_loss did not improve from 140824.31250\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 171549.7656 - mse: 171537.4844 - val_loss: 150557.0156 - val_mse: 150544.7031\nEpoch 226/1200\n\u001b[1m295/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 174444.2656 - mse: 174431.9219\nEpoch 226: val_loss did not improve from 140824.31250\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 174468.3438 - mse: 174456.0000 - val_loss: 140947.3438 - val_mse: 140935.0000\nEpoch 227/1200\n\u001b[1m295/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 176973.3906 - mse: 176961.0625\nEpoch 227: val_loss did not improve from 140824.31250\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 176944.3281 - mse: 176932.0000 - val_loss: 144094.6250 - val_mse: 144082.2656\nEpoch 228/1200\n\u001b[1m286/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 173985.2188 - mse: 173972.8906\nEpoch 228: val_loss improved from 140824.31250 to 140803.12500, saving model to /kaggle/working/weights.keras\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 173987.6562 - mse: 173975.3281 - val_loss: 140803.1250 - val_mse: 140790.8125\nEpoch 229/1200\n\u001b[1m292/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 175944.2344 - mse: 175931.8906\nEpoch 229: val_loss did not improve from 140803.12500\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 175881.7812 - mse: 175869.4219 - val_loss: 146329.3125 - val_mse: 146316.9219\nEpoch 230/1200\n\u001b[1m297/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 170140.1250 - mse: 170127.7188\nEpoch 230: val_loss did not improve from 140803.12500\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 170165.8750 - mse: 170153.4844 - val_loss: 148732.4062 - val_mse: 148720.0312\nEpoch 231/1200\n\u001b[1m298/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 168683.5469 - mse: 168671.1562\nEpoch 231: val_loss did not improve from 140803.12500\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 168709.7500 - mse: 168697.3750 - val_loss: 141747.3438 - val_mse: 141735.0312\nEpoch 232/1200\n\u001b[1m281/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 175536.3281 - mse: 175523.9375\nEpoch 232: val_loss did not improve from 140803.12500\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 175356.7656 - mse: 175344.3594 - val_loss: 142107.1406 - val_mse: 142094.7500\nEpoch 233/1200\n\u001b[1m293/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 175277.4531 - mse: 175265.0625\nEpoch 233: val_loss did not improve from 140803.12500\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 175271.0625 - mse: 175258.6719 - val_loss: 154639.1406 - val_mse: 154626.7656\nEpoch 234/1200\n\u001b[1m290/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 175775.2812 - mse: 175762.9531\nEpoch 234: val_loss did not improve from 140803.12500\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 175540.3750 - mse: 175528.0469 - val_loss: 141575.7969 - val_mse: 141563.4531\nEpoch 235/1200\n\u001b[1m284/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 172846.2500 - mse: 172833.9219\nEpoch 235: val_loss did not improve from 140803.12500\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 172823.9219 - mse: 172811.5938 - val_loss: 142862.6719 - val_mse: 142850.3125\nEpoch 236/1200\n\u001b[1m298/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 174759.4688 - mse: 174747.1250\nEpoch 236: val_loss did not improve from 140803.12500\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 174738.2812 - mse: 174725.9219 - val_loss: 142610.8594 - val_mse: 142598.4688\nEpoch 237/1200\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 169535.5781 - mse: 169523.2031\nEpoch 237: val_loss improved from 140803.12500 to 140222.64062, saving model to /kaggle/working/weights.keras\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 169545.0781 - mse: 169532.7031 - val_loss: 140222.6406 - val_mse: 140210.2656\nEpoch 238/1200\n\u001b[1m294/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 172719.8438 - mse: 172707.4688\nEpoch 238: val_loss did not improve from 140222.64062\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 172682.3594 - mse: 172670.0000 - val_loss: 141318.6562 - val_mse: 141306.2344\nEpoch 239/1200\n\u001b[1m296/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 168229.7500 - mse: 168217.3125\nEpoch 239: val_loss did not improve from 140222.64062\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 168264.6406 - mse: 168252.1875 - val_loss: 147323.4219 - val_mse: 147310.9688\nEpoch 240/1200\n\u001b[1m294/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 169794.8750 - mse: 169782.4688\nEpoch 240: val_loss did not improve from 140222.64062\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 169789.2188 - mse: 169776.8125 - val_loss: 145756.2188 - val_mse: 145743.8125\nEpoch 241/1200\n\u001b[1m294/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 172394.7656 - mse: 172382.3281\nEpoch 241: val_loss did not improve from 140222.64062\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 172392.5000 - mse: 172380.0781 - val_loss: 140548.9844 - val_mse: 140536.5156\nEpoch 242/1200\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 176183.4062 - mse: 176170.9844\nEpoch 242: val_loss did not improve from 140222.64062\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 176165.2812 - mse: 176152.8438 - val_loss: 146122.6719 - val_mse: 146110.2656\nEpoch 243/1200\n\u001b[1m289/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 165912.4219 - mse: 165900.0156\nEpoch 243: val_loss did not improve from 140222.64062\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 166061.6562 - mse: 166049.2656 - val_loss: 150886.3438 - val_mse: 150873.9531\nEpoch 244/1200\n\u001b[1m294/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 170255.7969 - mse: 170243.3750\nEpoch 244: val_loss did not improve from 140222.64062\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 170216.9688 - mse: 170204.5312 - val_loss: 146027.9531 - val_mse: 146015.4844\nEpoch 245/1200\n\u001b[1m283/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 172922.4688 - mse: 172910.0156\nEpoch 245: val_loss improved from 140222.64062 to 136703.21875, saving model to /kaggle/working/weights.keras\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 172785.7969 - mse: 172773.3438 - val_loss: 136703.2188 - val_mse: 136690.8125\nEpoch 246/1200\n\u001b[1m297/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 173138.6719 - mse: 173126.2344\nEpoch 246: val_loss did not improve from 136703.21875\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 173082.4844 - mse: 173070.0469 - val_loss: 145162.4375 - val_mse: 145149.9219\nEpoch 247/1200\n\u001b[1m293/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 166277.8438 - mse: 166265.3750\nEpoch 247: val_loss did not improve from 136703.21875\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 166291.8594 - mse: 166279.3906 - val_loss: 153139.1562 - val_mse: 153126.7188\nEpoch 248/1200\n\u001b[1m293/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 167669.7500 - mse: 167657.2656\nEpoch 248: val_loss did not improve from 136703.21875\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 167629.8750 - mse: 167617.3906 - val_loss: 152255.8906 - val_mse: 152243.4375\nEpoch 249/1200\n\u001b[1m292/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 165049.7969 - mse: 165037.2969\nEpoch 249: val_loss did not improve from 136703.21875\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 165112.0312 - mse: 165099.5312 - val_loss: 142151.5000 - val_mse: 142139.0156\nEpoch 250/1200\n\u001b[1m293/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 167083.0156 - mse: 167070.5312\nEpoch 250: val_loss did not improve from 136703.21875\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 167156.6094 - mse: 167144.1250 - val_loss: 143163.8906 - val_mse: 143151.4375\nEpoch 251/1200\n\u001b[1m291/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 166310.7812 - mse: 166298.2812\nEpoch 251: val_loss did not improve from 136703.21875\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 166303.2344 - mse: 166290.7500 - val_loss: 143989.1875 - val_mse: 143976.7344\nEpoch 252/1200\n\u001b[1m293/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 167168.0312 - mse: 167155.5312\nEpoch 252: val_loss did not improve from 136703.21875\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 167185.6875 - mse: 167173.1875 - val_loss: 140288.2812 - val_mse: 140275.7969\nEpoch 253/1200\n\u001b[1m290/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 166601.1406 - mse: 166588.6250\nEpoch 253: val_loss did not improve from 136703.21875\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 166574.4844 - mse: 166561.9531 - val_loss: 151651.1875 - val_mse: 151638.6875\nEpoch 254/1200\n\u001b[1m290/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 167941.3906 - mse: 167928.9219\nEpoch 254: val_loss did not improve from 136703.21875\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 167959.4688 - mse: 167947.0000 - val_loss: 146003.7812 - val_mse: 145991.2812\nEpoch 255/1200\n\u001b[1m290/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 165274.7656 - mse: 165262.2812\nEpoch 255: val_loss did not improve from 136703.21875\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 165356.2969 - mse: 165343.7969 - val_loss: 148356.2969 - val_mse: 148343.8281\nEpoch 256/1200\n\u001b[1m289/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 167075.2031 - mse: 167062.6875\nEpoch 256: val_loss did not improve from 136703.21875\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 167037.9531 - mse: 167025.4375 - val_loss: 144056.5000 - val_mse: 144043.9688\nEpoch 257/1200\n\u001b[1m289/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 163176.8125 - mse: 163164.3125\nEpoch 257: val_loss did not improve from 136703.21875\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 163327.5156 - mse: 163315.0156 - val_loss: 146648.0156 - val_mse: 146635.4844\nEpoch 258/1200\n\u001b[1m289/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 162388.1250 - mse: 162375.5469\nEpoch 258: val_loss did not improve from 136703.21875\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 162538.3281 - mse: 162525.7656 - val_loss: 143800.8906 - val_mse: 143788.3438\nEpoch 259/1200\n\u001b[1m287/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 167691.8750 - mse: 167679.3594\nEpoch 259: val_loss did not improve from 136703.21875\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 167740.4375 - mse: 167727.9219 - val_loss: 144595.6562 - val_mse: 144583.1250\nEpoch 260/1200\n\u001b[1m275/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 164134.2188 - mse: 164121.6875\nEpoch 260: val_loss did not improve from 136703.21875\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 164329.6562 - mse: 164317.1406 - val_loss: 144708.2031 - val_mse: 144695.6406\nEpoch 261/1200\n\u001b[1m291/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 167331.5938 - mse: 167319.0312\nEpoch 261: val_loss did not improve from 136703.21875\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 167270.9219 - mse: 167258.3750 - val_loss: 144116.8906 - val_mse: 144104.3438\nEpoch 262/1200\n\u001b[1m287/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 161765.7812 - mse: 161753.2031\nEpoch 262: val_loss did not improve from 136703.21875\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 161886.6875 - mse: 161874.1094 - val_loss: 142209.4062 - val_mse: 142196.8594\nEpoch 263/1200\n\u001b[1m286/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 168515.4375 - mse: 168502.8906\nEpoch 263: val_loss did not improve from 136703.21875\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 168413.9688 - mse: 168401.4375 - val_loss: 147726.0469 - val_mse: 147713.5000\nEpoch 264/1200\n\u001b[1m288/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 166171.7656 - mse: 166159.2656\nEpoch 264: val_loss did not improve from 136703.21875\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 166123.2188 - mse: 166110.7188 - val_loss: 149967.1875 - val_mse: 149954.5781\nEpoch 265/1200\n\u001b[1m287/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 166755.5625 - mse: 166743.0000\nEpoch 265: val_loss did not improve from 136703.21875\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 166658.3125 - mse: 166645.7500 - val_loss: 152016.1094 - val_mse: 152003.5156\nEpoch 266/1200\n\u001b[1m285/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 165240.4844 - mse: 165227.9062\nEpoch 266: val_loss did not improve from 136703.21875\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 165311.8906 - mse: 165299.3125 - val_loss: 145315.5156 - val_mse: 145302.9375\nEpoch 267/1200\n\u001b[1m285/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 159429.6406 - mse: 159417.0469\nEpoch 267: val_loss did not improve from 136703.21875\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 159709.7969 - mse: 159697.2031 - val_loss: 145162.7344 - val_mse: 145150.1250\nEpoch 268/1200\n\u001b[1m289/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 165533.9375 - mse: 165521.3438\nEpoch 268: val_loss did not improve from 136703.21875\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 165485.0938 - mse: 165472.5000 - val_loss: 140149.2031 - val_mse: 140136.5938\nEpoch 269/1200\n\u001b[1m285/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 157347.1250 - mse: 157334.5469\nEpoch 269: val_loss did not improve from 136703.21875\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 157694.1250 - mse: 157681.5625 - val_loss: 143587.7969 - val_mse: 143575.2031\nEpoch 270/1200\n\u001b[1m284/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 160748.1250 - mse: 160735.5469\nEpoch 270: val_loss did not improve from 136703.21875\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 160948.2812 - mse: 160935.7031 - val_loss: 142559.7812 - val_mse: 142547.2031\nEpoch 271/1200\n\u001b[1m285/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 161047.7656 - mse: 161035.2031\nEpoch 271: val_loss did not improve from 136703.21875\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 161153.4375 - mse: 161140.8594 - val_loss: 143479.7031 - val_mse: 143467.0781\nEpoch 272/1200\n\u001b[1m283/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 161336.0625 - mse: 161323.4531\nEpoch 272: val_loss did not improve from 136703.21875\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 161440.8594 - mse: 161428.2344 - val_loss: 148873.4688 - val_mse: 148860.8750\nEpoch 273/1200\n\u001b[1m289/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 163154.6562 - mse: 163142.0625\nEpoch 273: val_loss improved from 136703.21875 to 136322.82812, saving model to /kaggle/working/weights.keras\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 163150.3906 - mse: 163137.7969 - val_loss: 136322.8281 - val_mse: 136310.2188\nEpoch 274/1200\n\u001b[1m298/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 164200.8750 - mse: 164188.2656\nEpoch 274: val_loss did not improve from 136322.82812\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 164188.7656 - mse: 164176.1562 - val_loss: 145493.6719 - val_mse: 145481.0469\nEpoch 275/1200\n\u001b[1m288/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 162376.2656 - mse: 162363.6719\nEpoch 275: val_loss did not improve from 136322.82812\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 162391.4375 - mse: 162378.8438 - val_loss: 147694.2031 - val_mse: 147681.5938\nEpoch 276/1200\n\u001b[1m283/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 164065.8438 - mse: 164053.2188\nEpoch 276: val_loss did not improve from 136322.82812\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 163925.5781 - mse: 163912.9531 - val_loss: 151053.9688 - val_mse: 151041.3281\nEpoch 277/1200\n\u001b[1m289/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 158201.1562 - mse: 158188.5156\nEpoch 277: val_loss did not improve from 136322.82812\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 158308.5156 - mse: 158295.8906 - val_loss: 143171.7812 - val_mse: 143159.1406\nEpoch 278/1200\n\u001b[1m288/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 163400.3906 - mse: 163387.7500\nEpoch 278: val_loss did not improve from 136322.82812\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 163338.0938 - mse: 163325.4531 - val_loss: 138862.7656 - val_mse: 138850.1406\nEpoch 279/1200\n\u001b[1m287/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 160517.0000 - mse: 160504.3594\nEpoch 279: val_loss did not improve from 136322.82812\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 160513.7188 - mse: 160501.0781 - val_loss: 154521.2500 - val_mse: 154508.6250\nEpoch 280/1200\n\u001b[1m285/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 162473.0000 - mse: 162460.3594\nEpoch 280: val_loss did not improve from 136322.82812\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 162483.0156 - mse: 162470.3750 - val_loss: 143515.7812 - val_mse: 143503.1406\nEpoch 281/1200\n\u001b[1m289/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 159993.1562 - mse: 159980.5000\nEpoch 281: val_loss did not improve from 136322.82812\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 160042.5000 - mse: 160029.8438 - val_loss: 140167.9531 - val_mse: 140155.3281\nEpoch 282/1200\n\u001b[1m292/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 162357.5938 - mse: 162344.9688\nEpoch 282: val_loss did not improve from 136322.82812\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 162320.8750 - mse: 162308.2500 - val_loss: 152917.5938 - val_mse: 152904.9219\nEpoch 283/1200\n\u001b[1m293/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 159870.7500 - mse: 159858.1250\nEpoch 283: val_loss did not improve from 136322.82812\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 159892.5000 - mse: 159879.8594 - val_loss: 150431.8438 - val_mse: 150419.1562\nEpoch 284/1200\n\u001b[1m291/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 161928.8594 - mse: 161916.1875\nEpoch 284: val_loss did not improve from 136322.82812\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 161892.0000 - mse: 161879.3438 - val_loss: 142761.5938 - val_mse: 142748.9688\nEpoch 285/1200\n\u001b[1m287/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 159550.7344 - mse: 159538.0625\nEpoch 285: val_loss did not improve from 136322.82812\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 159504.8281 - mse: 159492.1562 - val_loss: 141727.8750 - val_mse: 141715.2500\nEpoch 286/1200\n\u001b[1m286/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 160514.7031 - mse: 160502.0312\nEpoch 286: val_loss did not improve from 136322.82812\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 160437.5781 - mse: 160424.8906 - val_loss: 139073.7344 - val_mse: 139061.0469\nEpoch 287/1200\n\u001b[1m287/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 162867.0938 - mse: 162854.4219\nEpoch 287: val_loss did not improve from 136322.82812\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 162829.9219 - mse: 162817.2500 - val_loss: 141708.4375 - val_mse: 141695.8438\nEpoch 288/1200\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 157912.9062 - mse: 157900.2656\nEpoch 288: val_loss did not improve from 136322.82812\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 157922.9219 - mse: 157910.2969 - val_loss: 143198.4531 - val_mse: 143185.7656\nEpoch 289/1200\n\u001b[1m286/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 161131.6875 - mse: 161119.0000\nEpoch 289: val_loss improved from 136322.82812 to 132890.53125, saving model to /kaggle/working/weights.keras\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 161172.9375 - mse: 161160.2500 - val_loss: 132890.5312 - val_mse: 132877.8594\nEpoch 290/1200\n\u001b[1m285/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 160019.6250 - mse: 160006.9375\nEpoch 290: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 160095.9531 - mse: 160083.2656 - val_loss: 140049.3906 - val_mse: 140036.6875\nEpoch 291/1200\n\u001b[1m286/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 159179.2344 - mse: 159166.5625\nEpoch 291: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 159279.2188 - mse: 159266.5469 - val_loss: 144801.1719 - val_mse: 144788.5156\nEpoch 292/1200\n\u001b[1m285/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 164237.2969 - mse: 164224.6406\nEpoch 292: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 164031.8281 - mse: 164019.1719 - val_loss: 149269.0938 - val_mse: 149256.3906\nEpoch 293/1200\n\u001b[1m283/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 160591.1719 - mse: 160578.4844\nEpoch 293: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 160615.5156 - mse: 160602.8281 - val_loss: 143908.4531 - val_mse: 143895.7344\nEpoch 294/1200\n\u001b[1m289/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 162028.4844 - mse: 162015.7812\nEpoch 294: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 161992.5312 - mse: 161979.8281 - val_loss: 145996.6875 - val_mse: 145984.0000\nEpoch 295/1200\n\u001b[1m292/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 158256.1406 - mse: 158243.4531\nEpoch 295: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 158272.3906 - mse: 158259.6875 - val_loss: 141667.5156 - val_mse: 141654.8125\nEpoch 296/1200\n\u001b[1m287/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 161355.8906 - mse: 161343.1875\nEpoch 296: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 161238.8281 - mse: 161226.1250 - val_loss: 137278.9531 - val_mse: 137266.2031\nEpoch 297/1200\n\u001b[1m292/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 158464.8281 - mse: 158452.1250\nEpoch 297: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 158517.2031 - mse: 158504.4844 - val_loss: 145810.6406 - val_mse: 145797.9375\nEpoch 298/1200\n\u001b[1m295/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 159836.9531 - mse: 159824.2188\nEpoch 298: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 159806.5312 - mse: 159793.7969 - val_loss: 147555.0938 - val_mse: 147542.3594\nEpoch 299/1200\n\u001b[1m295/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 162318.2344 - mse: 162305.5312\nEpoch 299: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 162227.3438 - mse: 162214.6406 - val_loss: 145400.7188 - val_mse: 145388.0156\nEpoch 300/1200\n\u001b[1m295/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 157403.3906 - mse: 157390.6562\nEpoch 300: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 157427.6250 - mse: 157414.8906 - val_loss: 143709.2500 - val_mse: 143696.5000\nEpoch 301/1200\n\u001b[1m290/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 151843.8281 - mse: 151831.0938\nEpoch 301: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 151994.1250 - mse: 151981.3906 - val_loss: 142752.7969 - val_mse: 142740.0469\nEpoch 302/1200\n\u001b[1m299/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 157582.2656 - mse: 157569.5156\nEpoch 302: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 157598.6562 - mse: 157585.9062 - val_loss: 145069.2188 - val_mse: 145056.4844\nEpoch 303/1200\n\u001b[1m292/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 156946.9844 - mse: 156934.2344\nEpoch 303: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 157058.3125 - mse: 157045.5625 - val_loss: 147210.7344 - val_mse: 147198.0000\nEpoch 304/1200\n\u001b[1m293/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 164564.1719 - mse: 164551.4375\nEpoch 304: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 164476.0156 - mse: 164463.2812 - val_loss: 144779.5000 - val_mse: 144766.7656\nEpoch 305/1200\n\u001b[1m290/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 156048.6562 - mse: 156035.8906\nEpoch 305: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 156056.0469 - mse: 156043.2969 - val_loss: 145701.2188 - val_mse: 145688.4375\nEpoch 306/1200\n\u001b[1m296/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 159669.3750 - mse: 159656.5938\nEpoch 306: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 159656.1562 - mse: 159643.3750 - val_loss: 138554.0312 - val_mse: 138541.2656\nEpoch 307/1200\n\u001b[1m297/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 158868.8125 - mse: 158856.0469\nEpoch 307: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 158856.8750 - mse: 158844.1250 - val_loss: 138014.3281 - val_mse: 138001.5469\nEpoch 308/1200\n\u001b[1m297/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 156405.9219 - mse: 156393.1406\nEpoch 308: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 156421.8125 - mse: 156409.0312 - val_loss: 140986.5000 - val_mse: 140973.7344\nEpoch 309/1200\n\u001b[1m294/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 160233.3594 - mse: 160220.5781\nEpoch 309: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 160184.3906 - mse: 160171.6094 - val_loss: 147390.3438 - val_mse: 147377.5625\nEpoch 310/1200\n\u001b[1m292/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 153961.9844 - mse: 153949.2344\nEpoch 310: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 154063.6562 - mse: 154050.9062 - val_loss: 146318.2031 - val_mse: 146305.3906\nEpoch 311/1200\n\u001b[1m293/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 155994.4062 - mse: 155981.5938\nEpoch 311: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 156006.0781 - mse: 155993.2812 - val_loss: 145013.1875 - val_mse: 145000.3906\nEpoch 312/1200\n\u001b[1m294/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 155923.9219 - mse: 155911.1250\nEpoch 312: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 155924.9844 - mse: 155912.1875 - val_loss: 148683.1562 - val_mse: 148670.3594\nEpoch 313/1200\n\u001b[1m279/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 158459.2812 - mse: 158446.4688\nEpoch 313: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 158143.4219 - mse: 158130.6250 - val_loss: 139123.7812 - val_mse: 139110.9688\nEpoch 314/1200\n\u001b[1m290/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 154578.5000 - mse: 154565.6875\nEpoch 314: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 154672.5625 - mse: 154659.7656 - val_loss: 142454.6094 - val_mse: 142441.7969\nEpoch 315/1200\n\u001b[1m292/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 155250.6562 - mse: 155237.8438\nEpoch 315: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 155307.7969 - mse: 155294.9844 - val_loss: 156402.9844 - val_mse: 156390.1875\nEpoch 316/1200\n\u001b[1m293/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 156151.5781 - mse: 156138.7812\nEpoch 316: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 156235.5625 - mse: 156222.7656 - val_loss: 145260.1875 - val_mse: 145247.3906\nEpoch 317/1200\n\u001b[1m283/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 156727.7188 - mse: 156714.9062\nEpoch 317: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 156619.6875 - mse: 156606.8906 - val_loss: 145569.8594 - val_mse: 145557.0469\nEpoch 318/1200\n\u001b[1m298/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 156077.1875 - mse: 156064.3750\nEpoch 318: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 156092.1406 - mse: 156079.3281 - val_loss: 150685.0938 - val_mse: 150672.2969\nEpoch 319/1200\n\u001b[1m276/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 157613.4219 - mse: 157600.6094\nEpoch 319: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 157545.2656 - mse: 157532.4531 - val_loss: 142051.3281 - val_mse: 142038.5000\nEpoch 320/1200\n\u001b[1m290/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 157864.8281 - mse: 157852.0000\nEpoch 320: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 157839.0938 - mse: 157826.2656 - val_loss: 142881.3281 - val_mse: 142868.5000\nEpoch 321/1200\n\u001b[1m295/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 157581.8594 - mse: 157569.0312\nEpoch 321: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 157571.3750 - mse: 157558.5469 - val_loss: 153076.4219 - val_mse: 153063.5938\nEpoch 322/1200\n\u001b[1m299/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 155549.7656 - mse: 155536.9219\nEpoch 322: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 155554.6875 - mse: 155541.8438 - val_loss: 145071.7812 - val_mse: 145058.9688\nEpoch 323/1200\n\u001b[1m295/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 157795.7812 - mse: 157782.9688\nEpoch 323: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 157792.9375 - mse: 157780.1250 - val_loss: 150337.0156 - val_mse: 150324.1875\nEpoch 324/1200\n\u001b[1m293/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 154425.1719 - mse: 154412.3125\nEpoch 324: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 154480.1250 - mse: 154467.2656 - val_loss: 140710.6250 - val_mse: 140697.7969\nEpoch 325/1200\n\u001b[1m296/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 158776.4375 - mse: 158763.5938\nEpoch 325: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 158771.9531 - mse: 158759.0938 - val_loss: 136915.6875 - val_mse: 136902.8750\nEpoch 326/1200\n\u001b[1m297/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 151304.9844 - mse: 151292.1406\nEpoch 326: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 151376.1094 - mse: 151363.2656 - val_loss: 138702.6719 - val_mse: 138689.7969\nEpoch 327/1200\n\u001b[1m297/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 152640.7031 - mse: 152627.8438\nEpoch 327: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 152660.0469 - mse: 152647.1875 - val_loss: 142320.0156 - val_mse: 142307.1094\nEpoch 328/1200\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 156331.3281 - mse: 156318.4531\nEpoch 328: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 156335.3125 - mse: 156322.4375 - val_loss: 136992.7188 - val_mse: 136979.8438\nEpoch 329/1200\n\u001b[1m299/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 159411.6562 - mse: 159398.7812\nEpoch 329: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 159403.1875 - mse: 159390.3125 - val_loss: 146324.1250 - val_mse: 146311.2812\nEpoch 330/1200\n\u001b[1m285/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 159341.6406 - mse: 159328.7969\nEpoch 330: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 159404.9219 - mse: 159392.0781 - val_loss: 153698.0781 - val_mse: 153685.2344\nEpoch 331/1200\n\u001b[1m295/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 154299.9531 - mse: 154287.1094\nEpoch 331: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 154294.7500 - mse: 154281.9062 - val_loss: 142710.3281 - val_mse: 142697.4531\nEpoch 332/1200\n\u001b[1m292/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 154875.5000 - mse: 154862.6406\nEpoch 332: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 154901.6875 - mse: 154888.8438 - val_loss: 143510.0312 - val_mse: 143497.1406\nEpoch 333/1200\n\u001b[1m274/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 155890.2500 - mse: 155877.3594\nEpoch 333: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 155844.8125 - mse: 155831.9375 - val_loss: 142188.5938 - val_mse: 142175.6875\nEpoch 334/1200\n\u001b[1m283/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 151319.3281 - mse: 151306.4219\nEpoch 334: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 151381.7656 - mse: 151368.8750 - val_loss: 148047.3594 - val_mse: 148034.5000\nEpoch 335/1200\n\u001b[1m291/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 156001.5938 - mse: 155988.7188\nEpoch 335: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 155980.7656 - mse: 155967.8750 - val_loss: 137934.7188 - val_mse: 137921.8281\nEpoch 336/1200\n\u001b[1m280/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 149864.7500 - mse: 149851.8594\nEpoch 336: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 150292.5469 - mse: 150279.6406 - val_loss: 144150.4219 - val_mse: 144137.5156\nEpoch 337/1200\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 149857.3594 - mse: 149844.4844\nEpoch 337: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 149870.3906 - mse: 149857.5000 - val_loss: 143493.8594 - val_mse: 143480.9531\nEpoch 338/1200\n\u001b[1m293/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 154595.4219 - mse: 154582.5156\nEpoch 338: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 154626.9844 - mse: 154614.0781 - val_loss: 141083.8906 - val_mse: 141070.9844\nEpoch 339/1200\n\u001b[1m294/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 155731.9688 - mse: 155719.0781\nEpoch 339: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 155697.5156 - mse: 155684.6250 - val_loss: 150316.0156 - val_mse: 150303.1094\nEpoch 340/1200\n\u001b[1m279/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 156187.5781 - mse: 156174.6719\nEpoch 340: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 156035.9062 - mse: 156022.9844 - val_loss: 139231.6250 - val_mse: 139218.7031\nEpoch 341/1200\n\u001b[1m276/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 151324.5938 - mse: 151311.7344\nEpoch 341: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 151406.5625 - mse: 151393.7031 - val_loss: 139804.7969 - val_mse: 139791.8750\nEpoch 342/1200\n\u001b[1m276/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 154452.4219 - mse: 154439.5469\nEpoch 342: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 154317.6406 - mse: 154304.7500 - val_loss: 146522.3438 - val_mse: 146509.4219\nEpoch 343/1200\n\u001b[1m275/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 156763.8281 - mse: 156750.9062\nEpoch 343: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 156715.8594 - mse: 156702.9375 - val_loss: 143143.4844 - val_mse: 143130.5312\nEpoch 344/1200\n\u001b[1m297/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 152322.3906 - mse: 152309.4531\nEpoch 344: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 152356.2969 - mse: 152343.3750 - val_loss: 146614.7031 - val_mse: 146601.7969\nEpoch 345/1200\n\u001b[1m289/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 151191.3906 - mse: 151178.4844\nEpoch 345: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 151261.5625 - mse: 151248.6406 - val_loss: 140587.1719 - val_mse: 140574.2500\nEpoch 346/1200\n\u001b[1m294/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 156581.5312 - mse: 156568.5625\nEpoch 346: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 156545.7344 - mse: 156532.7812 - val_loss: 147869.5312 - val_mse: 147856.5938\nEpoch 347/1200\n\u001b[1m285/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 153480.0625 - mse: 153467.0938\nEpoch 347: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 153414.1562 - mse: 153401.1875 - val_loss: 133193.3750 - val_mse: 133180.4531\nEpoch 348/1200\n\u001b[1m298/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 153992.9375 - mse: 153979.9844\nEpoch 348: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 153972.0781 - mse: 153959.1250 - val_loss: 145505.7500 - val_mse: 145492.7500\nEpoch 349/1200\n\u001b[1m281/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 154173.1250 - mse: 154160.1875\nEpoch 349: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 154183.3906 - mse: 154170.4375 - val_loss: 133321.8125 - val_mse: 133308.8750\nEpoch 350/1200\n\u001b[1m289/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 152646.0938 - mse: 152633.1875\nEpoch 350: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 152608.7812 - mse: 152595.8750 - val_loss: 136374.3281 - val_mse: 136361.3594\nEpoch 351/1200\n\u001b[1m290/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 154472.8125 - mse: 154459.8594\nEpoch 351: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 154492.8594 - mse: 154479.8906 - val_loss: 143294.7344 - val_mse: 143281.7969\nEpoch 352/1200\n\u001b[1m297/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 148689.6250 - mse: 148676.6875\nEpoch 352: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 148729.5625 - mse: 148716.6094 - val_loss: 158635.0156 - val_mse: 158622.0312\nEpoch 353/1200\n\u001b[1m279/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 153595.5781 - mse: 153582.6094\nEpoch 353: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 153645.4219 - mse: 153632.4531 - val_loss: 137181.7031 - val_mse: 137168.7031\nEpoch 354/1200\n\u001b[1m286/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 149789.0781 - mse: 149776.1250\nEpoch 354: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 149964.5000 - mse: 149951.5469 - val_loss: 146524.2344 - val_mse: 146511.2344\nEpoch 355/1200\n\u001b[1m274/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 151558.2031 - mse: 151545.2500\nEpoch 355: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 151619.6875 - mse: 151606.7500 - val_loss: 143005.8281 - val_mse: 142992.8438\nEpoch 356/1200\n\u001b[1m282/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 152744.9375 - mse: 152731.9531\nEpoch 356: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 152702.4844 - mse: 152689.4844 - val_loss: 144782.8438 - val_mse: 144769.9219\nEpoch 357/1200\n\u001b[1m290/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 154318.0781 - mse: 154305.1250\nEpoch 357: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 154322.6875 - mse: 154309.7500 - val_loss: 140554.1875 - val_mse: 140541.2344\nEpoch 358/1200\n\u001b[1m297/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 154330.5469 - mse: 154317.5625\nEpoch 358: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 154307.2656 - mse: 154294.2812 - val_loss: 142180.2500 - val_mse: 142167.2969\nEpoch 359/1200\n\u001b[1m278/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 154338.7812 - mse: 154325.8125\nEpoch 359: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 154197.7500 - mse: 154184.7812 - val_loss: 145031.7812 - val_mse: 145018.8125\nEpoch 360/1200\n\u001b[1m297/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 149083.6250 - mse: 149070.6250\nEpoch 360: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 149122.1406 - mse: 149109.1406 - val_loss: 140071.2344 - val_mse: 140058.2500\nEpoch 361/1200\n\u001b[1m285/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 157320.0156 - mse: 157306.9531\nEpoch 361: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 157137.8125 - mse: 157124.7500 - val_loss: 143864.3906 - val_mse: 143851.3438\nEpoch 362/1200\n\u001b[1m294/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 151349.7656 - mse: 151336.7344\nEpoch 362: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 151411.1562 - mse: 151398.1250 - val_loss: 138925.4531 - val_mse: 138912.4062\nEpoch 363/1200\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 152657.7344 - mse: 152644.7188\nEpoch 363: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 152658.7344 - mse: 152645.7188 - val_loss: 146318.7656 - val_mse: 146305.7812\nEpoch 364/1200\n\u001b[1m294/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 152725.0781 - mse: 152712.0469\nEpoch 364: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 152722.3750 - mse: 152709.3438 - val_loss: 138466.0938 - val_mse: 138453.0625\nEpoch 365/1200\n\u001b[1m297/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 150377.1875 - mse: 150364.1719\nEpoch 365: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 150394.3438 - mse: 150381.3281 - val_loss: 154085.8750 - val_mse: 154072.8438\nEpoch 366/1200\n\u001b[1m292/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 152788.8906 - mse: 152775.8594\nEpoch 366: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 152750.4219 - mse: 152737.3906 - val_loss: 149492.0469 - val_mse: 149478.9844\nEpoch 367/1200\n\u001b[1m294/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 152759.2031 - mse: 152746.1406\nEpoch 367: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 152722.8125 - mse: 152709.7656 - val_loss: 140428.5312 - val_mse: 140415.4844\nEpoch 368/1200\n\u001b[1m293/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 152618.9844 - mse: 152605.9688\nEpoch 368: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 152604.7031 - mse: 152591.6875 - val_loss: 148350.3906 - val_mse: 148337.3281\nEpoch 369/1200\n\u001b[1m286/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 152680.4531 - mse: 152667.4062\nEpoch 369: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 152616.0312 - mse: 152602.9688 - val_loss: 146867.4531 - val_mse: 146854.3750\nEpoch 370/1200\n\u001b[1m287/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 149620.6250 - mse: 149607.5938\nEpoch 370: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 149696.3125 - mse: 149683.2656 - val_loss: 149685.0312 - val_mse: 149671.9531\nEpoch 371/1200\n\u001b[1m294/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 152617.2188 - mse: 152604.1719\nEpoch 371: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 152535.8438 - mse: 152522.7969 - val_loss: 141177.8750 - val_mse: 141164.8281\nEpoch 372/1200\n\u001b[1m293/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 151884.2969 - mse: 151871.2344\nEpoch 372: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 151874.5312 - mse: 151861.4688 - val_loss: 148730.4375 - val_mse: 148717.3750\nEpoch 373/1200\n\u001b[1m285/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 149168.5156 - mse: 149155.4219\nEpoch 373: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 149338.5156 - mse: 149325.4219 - val_loss: 145354.9688 - val_mse: 145341.9531\nEpoch 374/1200\n\u001b[1m295/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 155262.2188 - mse: 155249.1562\nEpoch 374: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 155205.3125 - mse: 155192.2656 - val_loss: 147657.7188 - val_mse: 147644.6250\nEpoch 375/1200\n\u001b[1m286/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 155065.2344 - mse: 155052.1719\nEpoch 375: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 154992.9531 - mse: 154979.8906 - val_loss: 142369.4844 - val_mse: 142356.4219\nEpoch 376/1200\n\u001b[1m285/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 151179.4062 - mse: 151166.2969\nEpoch 376: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 151207.8281 - mse: 151194.7188 - val_loss: 145708.4844 - val_mse: 145695.4219\nEpoch 377/1200\n\u001b[1m279/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 153709.9375 - mse: 153696.8750\nEpoch 377: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 153637.0625 - mse: 153624.0156 - val_loss: 142188.8438 - val_mse: 142175.8125\nEpoch 378/1200\n\u001b[1m277/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 153619.5469 - mse: 153606.5156\nEpoch 378: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 153546.5469 - mse: 153533.5312 - val_loss: 145079.1406 - val_mse: 145066.0938\nEpoch 379/1200\n\u001b[1m297/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 149025.9062 - mse: 149012.8281\nEpoch 379: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 149035.4844 - mse: 149022.4062 - val_loss: 141830.6562 - val_mse: 141817.5625\nEpoch 380/1200\n\u001b[1m280/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 149540.4531 - mse: 149527.3750\nEpoch 380: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 149602.5469 - mse: 149589.4531 - val_loss: 149302.4688 - val_mse: 149289.3906\nEpoch 381/1200\n\u001b[1m278/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 148709.0781 - mse: 148695.9375\nEpoch 381: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 148676.0625 - mse: 148662.9219 - val_loss: 148707.3750 - val_mse: 148694.2812\nEpoch 382/1200\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 150222.6562 - mse: 150209.5781\nEpoch 382: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 150227.9688 - mse: 150214.8906 - val_loss: 150121.2969 - val_mse: 150108.1875\nEpoch 383/1200\n\u001b[1m299/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 155058.1719 - mse: 155045.0781\nEpoch 383: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 155040.5938 - mse: 155027.5156 - val_loss: 148065.9844 - val_mse: 148052.9219\nEpoch 384/1200\n\u001b[1m295/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 154734.9844 - mse: 154721.8906\nEpoch 384: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 154694.2344 - mse: 154681.1406 - val_loss: 144686.3750 - val_mse: 144673.2188\nEpoch 385/1200\n\u001b[1m297/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 148309.5469 - mse: 148296.4531\nEpoch 385: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 148331.4219 - mse: 148318.3281 - val_loss: 140898.8125 - val_mse: 140885.7344\nEpoch 386/1200\n\u001b[1m295/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 149247.4375 - mse: 149234.3594\nEpoch 386: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 149296.4062 - mse: 149283.3281 - val_loss: 143986.7969 - val_mse: 143973.7031\nEpoch 387/1200\n\u001b[1m288/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 151737.6094 - mse: 151724.4531\nEpoch 387: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 151674.6719 - mse: 151661.5156 - val_loss: 145296.8281 - val_mse: 145283.7188\nEpoch 388/1200\n\u001b[1m274/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 152719.5781 - mse: 152706.3906\nEpoch 388: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 152885.6250 - mse: 152872.4219 - val_loss: 140956.6875 - val_mse: 140943.5469\nEpoch 389/1200\n\u001b[1m296/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 149089.2344 - mse: 149076.1562\nEpoch 389: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 149115.7656 - mse: 149102.6875 - val_loss: 148664.3438 - val_mse: 148651.1719\nEpoch 390/1200\n\u001b[1m296/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 153767.5000 - mse: 153754.3906\nEpoch 390: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 153732.4219 - mse: 153719.3125 - val_loss: 143129.0312 - val_mse: 143115.9219\nEpoch 391/1200\n\u001b[1m289/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 152617.0625 - mse: 152603.9219\nEpoch 391: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 152480.1094 - mse: 152466.9688 - val_loss: 142094.7969 - val_mse: 142081.7031\nEpoch 392/1200\n\u001b[1m299/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 152901.6719 - mse: 152888.4688\nEpoch 392: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 152880.8906 - mse: 152867.6875 - val_loss: 144570.3125 - val_mse: 144557.2188\nEpoch 393/1200\n\u001b[1m287/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 153104.5312 - mse: 153091.4219\nEpoch 393: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 153080.3125 - mse: 153067.2031 - val_loss: 139086.2188 - val_mse: 139073.0469\nEpoch 394/1200\n\u001b[1m280/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 148249.4375 - mse: 148236.2812\nEpoch 394: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 148516.7500 - mse: 148503.5938 - val_loss: 150808.9531 - val_mse: 150795.8125\nEpoch 395/1200\n\u001b[1m288/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 148356.0781 - mse: 148342.9688\nEpoch 395: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 148390.7500 - mse: 148377.6406 - val_loss: 140947.0781 - val_mse: 140933.9062\nEpoch 396/1200\n\u001b[1m298/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 148580.0938 - mse: 148566.9688\nEpoch 396: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 148591.2031 - mse: 148578.0625 - val_loss: 150468.0781 - val_mse: 150454.9062\nEpoch 397/1200\n\u001b[1m298/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 149448.9062 - mse: 149435.7812\nEpoch 397: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 149470.1406 - mse: 149457.0156 - val_loss: 145631.5938 - val_mse: 145618.4375\nEpoch 398/1200\n\u001b[1m294/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 149334.7188 - mse: 149321.5938\nEpoch 398: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 149365.7344 - mse: 149352.6250 - val_loss: 145082.2656 - val_mse: 145069.1094\nEpoch 399/1200\n\u001b[1m297/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 153687.8281 - mse: 153674.7031\nEpoch 399: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 153652.3906 - mse: 153639.2656 - val_loss: 145667.2969 - val_mse: 145654.1094\nEpoch 400/1200\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 149133.9375 - mse: 149120.8281\nEpoch 400: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 149142.8281 - mse: 149129.7188 - val_loss: 149754.7500 - val_mse: 149741.6094\nEpoch 401/1200\n\u001b[1m294/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 144377.4531 - mse: 144364.2656\nEpoch 401: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 144462.4375 - mse: 144449.2500 - val_loss: 142579.3438 - val_mse: 142566.2031\nEpoch 402/1200\n\u001b[1m279/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 151524.5781 - mse: 151511.3438\nEpoch 402: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 151408.2500 - mse: 151395.0156 - val_loss: 154256.1719 - val_mse: 154243.0156\nEpoch 403/1200\n\u001b[1m279/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 152015.0000 - mse: 152001.8125\nEpoch 403: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 152016.8906 - mse: 152003.7031 - val_loss: 140677.0938 - val_mse: 140663.9688\nEpoch 404/1200\n\u001b[1m284/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 150793.8281 - mse: 150780.6562\nEpoch 404: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 150740.3594 - mse: 150727.1875 - val_loss: 135024.6094 - val_mse: 135011.4531\nEpoch 405/1200\n\u001b[1m285/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 147118.9531 - mse: 147105.7969\nEpoch 405: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 147157.5000 - mse: 147144.3438 - val_loss: 139296.2656 - val_mse: 139283.0781\nEpoch 406/1200\n\u001b[1m288/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 147913.8594 - mse: 147900.6875\nEpoch 406: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 147951.7188 - mse: 147938.5469 - val_loss: 148242.2656 - val_mse: 148229.1250\nEpoch 407/1200\n\u001b[1m298/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 147701.9062 - mse: 147688.6875\nEpoch 407: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 147719.7031 - mse: 147706.5000 - val_loss: 153024.2500 - val_mse: 153011.0781\nEpoch 408/1200\n\u001b[1m293/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 147618.2500 - mse: 147605.0625\nEpoch 408: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 147636.4844 - mse: 147623.2969 - val_loss: 146971.1250 - val_mse: 146957.9062\nEpoch 409/1200\n\u001b[1m289/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 143949.6562 - mse: 143936.4531\nEpoch 409: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 144103.8125 - mse: 144090.6094 - val_loss: 143476.6406 - val_mse: 143463.4062\nEpoch 410/1200\n\u001b[1m292/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 147857.5156 - mse: 147844.2969\nEpoch 410: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 147843.3750 - mse: 147830.1406 - val_loss: 147018.3125 - val_mse: 147005.1250\nEpoch 411/1200\n\u001b[1m290/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 145798.8125 - mse: 145785.6094\nEpoch 411: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 145876.5469 - mse: 145863.3438 - val_loss: 140065.1406 - val_mse: 140051.9844\nEpoch 412/1200\n\u001b[1m289/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 148294.4219 - mse: 148281.2031\nEpoch 412: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 148323.9688 - mse: 148310.7500 - val_loss: 149049.2344 - val_mse: 149036.0469\nEpoch 413/1200\n\u001b[1m299/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 151301.0312 - mse: 151287.8594\nEpoch 413: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 151302.9062 - mse: 151289.7344 - val_loss: 145767.6562 - val_mse: 145754.4688\nEpoch 414/1200\n\u001b[1m274/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 151651.4375 - mse: 151638.2188\nEpoch 414: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 151705.4375 - mse: 151692.2188 - val_loss: 137522.6250 - val_mse: 137509.4062\nEpoch 415/1200\n\u001b[1m284/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 145967.2344 - mse: 145953.9844\nEpoch 415: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 146024.1562 - mse: 146010.9062 - val_loss: 150965.3594 - val_mse: 150952.1094\nEpoch 416/1200\n\u001b[1m276/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 151731.0156 - mse: 151717.7812\nEpoch 416: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 151343.1406 - mse: 151329.9062 - val_loss: 139973.7188 - val_mse: 139960.5312\nEpoch 417/1200\n\u001b[1m286/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 149503.4219 - mse: 149490.1875\nEpoch 417: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 149564.9531 - mse: 149551.7188 - val_loss: 143761.7969 - val_mse: 143748.5469\nEpoch 418/1200\n\u001b[1m297/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 147623.9688 - mse: 147610.6875\nEpoch 418: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 147633.8906 - mse: 147620.6094 - val_loss: 138388.6875 - val_mse: 138375.4688\nEpoch 419/1200\n\u001b[1m297/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 149282.7656 - mse: 149269.5000\nEpoch 419: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 149265.9531 - mse: 149252.6875 - val_loss: 138328.6562 - val_mse: 138315.3750\nEpoch 420/1200\n\u001b[1m299/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 145326.1875 - mse: 145312.9219\nEpoch 420: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 145337.5000 - mse: 145324.2344 - val_loss: 145655.1406 - val_mse: 145641.9375\nEpoch 421/1200\n\u001b[1m297/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 148388.0156 - mse: 148374.7969\nEpoch 421: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 148380.7969 - mse: 148367.5781 - val_loss: 148591.2969 - val_mse: 148578.0312\nEpoch 422/1200\n\u001b[1m296/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 148652.6094 - mse: 148639.3125\nEpoch 422: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 148656.0781 - mse: 148642.7812 - val_loss: 144990.4062 - val_mse: 144977.1250\nEpoch 423/1200\n\u001b[1m298/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 151482.3750 - mse: 151469.1094\nEpoch 423: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 151447.7344 - mse: 151434.4688 - val_loss: 148361.9062 - val_mse: 148348.6875\nEpoch 424/1200\n\u001b[1m295/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 145914.8750 - mse: 145901.5938\nEpoch 424: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 145950.6875 - mse: 145937.4219 - val_loss: 140225.2969 - val_mse: 140211.9844\nEpoch 425/1200\n\u001b[1m295/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 144332.0000 - mse: 144318.6875\nEpoch 425: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 144344.5938 - mse: 144331.2969 - val_loss: 136161.1719 - val_mse: 136147.9219\nEpoch 426/1200\n\u001b[1m294/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 147084.0938 - mse: 147070.8438\nEpoch 426: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 147098.1562 - mse: 147084.9062 - val_loss: 142745.9062 - val_mse: 142732.6406\nEpoch 427/1200\n\u001b[1m282/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 144711.1406 - mse: 144697.8438\nEpoch 427: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 144862.4219 - mse: 144849.1094 - val_loss: 151463.1094 - val_mse: 151449.8281\nEpoch 428/1200\n\u001b[1m291/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 149323.5000 - mse: 149310.2031\nEpoch 428: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 149291.0000 - mse: 149277.7031 - val_loss: 143454.9062 - val_mse: 143441.6719\nEpoch 429/1200\n\u001b[1m284/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 146386.5938 - mse: 146373.2969\nEpoch 429: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 146450.8125 - mse: 146437.5312 - val_loss: 142455.1094 - val_mse: 142441.7969\nEpoch 430/1200\n\u001b[1m295/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 149368.0000 - mse: 149354.6875\nEpoch 430: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 149333.2500 - mse: 149319.9375 - val_loss: 145208.7188 - val_mse: 145195.4375\nEpoch 431/1200\n\u001b[1m295/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 152046.4844 - mse: 152033.1875\nEpoch 431: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 151931.2656 - mse: 151917.9844 - val_loss: 140155.6875 - val_mse: 140142.4062\nEpoch 432/1200\n\u001b[1m296/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 148395.2031 - mse: 148381.9375\nEpoch 432: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 148369.2344 - mse: 148355.9688 - val_loss: 150993.6094 - val_mse: 150980.3594\nEpoch 433/1200\n\u001b[1m298/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 147115.4688 - mse: 147102.2031\nEpoch 433: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 147117.3750 - mse: 147104.0938 - val_loss: 140847.8750 - val_mse: 140834.5938\nEpoch 434/1200\n\u001b[1m295/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 141072.2656 - mse: 141058.9844\nEpoch 434: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 141150.8125 - mse: 141137.5312 - val_loss: 146812.3125 - val_mse: 146799.0469\nEpoch 435/1200\n\u001b[1m294/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 147730.2031 - mse: 147716.9375\nEpoch 435: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 147739.0781 - mse: 147725.7969 - val_loss: 145577.7344 - val_mse: 145564.4531\nEpoch 436/1200\n\u001b[1m285/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 145702.2031 - mse: 145688.9062\nEpoch 436: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 145695.1719 - mse: 145681.8750 - val_loss: 141518.4688 - val_mse: 141505.1562\nEpoch 437/1200\n\u001b[1m288/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 145685.9375 - mse: 145672.6250\nEpoch 437: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 145758.4844 - mse: 145745.1719 - val_loss: 143940.5781 - val_mse: 143927.2812\nEpoch 438/1200\n\u001b[1m286/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 143318.1719 - mse: 143304.8594\nEpoch 438: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 143526.7031 - mse: 143513.3750 - val_loss: 145862.2188 - val_mse: 145848.8750\nEpoch 439/1200\n\u001b[1m296/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 148086.3594 - mse: 148073.0156\nEpoch 439: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 148068.0625 - mse: 148054.7188 - val_loss: 140648.1250 - val_mse: 140634.8125\nEpoch 440/1200\n\u001b[1m290/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 147983.3594 - mse: 147970.0469\nEpoch 440: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 147948.8594 - mse: 147935.5469 - val_loss: 140999.2500 - val_mse: 140985.9375\nEpoch 441/1200\n\u001b[1m293/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 144275.4844 - mse: 144262.1719\nEpoch 441: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 144294.0156 - mse: 144280.7031 - val_loss: 154737.0312 - val_mse: 154723.7031\nEpoch 442/1200\n\u001b[1m291/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 147249.5156 - mse: 147236.1719\nEpoch 442: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 147232.3438 - mse: 147219.0156 - val_loss: 145034.1719 - val_mse: 145020.8750\nEpoch 443/1200\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 147809.5156 - mse: 147796.1719\nEpoch 443: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 147811.8594 - mse: 147798.5156 - val_loss: 145723.3438 - val_mse: 145710.0156\nEpoch 444/1200\n\u001b[1m284/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 148687.8438 - mse: 148674.5000\nEpoch 444: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 148692.9375 - mse: 148679.5938 - val_loss: 148284.5469 - val_mse: 148271.1719\nEpoch 445/1200\n\u001b[1m293/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 145800.2500 - mse: 145786.8438\nEpoch 445: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 145808.5156 - mse: 145795.1094 - val_loss: 141679.3281 - val_mse: 141665.9531\nEpoch 446/1200\n\u001b[1m285/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 148271.7969 - mse: 148258.4219\nEpoch 446: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 148137.8438 - mse: 148124.4688 - val_loss: 147206.0000 - val_mse: 147192.6406\nEpoch 447/1200\n\u001b[1m292/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 144997.5312 - mse: 144984.2031\nEpoch 447: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 145070.9844 - mse: 145057.6719 - val_loss: 145188.6250 - val_mse: 145175.2812\nEpoch 448/1200\n\u001b[1m288/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 145509.3438 - mse: 145496.0000\nEpoch 448: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 145479.5625 - mse: 145466.2188 - val_loss: 145901.4844 - val_mse: 145888.0781\nEpoch 449/1200\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 146627.1250 - mse: 146613.7500\nEpoch 449: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 146623.4219 - mse: 146610.0625 - val_loss: 149414.3125 - val_mse: 149400.9844\nEpoch 450/1200\n\u001b[1m290/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 147760.6250 - mse: 147747.2344\nEpoch 450: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 147739.0469 - mse: 147725.6562 - val_loss: 144154.2812 - val_mse: 144140.8750\nEpoch 451/1200\n\u001b[1m291/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 148515.1250 - mse: 148501.7344\nEpoch 451: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 148482.7969 - mse: 148469.4062 - val_loss: 147729.6406 - val_mse: 147716.2500\nEpoch 452/1200\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 150347.2812 - mse: 150333.9219\nEpoch 452: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 150334.0625 - mse: 150320.7031 - val_loss: 147191.0938 - val_mse: 147177.7188\nEpoch 453/1200\n\u001b[1m290/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 145605.4688 - mse: 145592.0781\nEpoch 453: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 145637.1875 - mse: 145623.7969 - val_loss: 148027.1250 - val_mse: 148013.7812\nEpoch 454/1200\n\u001b[1m294/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 146186.1250 - mse: 146172.7344\nEpoch 454: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 146206.0625 - mse: 146192.6875 - val_loss: 150610.1406 - val_mse: 150596.7812\nEpoch 455/1200\n\u001b[1m296/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 148073.3750 - mse: 148060.0000\nEpoch 455: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 148072.1094 - mse: 148058.7500 - val_loss: 141225.2344 - val_mse: 141211.8438\nEpoch 456/1200\n\u001b[1m274/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 141488.2969 - mse: 141474.9062\nEpoch 456: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 141694.0312 - mse: 141680.6250 - val_loss: 146196.2812 - val_mse: 146182.8438\nEpoch 457/1200\n\u001b[1m276/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 149159.0312 - mse: 149145.6562\nEpoch 457: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 148811.0156 - mse: 148797.6250 - val_loss: 138345.9688 - val_mse: 138332.6094\nEpoch 458/1200\n\u001b[1m287/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 144965.4688 - mse: 144952.0469\nEpoch 458: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 144934.0469 - mse: 144920.6250 - val_loss: 147181.7344 - val_mse: 147168.3750\nEpoch 459/1200\n\u001b[1m273/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 142455.6562 - mse: 142442.2500\nEpoch 459: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 142636.2656 - mse: 142622.8594 - val_loss: 140347.5625 - val_mse: 140334.0938\nEpoch 460/1200\n\u001b[1m286/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 144280.3438 - mse: 144266.9688\nEpoch 460: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 144312.9844 - mse: 144299.6094 - val_loss: 148811.5469 - val_mse: 148798.1406\nEpoch 461/1200\n\u001b[1m286/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 144773.2656 - mse: 144759.8594\nEpoch 461: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 144841.9062 - mse: 144828.4844 - val_loss: 150856.3750 - val_mse: 150842.9688\nEpoch 462/1200\n\u001b[1m293/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 141718.4844 - mse: 141705.0625\nEpoch 462: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 141816.6875 - mse: 141803.2656 - val_loss: 144921.3906 - val_mse: 144908.0156\nEpoch 463/1200\n\u001b[1m297/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 143733.4375 - mse: 143720.0312\nEpoch 463: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 143770.0469 - mse: 143756.6562 - val_loss: 142168.1875 - val_mse: 142154.7656\nEpoch 464/1200\n\u001b[1m293/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 141254.6875 - mse: 141241.2656\nEpoch 464: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 141325.8594 - mse: 141312.4219 - val_loss: 146138.5625 - val_mse: 146125.1719\nEpoch 465/1200\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 146425.0469 - mse: 146411.6094\nEpoch 465: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 146420.8438 - mse: 146407.4062 - val_loss: 154397.9844 - val_mse: 154384.5625\nEpoch 466/1200\n\u001b[1m290/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 140321.5938 - mse: 140308.1875\nEpoch 466: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 140492.8750 - mse: 140479.4688 - val_loss: 149415.0469 - val_mse: 149401.5781\nEpoch 467/1200\n\u001b[1m296/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 147856.6875 - mse: 147843.2656\nEpoch 467: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 147839.7344 - mse: 147826.3125 - val_loss: 148508.3750 - val_mse: 148494.9688\nEpoch 468/1200\n\u001b[1m295/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 144247.3438 - mse: 144233.9688\nEpoch 468: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 144217.2031 - mse: 144203.8281 - val_loss: 143163.4375 - val_mse: 143150.0000\nEpoch 469/1200\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 143483.9531 - mse: 143470.5312\nEpoch 469: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 143483.3906 - mse: 143469.9688 - val_loss: 143124.7500 - val_mse: 143111.3438\nEpoch 470/1200\n\u001b[1m295/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 144212.0938 - mse: 144198.6094\nEpoch 470: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 144270.4062 - mse: 144256.9219 - val_loss: 151364.1562 - val_mse: 151350.7344\nEpoch 471/1200\n\u001b[1m297/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 143471.1406 - mse: 143457.6719\nEpoch 471: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 143492.2656 - mse: 143478.7969 - val_loss: 150616.2031 - val_mse: 150602.7188\nEpoch 472/1200\n\u001b[1m297/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 143027.4688 - mse: 143014.0156\nEpoch 472: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 143035.6875 - mse: 143022.2344 - val_loss: 149599.0156 - val_mse: 149585.5469\nEpoch 473/1200\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 148578.8125 - mse: 148565.2500\nEpoch 473: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 148572.9062 - mse: 148559.3438 - val_loss: 144822.6562 - val_mse: 144809.1562\nEpoch 474/1200\n\u001b[1m282/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 147708.8750 - mse: 147695.3906\nEpoch 474: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 147612.1406 - mse: 147598.6562 - val_loss: 144194.0312 - val_mse: 144180.5625\nEpoch 475/1200\n\u001b[1m294/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 147139.9375 - mse: 147126.4531\nEpoch 475: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 147077.4219 - mse: 147063.9375 - val_loss: 147020.8594 - val_mse: 147007.3594\nEpoch 476/1200\n\u001b[1m295/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 139613.0000 - mse: 139599.5625\nEpoch 476: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 139669.2188 - mse: 139655.7812 - val_loss: 139437.6719 - val_mse: 139424.2188\nEpoch 477/1200\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 143053.4375 - mse: 143039.9688\nEpoch 477: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 143057.6406 - mse: 143044.1875 - val_loss: 137237.6250 - val_mse: 137224.1250\nEpoch 478/1200\n\u001b[1m295/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 144359.2656 - mse: 144345.7656\nEpoch 478: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 144376.1562 - mse: 144362.6562 - val_loss: 150200.8906 - val_mse: 150187.4219\nEpoch 479/1200\n\u001b[1m284/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 144689.1562 - mse: 144675.7188\nEpoch 479: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 144757.1719 - mse: 144743.7344 - val_loss: 142860.9219 - val_mse: 142847.4531\nEpoch 480/1200\n\u001b[1m297/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 142915.1094 - mse: 142901.6562\nEpoch 480: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 142928.6094 - mse: 142915.1406 - val_loss: 149205.0312 - val_mse: 149191.5469\nEpoch 481/1200\n\u001b[1m299/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 144835.5938 - mse: 144822.0625\nEpoch 481: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 144832.4688 - mse: 144818.9375 - val_loss: 149923.0781 - val_mse: 149909.5312\nEpoch 482/1200\n\u001b[1m295/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 144015.1406 - mse: 144001.6719\nEpoch 482: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 143999.6094 - mse: 143986.1406 - val_loss: 144066.8281 - val_mse: 144053.2500\nEpoch 483/1200\n\u001b[1m287/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 142953.6094 - mse: 142940.0938\nEpoch 483: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 142970.4219 - mse: 142956.9062 - val_loss: 144593.3594 - val_mse: 144579.8438\nEpoch 484/1200\n\u001b[1m278/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 145507.3594 - mse: 145493.8594\nEpoch 484: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 145454.7500 - mse: 145441.2500 - val_loss: 140789.9688 - val_mse: 140776.4688\nEpoch 485/1200\n\u001b[1m288/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 145585.4219 - mse: 145571.9219\nEpoch 485: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 145517.2031 - mse: 145503.7031 - val_loss: 147623.9844 - val_mse: 147610.4688\nEpoch 486/1200\n\u001b[1m280/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 137165.8125 - mse: 137152.3125\nEpoch 486: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 137430.1719 - mse: 137416.6719 - val_loss: 146535.8906 - val_mse: 146522.4375\nEpoch 487/1200\n\u001b[1m295/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 145524.3594 - mse: 145510.8281\nEpoch 487: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 145495.3438 - mse: 145481.7969 - val_loss: 146938.5781 - val_mse: 146925.0625\nEpoch 488/1200\n\u001b[1m288/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 143252.9531 - mse: 143239.4062\nEpoch 488: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 143285.3750 - mse: 143271.8125 - val_loss: 154489.9375 - val_mse: 154476.4062\nEpoch 489/1200\n\u001b[1m287/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 145010.6875 - mse: 144997.1562\nEpoch 489: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 144940.9531 - mse: 144927.4375 - val_loss: 141759.5938 - val_mse: 141746.0938\nEpoch 490/1200\n\u001b[1m287/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 145863.9688 - mse: 145850.4375\nEpoch 490: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 145753.2188 - mse: 145739.6875 - val_loss: 143743.2812 - val_mse: 143729.7656\nEpoch 491/1200\n\u001b[1m291/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 140863.5000 - mse: 140849.9375\nEpoch 491: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 140950.0156 - mse: 140936.4375 - val_loss: 152405.5312 - val_mse: 152391.9688\nEpoch 492/1200\n\u001b[1m293/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 140916.5156 - mse: 140902.9375\nEpoch 492: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 140976.0781 - mse: 140962.5000 - val_loss: 140747.3125 - val_mse: 140733.7500\nEpoch 493/1200\n\u001b[1m286/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 143895.1719 - mse: 143881.6094\nEpoch 493: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 143841.2188 - mse: 143827.6562 - val_loss: 144563.5312 - val_mse: 144550.0000\nEpoch 494/1200\n\u001b[1m293/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 140535.7031 - mse: 140522.1562\nEpoch 494: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 140588.7500 - mse: 140575.2031 - val_loss: 142682.4688 - val_mse: 142668.9375\nEpoch 495/1200\n\u001b[1m291/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 138891.6094 - mse: 138878.0469\nEpoch 495: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 138986.9219 - mse: 138973.3750 - val_loss: 147846.5312 - val_mse: 147833.0312\nEpoch 496/1200\n\u001b[1m289/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 142828.7812 - mse: 142815.2500\nEpoch 496: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 142756.5312 - mse: 142743.0000 - val_loss: 148966.7031 - val_mse: 148953.1250\nEpoch 497/1200\n\u001b[1m281/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 142328.8438 - mse: 142315.3125\nEpoch 497: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 142351.6250 - mse: 142338.0938 - val_loss: 146814.0312 - val_mse: 146800.4531\nEpoch 498/1200\n\u001b[1m289/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 141993.9531 - mse: 141980.4062\nEpoch 498: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 141906.5938 - mse: 141893.0469 - val_loss: 136770.1719 - val_mse: 136756.5938\nEpoch 499/1200\n\u001b[1m292/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 140929.5469 - mse: 140915.9688\nEpoch 499: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 141035.0938 - mse: 141021.5156 - val_loss: 152368.8906 - val_mse: 152355.3438\nEpoch 500/1200\n\u001b[1m277/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 142433.2500 - mse: 142419.6719\nEpoch 500: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 142548.9062 - mse: 142535.3281 - val_loss: 142373.4375 - val_mse: 142359.9219\nEpoch 501/1200\n\u001b[1m294/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 140580.7969 - mse: 140567.2812\nEpoch 501: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 140635.2812 - mse: 140621.7812 - val_loss: 148047.2031 - val_mse: 148033.6250\nEpoch 502/1200\n\u001b[1m284/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 148068.1562 - mse: 148054.5938\nEpoch 502: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 147743.4844 - mse: 147729.9219 - val_loss: 137788.7188 - val_mse: 137775.1250\nEpoch 503/1200\n\u001b[1m283/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 143387.6875 - mse: 143374.1250\nEpoch 503: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 143309.4688 - mse: 143295.9062 - val_loss: 141099.7344 - val_mse: 141086.1406\nEpoch 504/1200\n\u001b[1m277/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 142855.3906 - mse: 142841.7969\nEpoch 504: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 142831.1094 - mse: 142817.5156 - val_loss: 142901.0469 - val_mse: 142887.4531\nEpoch 505/1200\n\u001b[1m282/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 145885.9844 - mse: 145872.3750\nEpoch 505: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 145661.1094 - mse: 145647.4844 - val_loss: 138287.6094 - val_mse: 138274.0000\nEpoch 506/1200\n\u001b[1m288/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 143195.1406 - mse: 143181.5469\nEpoch 506: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 143161.5000 - mse: 143147.9062 - val_loss: 144666.4062 - val_mse: 144652.8281\nEpoch 507/1200\n\u001b[1m290/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 144827.2969 - mse: 144813.7188\nEpoch 507: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 144791.7500 - mse: 144778.1875 - val_loss: 145473.7969 - val_mse: 145460.2031\nEpoch 508/1200\n\u001b[1m292/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 144904.0156 - mse: 144890.4219\nEpoch 508: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 144844.2500 - mse: 144830.6719 - val_loss: 148653.2500 - val_mse: 148639.6719\nEpoch 509/1200\n\u001b[1m289/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 144320.8750 - mse: 144307.2812\nEpoch 509: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 144281.4688 - mse: 144267.8750 - val_loss: 147136.5938 - val_mse: 147122.9844\nEpoch 510/1200\n\u001b[1m283/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 140357.7031 - mse: 140344.0938\nEpoch 510: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 140479.0000 - mse: 140465.3906 - val_loss: 150426.6719 - val_mse: 150413.0781\nEpoch 511/1200\n\u001b[1m290/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 142529.7656 - mse: 142516.1406\nEpoch 511: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 142512.6562 - mse: 142499.0469 - val_loss: 143748.8906 - val_mse: 143735.2656\nEpoch 512/1200\n\u001b[1m290/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 142482.1094 - mse: 142468.5156\nEpoch 512: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 142526.5938 - mse: 142512.9844 - val_loss: 146990.4688 - val_mse: 146976.8438\nEpoch 513/1200\n\u001b[1m292/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 144457.0625 - mse: 144443.4688\nEpoch 513: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 144409.8750 - mse: 144396.2969 - val_loss: 143765.3125 - val_mse: 143751.6875\nEpoch 514/1200\n\u001b[1m275/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 141863.8125 - mse: 141850.1719\nEpoch 514: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 141835.7344 - mse: 141822.0938 - val_loss: 147605.0312 - val_mse: 147591.4062\nEpoch 515/1200\n\u001b[1m288/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 140749.0156 - mse: 140735.4219\nEpoch 515: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 140751.7500 - mse: 140738.1562 - val_loss: 150941.4219 - val_mse: 150927.8125\nEpoch 516/1200\n\u001b[1m295/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 142692.6250 - mse: 142678.9844\nEpoch 516: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 142680.8125 - mse: 142667.1719 - val_loss: 144371.8125 - val_mse: 144358.1719\nEpoch 517/1200\n\u001b[1m281/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 142478.4062 - mse: 142464.8281\nEpoch 517: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 142530.2656 - mse: 142516.6875 - val_loss: 140546.1406 - val_mse: 140532.4844\nEpoch 518/1200\n\u001b[1m276/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 145801.3906 - mse: 145787.7031\nEpoch 518: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 145536.7969 - mse: 145523.1094 - val_loss: 139871.9375 - val_mse: 139858.2969\nEpoch 519/1200\n\u001b[1m292/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 142523.0938 - mse: 142509.4844\nEpoch 519: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 142522.9375 - mse: 142509.3438 - val_loss: 150450.9844 - val_mse: 150437.3125\nEpoch 520/1200\n\u001b[1m293/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 137598.9688 - mse: 137585.2969\nEpoch 520: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 137661.2812 - mse: 137647.6094 - val_loss: 155155.8125 - val_mse: 155142.1562\nEpoch 521/1200\n\u001b[1m286/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 140009.4219 - mse: 139995.7188\nEpoch 521: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 139957.5781 - mse: 139943.8906 - val_loss: 148887.9844 - val_mse: 148874.3438\nEpoch 522/1200\n\u001b[1m296/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 142177.3594 - mse: 142163.7031\nEpoch 522: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 142154.0938 - mse: 142140.4531 - val_loss: 152162.3594 - val_mse: 152148.7188\nEpoch 523/1200\n\u001b[1m293/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 138185.8281 - mse: 138172.1719\nEpoch 523: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 138246.0312 - mse: 138232.3750 - val_loss: 139686.8281 - val_mse: 139673.1406\nEpoch 524/1200\n\u001b[1m291/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 142483.9375 - mse: 142470.2812\nEpoch 524: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 142491.7812 - mse: 142478.1406 - val_loss: 148618.6562 - val_mse: 148604.9844\nEpoch 525/1200\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 142103.7031 - mse: 142090.0000\nEpoch 525: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 142100.2344 - mse: 142086.5469 - val_loss: 145773.4219 - val_mse: 145759.7188\nEpoch 526/1200\n\u001b[1m293/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 140990.7500 - mse: 140977.0625\nEpoch 526: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 140981.2188 - mse: 140967.5312 - val_loss: 156430.5312 - val_mse: 156416.8594\nEpoch 527/1200\n\u001b[1m293/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 138364.7812 - mse: 138351.1094\nEpoch 527: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 138410.2812 - mse: 138396.5938 - val_loss: 148194.4844 - val_mse: 148180.7969\nEpoch 528/1200\n\u001b[1m279/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 136747.1094 - mse: 136733.4531\nEpoch 528: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 136970.3125 - mse: 136956.6562 - val_loss: 155243.4688 - val_mse: 155229.7656\nEpoch 529/1200\n\u001b[1m298/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 143197.6562 - mse: 143184.0000\nEpoch 529: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 143166.6875 - mse: 143153.0312 - val_loss: 147469.4688 - val_mse: 147455.7500\nEpoch 530/1200\n\u001b[1m293/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 143979.7500 - mse: 143966.0156\nEpoch 530: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 143881.3750 - mse: 143867.6406 - val_loss: 147246.2500 - val_mse: 147232.5156\nEpoch 531/1200\n\u001b[1m296/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 142334.1719 - mse: 142320.4531\nEpoch 531: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 142322.4531 - mse: 142308.7500 - val_loss: 146203.4844 - val_mse: 146189.7812\nEpoch 532/1200\n\u001b[1m297/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 146033.1406 - mse: 146019.4375\nEpoch 532: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 145983.9531 - mse: 145970.2344 - val_loss: 151910.7656 - val_mse: 151897.0312\nEpoch 533/1200\n\u001b[1m293/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 139128.8438 - mse: 139115.1094\nEpoch 533: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 139180.5938 - mse: 139166.8594 - val_loss: 142752.0156 - val_mse: 142738.2969\nEpoch 534/1200\n\u001b[1m292/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 141368.6406 - mse: 141354.9375\nEpoch 534: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 141375.1875 - mse: 141361.4844 - val_loss: 145286.5312 - val_mse: 145272.7812\nEpoch 535/1200\n\u001b[1m291/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 139694.3594 - mse: 139680.6562\nEpoch 535: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 139698.2031 - mse: 139684.5000 - val_loss: 146080.0156 - val_mse: 146066.2969\nEpoch 536/1200\n\u001b[1m296/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 136029.6250 - mse: 136015.9062\nEpoch 536: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 136065.5312 - mse: 136051.8125 - val_loss: 149216.2500 - val_mse: 149202.5625\nEpoch 537/1200\n\u001b[1m295/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 144634.5312 - mse: 144620.8281\nEpoch 537: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 144594.6875 - mse: 144580.9844 - val_loss: 146602.9375 - val_mse: 146589.2031\nEpoch 538/1200\n\u001b[1m297/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 143446.9844 - mse: 143433.2969\nEpoch 538: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 143424.0781 - mse: 143410.3750 - val_loss: 141850.7031 - val_mse: 141836.9844\nEpoch 539/1200\n\u001b[1m294/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 141183.7812 - mse: 141170.0469\nEpoch 539: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 141164.8438 - mse: 141151.1094 - val_loss: 140791.3594 - val_mse: 140777.5625\nEpoch 540/1200\n\u001b[1m291/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 144149.1875 - mse: 144135.4375\nEpoch 540: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 144018.8906 - mse: 144005.1406 - val_loss: 148706.8438 - val_mse: 148693.1250\nEpoch 541/1200\n\u001b[1m274/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 139571.1719 - mse: 139557.4375\nEpoch 541: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 139613.7031 - mse: 139599.9844 - val_loss: 147282.7031 - val_mse: 147268.9531\nEpoch 542/1200\n\u001b[1m293/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 140653.7344 - mse: 140639.9844\nEpoch 542: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 140668.5625 - mse: 140654.8125 - val_loss: 148821.7812 - val_mse: 148807.9688\nEpoch 543/1200\n\u001b[1m294/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 141682.9688 - mse: 141669.2812\nEpoch 543: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 141632.2031 - mse: 141618.5156 - val_loss: 144099.1562 - val_mse: 144085.3594\nEpoch 544/1200\n\u001b[1m295/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 139231.0156 - mse: 139217.2500\nEpoch 544: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 139220.6719 - mse: 139206.9062 - val_loss: 152084.9844 - val_mse: 152071.2344\nEpoch 545/1200\n\u001b[1m284/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 137147.5469 - mse: 137133.7344\nEpoch 545: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 137261.5156 - mse: 137247.7031 - val_loss: 154908.5469 - val_mse: 154894.7656\nEpoch 546/1200\n\u001b[1m294/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 141394.1406 - mse: 141380.3594\nEpoch 546: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 141417.0469 - mse: 141403.2656 - val_loss: 144535.3906 - val_mse: 144521.5938\nEpoch 547/1200\n\u001b[1m284/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 142937.2969 - mse: 142923.5781\nEpoch 547: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 142871.6250 - mse: 142857.9062 - val_loss: 141248.1875 - val_mse: 141234.3906\nEpoch 548/1200\n\u001b[1m293/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 135834.2188 - mse: 135820.4688\nEpoch 548: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 135908.3906 - mse: 135894.6406 - val_loss: 149357.2969 - val_mse: 149343.5781\nEpoch 549/1200\n\u001b[1m289/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 144300.1094 - mse: 144286.3125\nEpoch 549: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 144165.3750 - mse: 144151.5781 - val_loss: 145622.5312 - val_mse: 145608.7656\nEpoch 550/1200\n\u001b[1m289/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 143313.4375 - mse: 143299.6250\nEpoch 550: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 143192.8281 - mse: 143179.0000 - val_loss: 152118.1094 - val_mse: 152104.3594\nEpoch 551/1200\n\u001b[1m294/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 140816.8281 - mse: 140803.0156\nEpoch 551: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 140807.3125 - mse: 140793.5156 - val_loss: 145181.6250 - val_mse: 145167.8125\nEpoch 552/1200\n\u001b[1m297/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 135946.4219 - mse: 135932.6094\nEpoch 552: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 135996.3281 - mse: 135982.5312 - val_loss: 145244.9219 - val_mse: 145231.1406\nEpoch 553/1200\n\u001b[1m294/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 140598.0938 - mse: 140584.2812\nEpoch 553: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 140579.3438 - mse: 140565.5312 - val_loss: 149138.2344 - val_mse: 149124.4062\nEpoch 554/1200\n\u001b[1m290/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 137408.5938 - mse: 137394.7500\nEpoch 554: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 137501.5469 - mse: 137487.7188 - val_loss: 143027.4688 - val_mse: 143013.6562\nEpoch 555/1200\n\u001b[1m293/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 133894.6250 - mse: 133880.7969\nEpoch 555: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 133981.1406 - mse: 133967.3125 - val_loss: 140236.4844 - val_mse: 140222.6406\nEpoch 556/1200\n\u001b[1m297/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 138464.1094 - mse: 138450.2344\nEpoch 556: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 138489.1250 - mse: 138475.2500 - val_loss: 151314.0000 - val_mse: 151300.1562\nEpoch 557/1200\n\u001b[1m278/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 137572.1719 - mse: 137558.3281\nEpoch 557: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 137768.6562 - mse: 137754.8281 - val_loss: 151683.5156 - val_mse: 151669.7188\nEpoch 558/1200\n\u001b[1m295/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 139860.9375 - mse: 139847.0938\nEpoch 558: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 139827.2031 - mse: 139813.3750 - val_loss: 147414.8125 - val_mse: 147400.9531\nEpoch 559/1200\n\u001b[1m294/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 139719.7031 - mse: 139705.7812\nEpoch 559: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 139674.2344 - mse: 139660.3125 - val_loss: 154145.6875 - val_mse: 154131.8125\nEpoch 560/1200\n\u001b[1m292/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 143369.9375 - mse: 143356.0469\nEpoch 560: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 143269.5000 - mse: 143255.6250 - val_loss: 139408.1406 - val_mse: 139394.2500\nEpoch 561/1200\n\u001b[1m294/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 142620.2031 - mse: 142606.3750\nEpoch 561: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 142586.5938 - mse: 142572.7500 - val_loss: 149547.8125 - val_mse: 149533.9375\nEpoch 562/1200\n\u001b[1m299/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 140596.2812 - mse: 140582.4062\nEpoch 562: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 140592.1562 - mse: 140578.2812 - val_loss: 148436.7969 - val_mse: 148422.9375\nEpoch 563/1200\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 138270.3281 - mse: 138256.4844\nEpoch 563: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 138269.9062 - mse: 138256.0625 - val_loss: 149338.3125 - val_mse: 149324.4062\nEpoch 564/1200\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 139721.1719 - mse: 139707.2969\nEpoch 564: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 139722.5312 - mse: 139708.6562 - val_loss: 146320.5781 - val_mse: 146306.6719\nEpoch 565/1200\n\u001b[1m299/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 141122.1406 - mse: 141108.2812\nEpoch 565: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 141114.8125 - mse: 141100.9531 - val_loss: 150850.2969 - val_mse: 150836.4219\nEpoch 566/1200\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 140737.1094 - mse: 140723.2031\nEpoch 566: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 140738.4219 - mse: 140724.5156 - val_loss: 142955.2812 - val_mse: 142941.4688\nEpoch 567/1200\n\u001b[1m297/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 140619.9844 - mse: 140606.1406\nEpoch 567: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 140610.3906 - mse: 140596.5469 - val_loss: 141388.0781 - val_mse: 141374.1875\nEpoch 568/1200\n\u001b[1m297/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 141908.1562 - mse: 141894.3125\nEpoch 568: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 141875.9062 - mse: 141862.0469 - val_loss: 149087.1719 - val_mse: 149073.2344\nEpoch 569/1200\n\u001b[1m297/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 135460.9531 - mse: 135447.0938\nEpoch 569: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 135490.3438 - mse: 135476.4844 - val_loss: 148805.1406 - val_mse: 148791.2656\nEpoch 570/1200\n\u001b[1m274/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 142334.8281 - mse: 142320.9062\nEpoch 570: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 142224.7344 - mse: 142210.8125 - val_loss: 153679.1406 - val_mse: 153665.2188\nEpoch 571/1200\n\u001b[1m296/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 134672.7031 - mse: 134658.8281\nEpoch 571: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 134685.3906 - mse: 134671.5156 - val_loss: 148742.9688 - val_mse: 148729.1094\nEpoch 572/1200\n\u001b[1m277/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 137441.2812 - mse: 137427.3438\nEpoch 572: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 137477.9219 - mse: 137463.9844 - val_loss: 145095.7656 - val_mse: 145081.8594\nEpoch 573/1200\n\u001b[1m291/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 134997.7500 - mse: 134983.8594\nEpoch 573: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 135089.8906 - mse: 135075.9844 - val_loss: 149820.7812 - val_mse: 149806.8438\nEpoch 574/1200\n\u001b[1m299/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 141567.5312 - mse: 141553.6250\nEpoch 574: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 141552.5156 - mse: 141538.5938 - val_loss: 141567.5156 - val_mse: 141553.6875\nEpoch 575/1200\n\u001b[1m296/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 138902.5156 - mse: 138888.5469\nEpoch 575: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 138889.7656 - mse: 138875.8125 - val_loss: 151889.2969 - val_mse: 151875.3594\nEpoch 576/1200\n\u001b[1m285/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 137487.1094 - mse: 137473.1719\nEpoch 576: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 137462.7188 - mse: 137448.7969 - val_loss: 145009.6719 - val_mse: 144995.6875\nEpoch 577/1200\n\u001b[1m291/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 139161.0781 - mse: 139147.1406\nEpoch 577: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 139190.6250 - mse: 139176.6719 - val_loss: 155412.3906 - val_mse: 155398.4688\nEpoch 578/1200\n\u001b[1m289/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 139625.6250 - mse: 139611.7031\nEpoch 578: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 139526.6406 - mse: 139512.7188 - val_loss: 149236.7188 - val_mse: 149222.7656\nEpoch 579/1200\n\u001b[1m288/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 135419.8906 - mse: 135405.9219\nEpoch 579: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 135534.6562 - mse: 135520.6875 - val_loss: 145924.7344 - val_mse: 145910.7812\nEpoch 580/1200\n\u001b[1m289/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 136331.1562 - mse: 136317.2188\nEpoch 580: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 136349.9688 - mse: 136336.0312 - val_loss: 155749.1094 - val_mse: 155735.1094\nEpoch 581/1200\n\u001b[1m289/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 140846.3281 - mse: 140832.3906\nEpoch 581: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 140767.9375 - mse: 140754.0000 - val_loss: 151492.9688 - val_mse: 151479.0156\nEpoch 582/1200\n\u001b[1m293/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 134687.3594 - mse: 134673.4219\nEpoch 582: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 134786.3594 - mse: 134772.4219 - val_loss: 153441.2812 - val_mse: 153427.3281\nEpoch 583/1200\n\u001b[1m291/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 136234.8594 - mse: 136220.8906\nEpoch 583: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 136283.2344 - mse: 136269.2812 - val_loss: 146483.4531 - val_mse: 146469.4688\nEpoch 584/1200\n\u001b[1m299/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 135538.7812 - mse: 135524.8125\nEpoch 584: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 135555.1875 - mse: 135541.2188 - val_loss: 145644.0781 - val_mse: 145630.1719\nEpoch 585/1200\n\u001b[1m280/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 138204.2500 - mse: 138190.3125\nEpoch 585: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 138220.0938 - mse: 138206.1562 - val_loss: 152003.3438 - val_mse: 151989.3906\nEpoch 586/1200\n\u001b[1m291/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 136571.4219 - mse: 136557.4219\nEpoch 586: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 136549.8125 - mse: 136535.8125 - val_loss: 148715.9219 - val_mse: 148701.9062\nEpoch 587/1200\n\u001b[1m292/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 139628.2656 - mse: 139614.2812\nEpoch 587: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 139627.5938 - mse: 139613.5938 - val_loss: 150055.3125 - val_mse: 150041.3281\nEpoch 588/1200\n\u001b[1m294/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 135339.0312 - mse: 135325.0469\nEpoch 588: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 135362.7500 - mse: 135348.7500 - val_loss: 152975.0469 - val_mse: 152961.0938\nEpoch 589/1200\n\u001b[1m288/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 138196.9219 - mse: 138182.8906\nEpoch 589: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 138151.0938 - mse: 138137.0625 - val_loss: 144134.0938 - val_mse: 144120.1250\nEpoch 590/1200\n\u001b[1m283/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 138229.2188 - mse: 138215.2656\nEpoch 590: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 138128.0000 - mse: 138114.0469 - val_loss: 143251.0156 - val_mse: 143237.0312\nEpoch 591/1200\n\u001b[1m289/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 139198.7031 - mse: 139184.7031\nEpoch 591: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 139106.8438 - mse: 139092.8438 - val_loss: 150786.6094 - val_mse: 150772.6562\nEpoch 592/1200\n\u001b[1m288/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 135829.7656 - mse: 135815.7656\nEpoch 592: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 135880.3438 - mse: 135866.3438 - val_loss: 148858.8750 - val_mse: 148844.8906\nEpoch 593/1200\n\u001b[1m289/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 142179.4062 - mse: 142165.3750\nEpoch 593: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 142121.0312 - mse: 142107.0000 - val_loss: 148445.0469 - val_mse: 148431.0156\nEpoch 594/1200\n\u001b[1m283/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 139420.1406 - mse: 139406.1719\nEpoch 594: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 139356.9219 - mse: 139342.9688 - val_loss: 152195.4062 - val_mse: 152181.3594\nEpoch 595/1200\n\u001b[1m287/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 139050.4688 - mse: 139036.4844\nEpoch 595: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 138927.2500 - mse: 138913.2812 - val_loss: 149586.2188 - val_mse: 149572.2188\nEpoch 596/1200\n\u001b[1m286/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 133209.2188 - mse: 133195.2031\nEpoch 596: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 133362.4219 - mse: 133348.4062 - val_loss: 146113.8125 - val_mse: 146099.7812\nEpoch 597/1200\n\u001b[1m279/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 138414.0625 - mse: 138400.0625\nEpoch 597: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 138404.7500 - mse: 138390.7344 - val_loss: 146054.7500 - val_mse: 146040.6875\nEpoch 598/1200\n\u001b[1m285/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 135561.6875 - mse: 135547.7031\nEpoch 598: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 135693.3281 - mse: 135679.3594 - val_loss: 153797.3906 - val_mse: 153783.3906\nEpoch 599/1200\n\u001b[1m298/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 137974.7969 - mse: 137960.7656\nEpoch 599: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 137968.0000 - mse: 137953.9844 - val_loss: 149630.1406 - val_mse: 149616.0938\nEpoch 600/1200\n\u001b[1m287/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 135058.5000 - mse: 135044.5000\nEpoch 600: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 135170.0469 - mse: 135156.0469 - val_loss: 154369.9844 - val_mse: 154355.9688\nEpoch 601/1200\n\u001b[1m285/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 138828.3750 - mse: 138814.3750\nEpoch 601: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 138785.6875 - mse: 138771.6875 - val_loss: 153276.5469 - val_mse: 153262.5000\nEpoch 602/1200\n\u001b[1m290/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 137215.6250 - mse: 137201.6562\nEpoch 602: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 137230.8750 - mse: 137216.9062 - val_loss: 155007.4531 - val_mse: 154993.4688\nEpoch 603/1200\n\u001b[1m273/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 134923.8750 - mse: 134909.8594\nEpoch 603: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 134991.5938 - mse: 134977.5781 - val_loss: 147730.8906 - val_mse: 147716.8438\nEpoch 604/1200\n\u001b[1m288/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 136606.2969 - mse: 136592.2812\nEpoch 604: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 136652.1562 - mse: 136638.1406 - val_loss: 148297.4531 - val_mse: 148283.4531\nEpoch 605/1200\n\u001b[1m292/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 136583.3281 - mse: 136569.3281\nEpoch 605: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 136554.4688 - mse: 136540.4531 - val_loss: 147713.5625 - val_mse: 147699.5156\nEpoch 606/1200\n\u001b[1m292/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 137867.2812 - mse: 137853.2344\nEpoch 606: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 137870.2969 - mse: 137856.2500 - val_loss: 141844.2500 - val_mse: 141830.1719\nEpoch 607/1200\n\u001b[1m291/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 130953.6328 - mse: 130939.5547\nEpoch 607: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 131063.0000 - mse: 131048.9219 - val_loss: 149598.7344 - val_mse: 149584.6875\nEpoch 608/1200\n\u001b[1m298/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 135951.5312 - mse: 135937.4531\nEpoch 608: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 135969.2969 - mse: 135955.2188 - val_loss: 148762.2969 - val_mse: 148748.2344\nEpoch 609/1200\n\u001b[1m289/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 137164.1250 - mse: 137150.0625\nEpoch 609: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 137095.4219 - mse: 137081.3750 - val_loss: 151770.9062 - val_mse: 151756.8438\nEpoch 610/1200\n\u001b[1m277/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 132664.9062 - mse: 132650.8438\nEpoch 610: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 132785.4375 - mse: 132771.3906 - val_loss: 149590.7656 - val_mse: 149576.6562\nEpoch 611/1200\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 132164.0312 - mse: 132149.9688\nEpoch 611: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 132172.9531 - mse: 132158.9062 - val_loss: 148065.9688 - val_mse: 148051.9375\nEpoch 612/1200\n\u001b[1m292/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 132505.0781 - mse: 132491.0156\nEpoch 612: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 132567.9531 - mse: 132553.8750 - val_loss: 146371.0156 - val_mse: 146356.9531\nEpoch 613/1200\n\u001b[1m282/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 138247.0625 - mse: 138232.9688\nEpoch 613: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 138200.6406 - mse: 138186.5625 - val_loss: 150633.5625 - val_mse: 150619.5156\nEpoch 614/1200\n\u001b[1m290/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 135339.9375 - mse: 135325.8594\nEpoch 614: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 135367.4688 - mse: 135353.3906 - val_loss: 152448.4375 - val_mse: 152434.3594\nEpoch 615/1200\n\u001b[1m291/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 136516.9375 - mse: 136502.8906\nEpoch 615: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 136515.3281 - mse: 136501.2656 - val_loss: 151693.4844 - val_mse: 151679.3906\nEpoch 616/1200\n\u001b[1m294/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 136205.0312 - mse: 136190.9531\nEpoch 616: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 136162.9844 - mse: 136148.9062 - val_loss: 152403.4844 - val_mse: 152389.4062\nEpoch 617/1200\n\u001b[1m297/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 138627.7969 - mse: 138613.7188\nEpoch 617: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 138617.6875 - mse: 138603.6094 - val_loss: 154880.2188 - val_mse: 154866.1406\nEpoch 618/1200\n\u001b[1m287/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 134341.5000 - mse: 134327.4375\nEpoch 618: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 134418.5625 - mse: 134404.5000 - val_loss: 148563.4531 - val_mse: 148549.3906\nEpoch 619/1200\n\u001b[1m290/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 133382.9688 - mse: 133368.8906\nEpoch 619: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 133394.3125 - mse: 133380.2500 - val_loss: 151172.7812 - val_mse: 151158.6719\nEpoch 620/1200\n\u001b[1m292/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 133886.7656 - mse: 133872.6562\nEpoch 620: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 133908.7656 - mse: 133894.6562 - val_loss: 153360.7969 - val_mse: 153346.7031\nEpoch 621/1200\n\u001b[1m290/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 134544.4688 - mse: 134530.3125\nEpoch 621: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 134540.2344 - mse: 134526.0938 - val_loss: 140342.8438 - val_mse: 140328.7188\nEpoch 622/1200\n\u001b[1m292/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 135611.0469 - mse: 135596.9219\nEpoch 622: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 135585.8438 - mse: 135571.7188 - val_loss: 152317.2188 - val_mse: 152303.1094\nEpoch 623/1200\n\u001b[1m295/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 135109.7031 - mse: 135095.6719\nEpoch 623: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 135147.9375 - mse: 135133.9062 - val_loss: 150918.2500 - val_mse: 150904.1875\nEpoch 624/1200\n\u001b[1m287/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 132178.8281 - mse: 132164.7031\nEpoch 624: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 132333.0781 - mse: 132318.9531 - val_loss: 145144.0156 - val_mse: 145129.9062\nEpoch 625/1200\n\u001b[1m281/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 133779.3906 - mse: 133765.2500\nEpoch 625: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 133909.2500 - mse: 133895.0938 - val_loss: 145081.7656 - val_mse: 145067.6406\nEpoch 626/1200\n\u001b[1m295/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 133286.1094 - mse: 133271.9531\nEpoch 626: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 133280.4062 - mse: 133266.2656 - val_loss: 147362.9688 - val_mse: 147348.8594\nEpoch 627/1200\n\u001b[1m284/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 135131.8594 - mse: 135117.7500\nEpoch 627: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 135025.6875 - mse: 135011.5781 - val_loss: 147816.7500 - val_mse: 147802.6250\nEpoch 628/1200\n\u001b[1m285/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 130091.0000 - mse: 130076.8828\nEpoch 628: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 130248.4531 - mse: 130234.3359 - val_loss: 150945.7344 - val_mse: 150931.5938\nEpoch 629/1200\n\u001b[1m285/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 129501.4922 - mse: 129487.3828\nEpoch 629: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 129557.0156 - mse: 129542.9062 - val_loss: 147802.9688 - val_mse: 147788.8438\nEpoch 630/1200\n\u001b[1m282/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 135317.3906 - mse: 135303.2656\nEpoch 630: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 135338.2500 - mse: 135324.1250 - val_loss: 143607.0156 - val_mse: 143592.8438\nEpoch 631/1200\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 131963.5938 - mse: 131949.4688\nEpoch 631: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 131966.8906 - mse: 131952.7656 - val_loss: 156894.4688 - val_mse: 156880.3125\nEpoch 632/1200\n\u001b[1m298/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 131356.6875 - mse: 131342.5625\nEpoch 632: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 131400.6875 - mse: 131386.5625 - val_loss: 139971.0312 - val_mse: 139956.8281\nEpoch 633/1200\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 136454.2500 - mse: 136440.0938\nEpoch 633: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 136446.4844 - mse: 136432.3281 - val_loss: 148298.7969 - val_mse: 148284.6719\nEpoch 634/1200\n\u001b[1m273/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 132317.1094 - mse: 132302.9531\nEpoch 634: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 132505.1719 - mse: 132491.0156 - val_loss: 146679.4375 - val_mse: 146665.2812\nEpoch 635/1200\n\u001b[1m298/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 134886.0156 - mse: 134871.8281\nEpoch 635: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 134875.5625 - mse: 134861.3750 - val_loss: 151352.0781 - val_mse: 151337.9375\nEpoch 636/1200\n\u001b[1m295/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 134999.5469 - mse: 134985.3906\nEpoch 636: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 134979.5938 - mse: 134965.4375 - val_loss: 149312.2812 - val_mse: 149298.1562\nEpoch 637/1200\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 134958.0625 - mse: 134943.9531\nEpoch 637: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 134958.7969 - mse: 134944.6875 - val_loss: 156511.6094 - val_mse: 156497.4375\nEpoch 638/1200\n\u001b[1m275/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 133732.3125 - mse: 133718.1406\nEpoch 638: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 133838.2969 - mse: 133824.1250 - val_loss: 155487.5625 - val_mse: 155473.4219\nEpoch 639/1200\n\u001b[1m274/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 132928.9688 - mse: 132914.7969\nEpoch 639: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 132934.6406 - mse: 132920.4688 - val_loss: 152056.5000 - val_mse: 152042.2969\nEpoch 640/1200\n\u001b[1m294/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 130724.8359 - mse: 130710.6719\nEpoch 640: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 130767.7266 - mse: 130753.5625 - val_loss: 159571.0469 - val_mse: 159556.8438\nEpoch 641/1200\n\u001b[1m299/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 131712.4531 - mse: 131698.2969\nEpoch 641: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 131720.7500 - mse: 131706.5781 - val_loss: 150841.2344 - val_mse: 150827.0625\nEpoch 642/1200\n\u001b[1m288/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 129475.8594 - mse: 129461.6562\nEpoch 642: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 129652.0469 - mse: 129637.8438 - val_loss: 149488.5781 - val_mse: 149474.4062\nEpoch 643/1200\n\u001b[1m296/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 131798.1406 - mse: 131784.0000\nEpoch 643: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 131805.7969 - mse: 131791.6719 - val_loss: 151169.8438 - val_mse: 151155.6094\nEpoch 644/1200\n\u001b[1m295/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 130221.3750 - mse: 130207.2031\nEpoch 644: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 130292.0469 - mse: 130277.8750 - val_loss: 151808.8281 - val_mse: 151794.6719\nEpoch 645/1200\n\u001b[1m279/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 133408.6562 - mse: 133394.4531\nEpoch 645: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 133239.0000 - mse: 133224.7969 - val_loss: 151461.0625 - val_mse: 151446.8750\nEpoch 646/1200\n\u001b[1m284/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 134209.5781 - mse: 134195.3594\nEpoch 646: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 134147.3281 - mse: 134133.1094 - val_loss: 153510.4062 - val_mse: 153496.2188\nEpoch 647/1200\n\u001b[1m282/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 137061.2500 - mse: 137047.0625\nEpoch 647: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 136831.5625 - mse: 136817.3906 - val_loss: 143960.5938 - val_mse: 143946.4531\nEpoch 648/1200\n\u001b[1m284/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 135194.4219 - mse: 135180.2031\nEpoch 648: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 135148.6250 - mse: 135134.3906 - val_loss: 150110.3750 - val_mse: 150096.1719\nEpoch 649/1200\n\u001b[1m279/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 132358.0781 - mse: 132343.8281\nEpoch 649: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 132448.9375 - mse: 132434.6875 - val_loss: 149900.7500 - val_mse: 149886.5312\nEpoch 650/1200\n\u001b[1m293/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 129358.2500 - mse: 129344.0391\nEpoch 650: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 129366.4688 - mse: 129352.2578 - val_loss: 151231.5938 - val_mse: 151217.3594\nEpoch 651/1200\n\u001b[1m274/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 130934.1797 - mse: 130919.9531\nEpoch 651: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 131117.3906 - mse: 131103.1562 - val_loss: 145869.6250 - val_mse: 145855.3750\nEpoch 652/1200\n\u001b[1m296/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 129681.1172 - mse: 129666.8828\nEpoch 652: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 129700.9375 - mse: 129686.7109 - val_loss: 155624.3594 - val_mse: 155610.1094\nEpoch 653/1200\n\u001b[1m298/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 134389.0938 - mse: 134374.8594\nEpoch 653: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 134374.2031 - mse: 134359.9844 - val_loss: 148701.2344 - val_mse: 148687.0156\nEpoch 654/1200\n\u001b[1m287/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 131506.1875 - mse: 131491.9219\nEpoch 654: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 131495.2031 - mse: 131480.9375 - val_loss: 147467.6406 - val_mse: 147453.4219\nEpoch 655/1200\n\u001b[1m287/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 130620.1719 - mse: 130605.9297\nEpoch 655: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 130608.6250 - mse: 130594.3906 - val_loss: 143756.3906 - val_mse: 143742.1719\nEpoch 656/1200\n\u001b[1m294/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 131991.5938 - mse: 131977.3438\nEpoch 656: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 131964.9375 - mse: 131950.6719 - val_loss: 148380.0781 - val_mse: 148365.7969\nEpoch 657/1200\n\u001b[1m291/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 130032.3125 - mse: 130018.0781\nEpoch 657: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 130129.5781 - mse: 130115.3438 - val_loss: 149283.0156 - val_mse: 149268.7656\nEpoch 658/1200\n\u001b[1m298/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 133060.9062 - mse: 133046.6406\nEpoch 658: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 133052.4219 - mse: 133038.1719 - val_loss: 144686.1094 - val_mse: 144671.8125\nEpoch 659/1200\n\u001b[1m295/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 128990.9922 - mse: 128976.7578\nEpoch 659: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 129034.3906 - mse: 129020.1641 - val_loss: 146160.3594 - val_mse: 146146.0781\nEpoch 660/1200\n\u001b[1m279/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 132008.9219 - mse: 131994.6875\nEpoch 660: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 132099.2188 - mse: 132084.9844 - val_loss: 150007.6875 - val_mse: 149993.4062\nEpoch 661/1200\n\u001b[1m299/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 131833.6250 - mse: 131819.3438\nEpoch 661: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 131836.5625 - mse: 131822.2812 - val_loss: 146876.3594 - val_mse: 146862.1094\nEpoch 662/1200\n\u001b[1m287/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 127133.1562 - mse: 127118.9062\nEpoch 662: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 127210.9922 - mse: 127196.7422 - val_loss: 148268.7188 - val_mse: 148254.4688\nEpoch 663/1200\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 133764.9219 - mse: 133750.6406\nEpoch 663: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 133764.7344 - mse: 133750.4531 - val_loss: 153521.7344 - val_mse: 153507.4844\nEpoch 664/1200\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 134069.0469 - mse: 134054.7656\nEpoch 664: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 134064.2031 - mse: 134049.9375 - val_loss: 150238.7031 - val_mse: 150224.3906\nEpoch 665/1200\n\u001b[1m273/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 128303.2734 - mse: 128289.0312\nEpoch 665: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 128483.2969 - mse: 128469.0547 - val_loss: 151674.5625 - val_mse: 151660.2812\nEpoch 666/1200\n\u001b[1m295/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 137750.9219 - mse: 137736.6250\nEpoch 666: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 137685.8281 - mse: 137671.5469 - val_loss: 152038.3125 - val_mse: 152024.0156\nEpoch 667/1200\n\u001b[1m274/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 130902.7891 - mse: 130888.5078\nEpoch 667: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 131128.2656 - mse: 131113.9844 - val_loss: 151444.4844 - val_mse: 151430.1719\nEpoch 668/1200\n\u001b[1m292/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 133593.5938 - mse: 133579.3125\nEpoch 668: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 133508.3594 - mse: 133494.0781 - val_loss: 143330.2344 - val_mse: 143315.9375\nEpoch 669/1200\n\u001b[1m289/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 135510.5469 - mse: 135496.3125\nEpoch 669: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 135401.9531 - mse: 135387.7031 - val_loss: 156527.7031 - val_mse: 156513.4531\nEpoch 670/1200\n\u001b[1m294/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 130334.9297 - mse: 130320.6172\nEpoch 670: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 130353.7969 - mse: 130339.4844 - val_loss: 154336.8906 - val_mse: 154322.5625\nEpoch 671/1200\n\u001b[1m299/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 132590.0625 - mse: 132575.7656\nEpoch 671: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 132596.9062 - mse: 132582.6094 - val_loss: 144325.2656 - val_mse: 144310.9531\nEpoch 672/1200\n\u001b[1m298/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 134042.9219 - mse: 134028.5781\nEpoch 672: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 134037.1875 - mse: 134022.8594 - val_loss: 142080.5938 - val_mse: 142066.2969\nEpoch 673/1200\n\u001b[1m295/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 131350.9375 - mse: 131336.6406\nEpoch 673: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 131355.6406 - mse: 131341.3438 - val_loss: 150669.3281 - val_mse: 150655.0000\nEpoch 674/1200\n\u001b[1m296/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 129981.6016 - mse: 129967.2969\nEpoch 674: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 130001.7500 - mse: 129987.4453 - val_loss: 154408.0938 - val_mse: 154393.7812\nEpoch 675/1200\n\u001b[1m287/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 132428.1406 - mse: 132413.8750\nEpoch 675: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 132425.2656 - mse: 132411.0000 - val_loss: 155323.5938 - val_mse: 155309.2500\nEpoch 676/1200\n\u001b[1m284/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 132509.0000 - mse: 132494.7188\nEpoch 676: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 132442.5625 - mse: 132428.2812 - val_loss: 141363.6406 - val_mse: 141349.3281\nEpoch 677/1200\n\u001b[1m299/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 139920.4531 - mse: 139906.1406\nEpoch 677: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 139873.5781 - mse: 139859.2812 - val_loss: 156600.9844 - val_mse: 156586.6406\nEpoch 678/1200\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 130185.4531 - mse: 130171.1406\nEpoch 678: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 130190.4375 - mse: 130176.1250 - val_loss: 145277.7969 - val_mse: 145263.4844\nEpoch 679/1200\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 127559.4375 - mse: 127545.1094\nEpoch 679: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 127569.0938 - mse: 127554.7578 - val_loss: 154862.6875 - val_mse: 154848.3906\nEpoch 680/1200\n\u001b[1m297/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 130539.9453 - mse: 130525.6094\nEpoch 680: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 130527.6875 - mse: 130513.3516 - val_loss: 153586.7188 - val_mse: 153572.3750\nEpoch 681/1200\n\u001b[1m294/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 130160.8672 - mse: 130146.5234\nEpoch 681: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 130193.8594 - mse: 130179.5156 - val_loss: 156085.9375 - val_mse: 156071.5781\nEpoch 682/1200\n\u001b[1m289/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 130556.4219 - mse: 130542.1094\nEpoch 682: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 130523.5078 - mse: 130509.1953 - val_loss: 146574.6406 - val_mse: 146560.3125\nEpoch 683/1200\n\u001b[1m297/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 130739.8359 - mse: 130725.4844\nEpoch 683: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 130722.9219 - mse: 130708.5781 - val_loss: 150867.5312 - val_mse: 150853.2031\nEpoch 684/1200\n\u001b[1m295/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 130157.1016 - mse: 130142.7500\nEpoch 684: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 130171.1250 - mse: 130156.7734 - val_loss: 152084.2500 - val_mse: 152069.9062\nEpoch 685/1200\n\u001b[1m293/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 132187.7812 - mse: 132173.4219\nEpoch 685: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 132148.5469 - mse: 132134.2031 - val_loss: 149266.4219 - val_mse: 149252.0781\nEpoch 686/1200\n\u001b[1m298/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 132294.9688 - mse: 132280.6250\nEpoch 686: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 132279.8594 - mse: 132265.5312 - val_loss: 152518.0938 - val_mse: 152503.7188\nEpoch 687/1200\n\u001b[1m299/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 129831.4141 - mse: 129817.0781\nEpoch 687: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 129839.0312 - mse: 129824.6953 - val_loss: 147596.5312 - val_mse: 147582.1406\nEpoch 688/1200\n\u001b[1m275/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 128559.1562 - mse: 128544.7891\nEpoch 688: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 128594.7969 - mse: 128580.4453 - val_loss: 149751.3906 - val_mse: 149737.0156\nEpoch 689/1200\n\u001b[1m290/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 129449.7734 - mse: 129435.4062\nEpoch 689: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 129459.4844 - mse: 129445.1172 - val_loss: 158645.8594 - val_mse: 158631.4688\nEpoch 690/1200\n\u001b[1m288/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 131271.1250 - mse: 131256.7500\nEpoch 690: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 131249.6875 - mse: 131235.3125 - val_loss: 157272.6562 - val_mse: 157258.2656\nEpoch 691/1200\n\u001b[1m287/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 129940.9453 - mse: 129926.5547\nEpoch 691: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 129968.4375 - mse: 129954.0547 - val_loss: 150830.3594 - val_mse: 150815.9844\nEpoch 692/1200\n\u001b[1m298/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 131272.0781 - mse: 131257.6719\nEpoch 692: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 131256.8438 - mse: 131242.4375 - val_loss: 150967.7969 - val_mse: 150953.4219\nEpoch 693/1200\n\u001b[1m292/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 129656.6172 - mse: 129642.2344\nEpoch 693: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 129666.0547 - mse: 129651.6719 - val_loss: 155862.3281 - val_mse: 155847.9375\nEpoch 694/1200\n\u001b[1m298/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 127568.6250 - mse: 127554.2266\nEpoch 694: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 127567.6172 - mse: 127553.2188 - val_loss: 155445.7188 - val_mse: 155431.3125\nEpoch 695/1200\n\u001b[1m287/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 131791.1875 - mse: 131776.7969\nEpoch 695: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 131785.9844 - mse: 131771.5938 - val_loss: 158244.3750 - val_mse: 158229.9688\nEpoch 696/1200\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 135658.9844 - mse: 135644.5625\nEpoch 696: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 135645.6875 - mse: 135631.2656 - val_loss: 155182.5938 - val_mse: 155168.1875\nEpoch 697/1200\n\u001b[1m295/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 128592.5078 - mse: 128578.1016\nEpoch 697: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 128620.4219 - mse: 128606.0156 - val_loss: 149239.8125 - val_mse: 149225.3906\nEpoch 698/1200\n\u001b[1m288/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 132026.2812 - mse: 132011.8594\nEpoch 698: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 131860.2031 - mse: 131845.7812 - val_loss: 155082.8125 - val_mse: 155068.3906\nEpoch 699/1200\n\u001b[1m280/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 127344.8047 - mse: 127330.3906\nEpoch 699: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 127423.5312 - mse: 127409.1172 - val_loss: 151395.3281 - val_mse: 151380.8906\nEpoch 700/1200\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 129666.2109 - mse: 129651.7578\nEpoch 700: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 129662.8750 - mse: 129648.4297 - val_loss: 149743.2188 - val_mse: 149728.7500\nEpoch 701/1200\n\u001b[1m286/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 127560.9062 - mse: 127546.4375\nEpoch 701: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 127628.8203 - mse: 127614.3516 - val_loss: 153921.0312 - val_mse: 153906.5938\nEpoch 702/1200\n\u001b[1m290/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 127449.6953 - mse: 127435.2734\nEpoch 702: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 127514.1484 - mse: 127499.7266 - val_loss: 151364.3125 - val_mse: 151349.8438\nEpoch 703/1200\n\u001b[1m279/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 133581.8906 - mse: 133567.4531\nEpoch 703: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 133441.2812 - mse: 133426.8438 - val_loss: 148876.2188 - val_mse: 148861.7656\nEpoch 704/1200\n\u001b[1m296/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 125634.0391 - mse: 125619.5938\nEpoch 704: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 125650.2891 - mse: 125635.8438 - val_loss: 149189.3594 - val_mse: 149174.8750\nEpoch 705/1200\n\u001b[1m292/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 130581.2422 - mse: 130566.7812\nEpoch 705: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 130519.1016 - mse: 130504.6406 - val_loss: 145952.0156 - val_mse: 145937.5625\nEpoch 706/1200\n\u001b[1m274/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 129102.8359 - mse: 129088.3516\nEpoch 706: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 129106.5859 - mse: 129092.0938 - val_loss: 154713.8281 - val_mse: 154699.3750\nEpoch 707/1200\n\u001b[1m296/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 127244.0078 - mse: 127229.5391\nEpoch 707: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 127248.4609 - mse: 127233.9922 - val_loss: 152536.3906 - val_mse: 152521.8750\nEpoch 708/1200\n\u001b[1m298/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 127642.1016 - mse: 127627.6328\nEpoch 708: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 127650.6406 - mse: 127636.1719 - val_loss: 147752.7188 - val_mse: 147738.2344\nEpoch 709/1200\n\u001b[1m284/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 127309.7500 - mse: 127295.2656\nEpoch 709: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 127314.5938 - mse: 127300.1172 - val_loss: 150100.3750 - val_mse: 150085.9062\nEpoch 710/1200\n\u001b[1m296/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 129693.1250 - mse: 129678.6250\nEpoch 710: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 129673.3672 - mse: 129658.8594 - val_loss: 147560.2344 - val_mse: 147545.7500\nEpoch 711/1200\n\u001b[1m299/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 124815.5547 - mse: 124801.0469\nEpoch 711: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 124843.0391 - mse: 124828.5312 - val_loss: 152243.5625 - val_mse: 152229.0938\nEpoch 712/1200\n\u001b[1m299/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 126499.7812 - mse: 126485.2891\nEpoch 712: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 126519.6562 - mse: 126505.1641 - val_loss: 148300.2500 - val_mse: 148285.7500\nEpoch 713/1200\n\u001b[1m285/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 124530.3125 - mse: 124515.8203\nEpoch 713: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 124644.2734 - mse: 124629.7812 - val_loss: 157597.2188 - val_mse: 157582.7500\nEpoch 714/1200\n\u001b[1m295/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 127738.6250 - mse: 127724.1250\nEpoch 714: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 127738.0312 - mse: 127723.5234 - val_loss: 152416.6094 - val_mse: 152402.1250\nEpoch 715/1200\n\u001b[1m288/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 125541.7422 - mse: 125527.2344\nEpoch 715: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 125618.3203 - mse: 125603.8203 - val_loss: 148161.2812 - val_mse: 148146.7969\nEpoch 716/1200\n\u001b[1m295/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 127191.6953 - mse: 127177.1875\nEpoch 716: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 127216.8438 - mse: 127202.3281 - val_loss: 152547.2812 - val_mse: 152532.7812\nEpoch 717/1200\n\u001b[1m296/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 132181.1250 - mse: 132166.6406\nEpoch 717: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 132151.1875 - mse: 132136.6875 - val_loss: 144675.5938 - val_mse: 144661.0625\nEpoch 718/1200\n\u001b[1m294/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 132700.2656 - mse: 132685.7500\nEpoch 718: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 132607.0312 - mse: 132592.5156 - val_loss: 154446.0000 - val_mse: 154431.4844\nEpoch 719/1200\n\u001b[1m292/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 130877.5625 - mse: 130863.0156\nEpoch 719: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 130803.1328 - mse: 130788.5859 - val_loss: 155293.2188 - val_mse: 155278.6406\nEpoch 720/1200\n\u001b[1m295/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 129176.1328 - mse: 129161.6016\nEpoch 720: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 129170.3828 - mse: 129155.8516 - val_loss: 155771.8438 - val_mse: 155757.2812\nEpoch 721/1200\n\u001b[1m298/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 129417.2422 - mse: 129402.6953\nEpoch 721: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 129419.8750 - mse: 129405.3281 - val_loss: 150298.3281 - val_mse: 150283.7969\nEpoch 722/1200\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 128865.1719 - mse: 128850.6484\nEpoch 722: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 128859.7266 - mse: 128845.2031 - val_loss: 159141.2344 - val_mse: 159126.6875\nEpoch 723/1200\n\u001b[1m275/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 133455.0000 - mse: 133440.4531\nEpoch 723: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 133036.0469 - mse: 133021.5156 - val_loss: 150187.0156 - val_mse: 150172.4844\nEpoch 724/1200\n\u001b[1m297/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 125693.1562 - mse: 125678.6406\nEpoch 724: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 125713.3438 - mse: 125698.8203 - val_loss: 159616.1250 - val_mse: 159601.5781\nEpoch 725/1200\n\u001b[1m298/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 125886.4062 - mse: 125871.8750\nEpoch 725: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 125913.1094 - mse: 125898.5781 - val_loss: 151779.4531 - val_mse: 151764.8281\nEpoch 726/1200\n\u001b[1m292/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 128839.8906 - mse: 128825.3281\nEpoch 726: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 128787.3359 - mse: 128772.7734 - val_loss: 151543.7812 - val_mse: 151529.2344\nEpoch 727/1200\n\u001b[1m299/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 130821.0938 - mse: 130806.5312\nEpoch 727: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 130815.4922 - mse: 130800.9219 - val_loss: 153911.6719 - val_mse: 153897.1250\nEpoch 728/1200\n\u001b[1m276/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 125913.5859 - mse: 125899.0312\nEpoch 728: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 125917.9688 - mse: 125903.4141 - val_loss: 148636.0000 - val_mse: 148621.4375\nEpoch 729/1200\n\u001b[1m293/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 129322.1250 - mse: 129307.5234\nEpoch 729: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 129295.1172 - mse: 129280.5156 - val_loss: 152051.0000 - val_mse: 152036.4531\nEpoch 730/1200\n\u001b[1m294/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 132087.7500 - mse: 132073.1875\nEpoch 730: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 131972.5469 - mse: 131957.9844 - val_loss: 155053.7969 - val_mse: 155039.2344\nEpoch 731/1200\n\u001b[1m293/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 125879.2031 - mse: 125864.6328\nEpoch 731: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 125931.2734 - mse: 125916.7031 - val_loss: 157734.1094 - val_mse: 157719.5469\nEpoch 732/1200\n\u001b[1m299/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 128852.0547 - mse: 128837.4766\nEpoch 732: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 128842.7031 - mse: 128828.1250 - val_loss: 146851.2188 - val_mse: 146836.6094\nEpoch 733/1200\n\u001b[1m299/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 128808.0078 - mse: 128793.3984\nEpoch 733: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 128797.4219 - mse: 128782.8203 - val_loss: 145544.0156 - val_mse: 145529.4219\nEpoch 734/1200\n\u001b[1m298/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 124826.6719 - mse: 124812.0391\nEpoch 734: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 124845.9609 - mse: 124831.3203 - val_loss: 151520.6094 - val_mse: 151506.0156\nEpoch 735/1200\n\u001b[1m273/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 126352.3516 - mse: 126337.7578\nEpoch 735: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 126433.0000 - mse: 126418.4062 - val_loss: 154480.5938 - val_mse: 154465.9375\nEpoch 736/1200\n\u001b[1m299/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 127000.2109 - mse: 126985.5547\nEpoch 736: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 127009.8594 - mse: 126995.2031 - val_loss: 149050.3438 - val_mse: 149035.7344\nEpoch 737/1200\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 127845.1719 - mse: 127830.5938\nEpoch 737: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 127846.2812 - mse: 127831.7031 - val_loss: 151451.4062 - val_mse: 151436.8438\nEpoch 738/1200\n\u001b[1m290/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 128240.9453 - mse: 128226.2969\nEpoch 738: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 128181.4297 - mse: 128166.7812 - val_loss: 147224.1719 - val_mse: 147209.5469\nEpoch 739/1200\n\u001b[1m293/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 127833.8047 - mse: 127819.1641\nEpoch 739: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 127847.5625 - mse: 127832.9219 - val_loss: 152370.1094 - val_mse: 152355.5156\nEpoch 740/1200\n\u001b[1m295/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 127712.3281 - mse: 127697.6719\nEpoch 740: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 127719.2500 - mse: 127704.5859 - val_loss: 154057.4062 - val_mse: 154042.7656\nEpoch 741/1200\n\u001b[1m296/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 125484.1484 - mse: 125469.5312\nEpoch 741: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 125490.8828 - mse: 125476.2656 - val_loss: 153611.1094 - val_mse: 153596.5156\nEpoch 742/1200\n\u001b[1m290/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 123682.0078 - mse: 123667.3594\nEpoch 742: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 123782.3984 - mse: 123767.7500 - val_loss: 162148.1250 - val_mse: 162133.5000\nEpoch 743/1200\n\u001b[1m295/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 127475.1875 - mse: 127460.5781\nEpoch 743: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 127454.2188 - mse: 127439.6094 - val_loss: 156660.7969 - val_mse: 156646.1250\nEpoch 744/1200\n\u001b[1m284/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 132729.2969 - mse: 132714.6562\nEpoch 744: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 132427.5781 - mse: 132412.9375 - val_loss: 151789.7969 - val_mse: 151775.1719\nEpoch 745/1200\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 127720.5547 - mse: 127705.8828\nEpoch 745: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 127716.3203 - mse: 127701.6484 - val_loss: 154816.9375 - val_mse: 154802.2812\nEpoch 746/1200\n\u001b[1m297/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 130633.4297 - mse: 130618.7344\nEpoch 746: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 130596.1953 - mse: 130581.5000 - val_loss: 155814.6250 - val_mse: 155799.9531\nEpoch 747/1200\n\u001b[1m295/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 123452.1875 - mse: 123437.4688\nEpoch 747: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 123486.7109 - mse: 123471.9922 - val_loss: 151634.7344 - val_mse: 151620.1250\nEpoch 748/1200\n\u001b[1m298/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 126558.6641 - mse: 126544.0000\nEpoch 748: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 126552.6719 - mse: 126538.0078 - val_loss: 152361.4688 - val_mse: 152346.8281\nEpoch 749/1200\n\u001b[1m293/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 128627.6016 - mse: 128612.8906\nEpoch 749: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 128573.8672 - mse: 128559.1562 - val_loss: 147849.7031 - val_mse: 147835.0156\nEpoch 750/1200\n\u001b[1m292/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 131294.0938 - mse: 131279.4219\nEpoch 750: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 131220.0000 - mse: 131205.3281 - val_loss: 155705.7969 - val_mse: 155691.0469\nEpoch 751/1200\n\u001b[1m293/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 124042.1719 - mse: 124027.4766\nEpoch 751: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 124076.2578 - mse: 124061.5625 - val_loss: 153587.1094 - val_mse: 153572.4531\nEpoch 752/1200\n\u001b[1m297/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 123945.1172 - mse: 123930.4609\nEpoch 752: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 123957.0469 - mse: 123942.3906 - val_loss: 155171.3750 - val_mse: 155156.6250\nEpoch 753/1200\n\u001b[1m293/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 126785.3438 - mse: 126770.6328\nEpoch 753: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 126816.9531 - mse: 126802.2422 - val_loss: 157863.7188 - val_mse: 157849.0156\nEpoch 754/1200\n\u001b[1m294/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 124491.9297 - mse: 124477.2266\nEpoch 754: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 124558.2891 - mse: 124543.5859 - val_loss: 152373.5625 - val_mse: 152358.8438\nEpoch 755/1200\n\u001b[1m288/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 125124.4297 - mse: 125109.7344\nEpoch 755: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 125146.7891 - mse: 125132.0938 - val_loss: 146089.0781 - val_mse: 146074.3750\nEpoch 756/1200\n\u001b[1m280/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 125119.7109 - mse: 125104.9688\nEpoch 756: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 125016.6016 - mse: 125001.8594 - val_loss: 150444.5312 - val_mse: 150429.8125\nEpoch 757/1200\n\u001b[1m299/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 125658.9375 - mse: 125644.1797\nEpoch 757: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 125678.3047 - mse: 125663.5469 - val_loss: 146657.1406 - val_mse: 146642.3750\nEpoch 758/1200\n\u001b[1m295/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 123945.2031 - mse: 123930.4766\nEpoch 758: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 123962.6953 - mse: 123947.9688 - val_loss: 149881.8281 - val_mse: 149867.0781\nEpoch 759/1200\n\u001b[1m295/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 127331.5156 - mse: 127316.7422\nEpoch 759: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 127287.3359 - mse: 127272.5625 - val_loss: 149804.5156 - val_mse: 149789.7812\nEpoch 760/1200\n\u001b[1m292/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 126893.8672 - mse: 126879.1172\nEpoch 760: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 126853.5625 - mse: 126838.8125 - val_loss: 145153.9375 - val_mse: 145139.1875\nEpoch 761/1200\n\u001b[1m290/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 128574.6250 - mse: 128559.8359\nEpoch 761: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 128467.1953 - mse: 128452.4062 - val_loss: 152675.4844 - val_mse: 152660.7031\nEpoch 762/1200\n\u001b[1m299/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 125128.5547 - mse: 125113.7891\nEpoch 762: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 125125.9844 - mse: 125111.2188 - val_loss: 156801.3438 - val_mse: 156786.5781\nEpoch 763/1200\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 124520.1406 - mse: 124505.3906\nEpoch 763: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 124514.9141 - mse: 124500.1641 - val_loss: 145714.7031 - val_mse: 145699.9531\nEpoch 764/1200\n\u001b[1m288/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 122509.3125 - mse: 122494.4922\nEpoch 764: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 122631.1172 - mse: 122616.2969 - val_loss: 151863.5312 - val_mse: 151848.7656\nEpoch 765/1200\n\u001b[1m295/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 128442.3750 - mse: 128427.6094\nEpoch 765: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 128400.1328 - mse: 128385.3672 - val_loss: 156993.1406 - val_mse: 156978.4062\nEpoch 766/1200\n\u001b[1m277/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 124438.9141 - mse: 124424.1484\nEpoch 766: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 124394.2812 - mse: 124379.5312 - val_loss: 156109.1094 - val_mse: 156094.3281\nEpoch 767/1200\n\u001b[1m274/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 126417.6719 - mse: 126402.8672\nEpoch 767: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 126433.0547 - mse: 126418.2422 - val_loss: 160093.3750 - val_mse: 160078.5625\nEpoch 768/1200\n\u001b[1m277/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 126875.5000 - mse: 126860.7188\nEpoch 768: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 126699.2734 - mse: 126684.4922 - val_loss: 158007.7188 - val_mse: 157992.9219\nEpoch 769/1200\n\u001b[1m275/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 127478.6719 - mse: 127463.8906\nEpoch 769: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 127407.8828 - mse: 127393.1016 - val_loss: 150434.1406 - val_mse: 150419.3594\nEpoch 770/1200\n\u001b[1m296/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 125360.6562 - mse: 125345.8281\nEpoch 770: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 125350.0703 - mse: 125335.2500 - val_loss: 157514.1719 - val_mse: 157499.3594\nEpoch 771/1200\n\u001b[1m290/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 123098.8125 - mse: 123084.0156\nEpoch 771: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 123159.2578 - mse: 123144.4688 - val_loss: 158130.3594 - val_mse: 158115.5469\nEpoch 772/1200\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 121515.0391 - mse: 121500.2031\nEpoch 772: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 121522.5078 - mse: 121507.6797 - val_loss: 158647.1094 - val_mse: 158632.3125\nEpoch 773/1200\n\u001b[1m275/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 122500.8516 - mse: 122486.0859\nEpoch 773: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 122729.5938 - mse: 122714.8359 - val_loss: 147195.0781 - val_mse: 147180.2500\nEpoch 774/1200\n\u001b[1m293/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 123095.3750 - mse: 123080.5547\nEpoch 774: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 123134.8203 - mse: 123120.0000 - val_loss: 153412.3906 - val_mse: 153397.5000\nEpoch 775/1200\n\u001b[1m295/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 119057.2500 - mse: 119042.4297\nEpoch 775: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 119128.6719 - mse: 119113.8516 - val_loss: 154033.8594 - val_mse: 154018.9375\nEpoch 776/1200\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 123863.2812 - mse: 123848.4219\nEpoch 776: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 123865.6250 - mse: 123850.7656 - val_loss: 154229.1562 - val_mse: 154214.2812\nEpoch 777/1200\n\u001b[1m299/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 127303.2422 - mse: 127288.4141\nEpoch 777: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 127291.6484 - mse: 127276.8203 - val_loss: 148661.9062 - val_mse: 148647.0469\nEpoch 778/1200\n\u001b[1m298/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 122567.4219 - mse: 122552.5938\nEpoch 778: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 122598.4375 - mse: 122583.6094 - val_loss: 147596.1250 - val_mse: 147581.2656\nEpoch 779/1200\n\u001b[1m279/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 125728.0781 - mse: 125713.1953\nEpoch 779: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 125864.9062 - mse: 125850.0312 - val_loss: 153507.4531 - val_mse: 153492.6094\nEpoch 780/1200\n\u001b[1m276/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 124804.8438 - mse: 124790.0078\nEpoch 780: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 124867.1875 - mse: 124852.3438 - val_loss: 151713.2500 - val_mse: 151698.4062\nEpoch 781/1200\n\u001b[1m290/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 119984.8906 - mse: 119969.9922\nEpoch 781: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 120089.8594 - mse: 120074.9609 - val_loss: 152830.2969 - val_mse: 152815.3750\nEpoch 782/1200\n\u001b[1m276/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 122570.2266 - mse: 122555.2891\nEpoch 782: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 122713.1172 - mse: 122698.1797 - val_loss: 146309.0938 - val_mse: 146294.2031\nEpoch 783/1200\n\u001b[1m298/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 121210.6484 - mse: 121195.7969\nEpoch 783: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 121243.4766 - mse: 121228.6172 - val_loss: 156421.7969 - val_mse: 156406.9219\nEpoch 784/1200\n\u001b[1m299/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 123941.6719 - mse: 123926.7734\nEpoch 784: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 123944.5078 - mse: 123929.6172 - val_loss: 145375.8125 - val_mse: 145360.9062\nEpoch 785/1200\n\u001b[1m278/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 129083.5234 - mse: 129068.6172\nEpoch 785: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 128805.0312 - mse: 128790.1250 - val_loss: 157362.4219 - val_mse: 157347.5156\nEpoch 786/1200\n\u001b[1m295/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 128025.3750 - mse: 128010.4688\nEpoch 786: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 127979.0859 - mse: 127964.1875 - val_loss: 155518.3750 - val_mse: 155503.4844\nEpoch 787/1200\n\u001b[1m292/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 124267.6172 - mse: 124252.7578\nEpoch 787: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 124288.1797 - mse: 124273.3203 - val_loss: 150243.7812 - val_mse: 150228.8906\nEpoch 788/1200\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 125685.6875 - mse: 125670.8125\nEpoch 788: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 125686.0000 - mse: 125671.1250 - val_loss: 146364.3281 - val_mse: 146349.4219\nEpoch 789/1200\n\u001b[1m296/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 123189.2109 - mse: 123174.2734\nEpoch 789: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 123228.5469 - mse: 123213.6094 - val_loss: 154581.8125 - val_mse: 154566.8281\nEpoch 790/1200\n\u001b[1m298/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 123280.4297 - mse: 123265.5000\nEpoch 790: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 123291.7500 - mse: 123276.8203 - val_loss: 152736.7031 - val_mse: 152721.7656\nEpoch 791/1200\n\u001b[1m292/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 120605.7031 - mse: 120590.7812\nEpoch 791: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 120656.5859 - mse: 120641.6562 - val_loss: 154855.8594 - val_mse: 154840.9219\nEpoch 792/1200\n\u001b[1m295/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 126379.3125 - mse: 126364.3438\nEpoch 792: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 126313.7031 - mse: 126298.7344 - val_loss: 146894.0938 - val_mse: 146879.1719\nEpoch 793/1200\n\u001b[1m287/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 123375.3438 - mse: 123360.4219\nEpoch 793: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 123397.8359 - mse: 123382.9141 - val_loss: 157795.6094 - val_mse: 157780.6875\nEpoch 794/1200\n\u001b[1m298/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 126021.8047 - mse: 126006.8359\nEpoch 794: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 125999.9922 - mse: 125985.0234 - val_loss: 152907.4844 - val_mse: 152892.5156\nEpoch 795/1200\n\u001b[1m298/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 121678.4766 - mse: 121663.5391\nEpoch 795: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 121686.7734 - mse: 121671.8359 - val_loss: 155169.1094 - val_mse: 155154.1406\nEpoch 796/1200\n\u001b[1m287/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 124470.5938 - mse: 124455.6484\nEpoch 796: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 124381.1484 - mse: 124366.2109 - val_loss: 154283.3750 - val_mse: 154268.4219\nEpoch 797/1200\n\u001b[1m299/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 123218.0547 - mse: 123203.1172\nEpoch 797: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 123220.4531 - mse: 123205.5156 - val_loss: 151191.7812 - val_mse: 151176.8438\nEpoch 798/1200\n\u001b[1m284/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 121043.9531 - mse: 121028.9609\nEpoch 798: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 121122.6328 - mse: 121107.6484 - val_loss: 147962.7969 - val_mse: 147947.7812\nEpoch 799/1200\n\u001b[1m293/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 122114.7109 - mse: 122099.7578\nEpoch 799: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 122132.1719 - mse: 122117.2188 - val_loss: 154059.6875 - val_mse: 154044.7188\nEpoch 800/1200\n\u001b[1m289/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 126198.5234 - mse: 126183.4688\nEpoch 800: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 126127.1172 - mse: 126112.0547 - val_loss: 151590.4062 - val_mse: 151575.4062\nEpoch 801/1200\n\u001b[1m276/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 125294.6719 - mse: 125279.6641\nEpoch 801: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 125169.7969 - mse: 125154.7891 - val_loss: 153000.2188 - val_mse: 152985.2188\nEpoch 802/1200\n\u001b[1m286/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 122306.8438 - mse: 122291.7812\nEpoch 802: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 122325.2891 - mse: 122310.2266 - val_loss: 147333.8438 - val_mse: 147318.8438\nEpoch 803/1200\n\u001b[1m275/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 124482.5234 - mse: 124467.5391\nEpoch 803: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 124315.1719 - mse: 124300.1875 - val_loss: 143813.8594 - val_mse: 143798.8125\nEpoch 804/1200\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 122034.1172 - mse: 122019.1562\nEpoch 804: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 122039.7188 - mse: 122024.7578 - val_loss: 157077.2344 - val_mse: 157062.2188\nEpoch 805/1200\n\u001b[1m299/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 121058.4844 - mse: 121043.4844\nEpoch 805: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 121062.4219 - mse: 121047.4297 - val_loss: 149502.2656 - val_mse: 149487.2812\nEpoch 806/1200\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 126279.7266 - mse: 126264.7188\nEpoch 806: val_loss did not improve from 132890.53125\n\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 126274.6562 - mse: 126259.6484 - val_loss: 146336.8594 - val_mse: 146321.8594\nEpoch 807/1200\n\u001b[1m135/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 115495.5781 - mse: 115480.5391","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":"y_pred=model.predict(X_test)\nmse = mean_squared_error(y_test, y_pred)\nprint(f\"Mean Squared Error: {mse}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-08T19:14:28.279727Z","iopub.execute_input":"2025-01-08T19:14:28.280484Z","iopub.status.idle":"2025-01-08T19:14:28.749793Z","shell.execute_reply.started":"2025-01-08T19:14:28.280451Z","shell.execute_reply":"2025-01-08T19:14:28.748962Z"}},"outputs":[{"name":"stdout","text":"\u001b[1m188/188\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\nMean Squared Error: 150287.19266053362\n","output_type":"stream"}],"execution_count":43},{"cell_type":"code","source":"prediction=model.predict(testdf)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-07T20:25:16.231622Z","iopub.status.idle":"2025-01-07T20:25:16.232103Z","shell.execute_reply":"2025-01-07T20:25:16.231909Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#load model with best weights according to validation loss\nfrom tensorflow.keras.models import load_model\nbest_model = load_model(\"/kaggle/working/weights.keras\")\nprediction = best_model.predict(testdf)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-08T20:56:47.047075Z","iopub.execute_input":"2025-01-08T20:56:47.047462Z","iopub.status.idle":"2025-01-08T20:56:47.847894Z","shell.execute_reply.started":"2025-01-08T20:56:47.047418Z","shell.execute_reply":"2025-01-08T20:56:47.847007Z"}},"outputs":[{"name":"stdout","text":"\u001b[1m313/313\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n","output_type":"stream"}],"execution_count":55},{"cell_type":"code","source":"import csv\narr=[]\nfor i in range(len(prediction)):\n    arr.append([len(traindf)+i+1,prediction[i][0]])\nwriter = csv.writer(open(\"/kaggle/working/submission.csv\", 'w'))\nfor row in arr:\n    writer.writerow(row)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-08T20:57:02.474111Z","iopub.execute_input":"2025-01-08T20:57:02.474526Z","iopub.status.idle":"2025-01-08T20:57:02.498817Z","shell.execute_reply.started":"2025-01-08T20:57:02.474483Z","shell.execute_reply":"2025-01-08T20:57:02.497893Z"}},"outputs":[],"execution_count":57}]}